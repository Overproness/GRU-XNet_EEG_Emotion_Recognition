{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "61fc32d4",
      "metadata": {},
      "source": [
        "# CA-CRNN: Emotion Recognition from EEG Signals with 4D Features\n",
        "\n",
        "This notebook implements the CA-CRNN model for EEG-based emotion recognition as described in the paper:\n",
        "\"Emotion recognition of EEG signals based on CA-CRNN with 4D features\" by Zhang et al. (2025)\n",
        "\n",
        "## Key Components:\n",
        "- 4D Feature Structure (Frequency × Spatial × Temporal)\n",
        "- Channel Attention Mechanism\n",
        "- Convolutional Recurrent Neural Network (CRNN)\n",
        "- Bidirectional LSTM for temporal feature extraction\n",
        "\n",
        "## Datasets:\n",
        "- DEAP (Valence/Arousal classification)\n",
        "- SEED & SEED-IV (3-class emotion classification)\n",
        "- GAMEEMO (Custom gaming emotion dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "e63059a7",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.18.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import signal\n",
        "from scipy.io import loadmat\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dense, Dropout, \n",
        "                                      Flatten, BatchNormalization, LSTM, \n",
        "                                      Bidirectional, TimeDistributed, GlobalAveragePooling2D,\n",
        "                                      GlobalMaxPooling2D, Reshape, Multiply, Add)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f342568e",
      "metadata": {},
      "source": [
        "## Configuration and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "e50ceca5",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded successfully!\n",
            "Output Directory: ./output\n",
            "Checkpoint Directory: ./checkpoints\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "class Config:\n",
        "    # Paths (Kaggle environment)\n",
        "    DEAP_PATH = '/kaggle/input/deap-dataset/deap-dataset/data_preprocessed_python'\n",
        "    SEED_IV_PATH = '/kaggle/input/seed-iv'\n",
        "    GAMEEMO_PATH = '/kaggle/input/database-for-emotion-recognition-system-gameemo/GAMEEMO'\n",
        "    \n",
        "    # Output paths\n",
        "    OUTPUT_DIR = './output'\n",
        "    CHECKPOINT_DIR = './checkpoints'\n",
        "    VISUALIZATIONS_DIR = './visualizations'\n",
        "    GDRIVE_DIR = './gdrive_backup'\n",
        "    \n",
        "    # EEG Parameters\n",
        "    SAMPLING_RATE_DEAP = 128  # Hz (preprocessed)\n",
        "    SAMPLING_RATE_SEED = 200  # Hz\n",
        "    WINDOW_SIZE = 0.5  # seconds\n",
        "    \n",
        "    # Frequency Bands\n",
        "    FREQ_BANDS = {\n",
        "        'theta': (4, 7),\n",
        "        'alpha': (8, 13),\n",
        "        'beta': (14, 30),\n",
        "        'gamma': (31, 45)\n",
        "    }\n",
        "    \n",
        "    # Model Parameters\n",
        "    TIME_STEPS = 4  # Best result from paper (T=4)\n",
        "    BATCH_SIZE = 128\n",
        "    EPOCHS = 100\n",
        "    LEARNING_RATE = 0.001\n",
        "    N_FOLDS = 5\n",
        "    \n",
        "    # DEAP specific\n",
        "    N_CHANNELS_DEAP = 32\n",
        "    VALENCE_THRESHOLD = 5\n",
        "    AROUSAL_THRESHOLD = 5\n",
        "    \n",
        "    # SEED-IV specific\n",
        "    N_CHANNELS_SEED = 62\n",
        "    N_CLASSES_SEED_IV = 4  # neutral, sad, fear, happy\n",
        "    \n",
        "    # Feature map dimensions (after electrode mapping)\n",
        "    FEATURE_HEIGHT = 8\n",
        "    FEATURE_WIDTH = 9\n",
        "    N_FREQ_BANDS = 4\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create directories\n",
        "for directory in [config.OUTPUT_DIR, config.CHECKPOINT_DIR, \n",
        "                  config.VISUALIZATIONS_DIR, config.GDRIVE_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    \n",
        "print(\"Configuration loaded successfully!\")\n",
        "print(f\"Output Directory: {config.OUTPUT_DIR}\")\n",
        "print(f\"Checkpoint Directory: {config.CHECKPOINT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "482ff965",
      "metadata": {},
      "source": [
        "## 4D Feature Extraction\n",
        "\n",
        "Implementation of the 4D feature structure that integrates:\n",
        "- **Frequency information**: 4 frequency bands (θ, α, β, γ)\n",
        "- **Spatial information**: 2D electrode mapping (8×9 grid)\n",
        "- **Temporal information**: Time segments with differential entropy features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "ef75fec6",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4D Feature Extractor implemented successfully!\n"
          ]
        }
      ],
      "source": [
        "class EEGFeatureExtractor:\n",
        "    \"\"\"\n",
        "    Extract 4D features from EEG signals according to the paper.\n",
        "    4D structure: N × Frequency × Height × Width × TimeSteps\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, sampling_rate=128, window_size=0.5, n_channels=32):\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.window_size = window_size\n",
        "        self.n_samples_per_window = int(sampling_rate * window_size)\n",
        "        self.n_channels = n_channels\n",
        "        \n",
        "        # 10-20 electrode mapping for DEAP (32 channels) to 8×9 grid\n",
        "        self.electrode_mapping_deap = self._create_electrode_mapping_deap()\n",
        "        \n",
        "        # SEED electrode mapping (62 channels)\n",
        "        self.electrode_mapping_seed = self._create_electrode_mapping_seed()\n",
        "    \n",
        "    def _create_electrode_mapping_deap(self):\n",
        "        \"\"\"\n",
        "        Map 32 DEAP channels to 8×9 2D grid following 10-20 international system.\n",
        "        Channels in DEAP: \n",
        "        Fp1, AF3, F3, F7, FC5, FC1, C3, T7, CP5, CP1, P3, P7, PO3, O1,\n",
        "        Oz, Pz, Fp2, AF4, Fz, F4, F8, FC6, FC2, Cz, C4, T8, CP6, CP2, P4, P8, PO4, O2\n",
        "        \"\"\"\n",
        "        mapping = np.zeros((8, 9), dtype=int) - 1  # -1 indicates no electrode\n",
        "        \n",
        "        # Map each channel to grid position (row, col)\n",
        "        positions = {\n",
        "            0: (0, 2), 1: (1, 2), 2: (2, 2), 3: (2, 0), 4: (3, 1), 5: (3, 3),\n",
        "            6: (4, 2), 7: (4, 0), 8: (5, 1), 9: (5, 3), 10: (6, 2), 11: (6, 0),\n",
        "            12: (7, 1), 13: (7, 2), 14: (7, 4), 15: (6, 4), 16: (0, 6), 17: (1, 6),\n",
        "            18: (2, 4), 19: (2, 6), 20: (2, 8), 21: (3, 7), 22: (3, 5), 23: (4, 4),\n",
        "            24: (4, 6), 25: (4, 8), 26: (5, 7), 27: (5, 5), 28: (6, 6), 29: (6, 8),\n",
        "            30: (7, 7), 31: (7, 6)\n",
        "        }\n",
        "        \n",
        "        for ch, (row, col) in positions.items():\n",
        "            mapping[row, col] = ch\n",
        "            \n",
        "        return mapping\n",
        "    \n",
        "    def _create_electrode_mapping_seed(self):\n",
        "        \"\"\"\n",
        "        Map 62 SEED channels to larger 2D grid.\n",
        "        For SEED, we'll create a 9×9 grid to accommodate more electrodes.\n",
        "        \"\"\"\n",
        "        mapping = np.zeros((9, 9), dtype=int) - 1\n",
        "        \n",
        "        # Simplified mapping for SEED (62 channels)\n",
        "        # This is a simplified version; actual mapping should follow ESI-62 cap layout\n",
        "        channel_idx = 0\n",
        "        for i in range(9):\n",
        "            for j in range(9):\n",
        "                if channel_idx < 62:\n",
        "                    mapping[i, j] = channel_idx\n",
        "                    channel_idx += 1\n",
        "                    \n",
        "        return mapping[:8, :]  # Trim to 8×9 for consistency\n",
        "    \n",
        "    def differential_entropy(self, signal_segment):\n",
        "        \"\"\"\n",
        "        Calculate Differential Entropy (DE) for a signal segment.\n",
        "        DE = 0.5 * log(2πeσ²)\n",
        "        \n",
        "        Args:\n",
        "            signal_segment: 1D array of EEG signal\n",
        "            \n",
        "        Returns:\n",
        "            Differential entropy value\n",
        "        \"\"\"\n",
        "        variance = np.var(signal_segment)\n",
        "        if variance == 0:\n",
        "            variance = 1e-10  # Avoid log(0)\n",
        "        de = 0.5 * np.log(2 * np.pi * np.e * variance)\n",
        "        return de\n",
        "    \n",
        "    def extract_frequency_bands(self, eeg_data):\n",
        "        \"\"\"\n",
        "        Decompose EEG signal into frequency bands using Butterworth filter.\n",
        "        \n",
        "        Args:\n",
        "            eeg_data: (n_samples, n_channels) EEG data\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with frequency bands as keys and filtered signals as values\n",
        "        \"\"\"\n",
        "        # Check if data is too short for filtering\n",
        "        min_length = 30  # Minimum samples required for 4th order filter\n",
        "        if eeg_data.shape[0] < min_length:\n",
        "            raise ValueError(f\"EEG data too short ({eeg_data.shape[0]} samples). \"\n",
        "                           f\"Need at least {min_length} samples for filtering. \"\n",
        "                           f\"This segment will be skipped.\")\n",
        "        \n",
        "        frequency_data = {}\n",
        "        \n",
        "        for band_name, (low_freq, high_freq) in config.FREQ_BANDS.items():\n",
        "            # Design Butterworth bandpass filter\n",
        "            nyquist = self.sampling_rate / 2\n",
        "            low = low_freq / nyquist\n",
        "            high = high_freq / nyquist\n",
        "            \n",
        "            # Ensure frequencies are in valid range\n",
        "            low = max(0.001, min(low, 0.999))\n",
        "            high = max(0.001, min(high, 0.999))\n",
        "            \n",
        "            if low >= high:\n",
        "                continue\n",
        "                \n",
        "            b, a = signal.butter(4, [low, high], btype='band')\n",
        "            \n",
        "            # Calculate minimum required length for filtfilt\n",
        "            padlen = 3 * max(len(a), len(b))\n",
        "            \n",
        "            # Apply filter to each channel\n",
        "            filtered_data = np.zeros_like(eeg_data)\n",
        "            for ch in range(eeg_data.shape[1]):\n",
        "                # Check if signal is long enough\n",
        "                if eeg_data.shape[0] <= padlen:\n",
        "                    # Signal too short, use unfiltered data with warning\n",
        "                    filtered_data[:, ch] = eeg_data[:, ch]\n",
        "                else:\n",
        "                    # Apply filter normally\n",
        "                    filtered_data[:, ch] = signal.filtfilt(b, a, eeg_data[:, ch])\n",
        "            \n",
        "            frequency_data[band_name] = filtered_data\n",
        "            \n",
        "        return frequency_data\n",
        "    \n",
        "    def extract_de_features(self, frequency_data):\n",
        "        \"\"\"\n",
        "        Extract Differential Entropy features from frequency band data.\n",
        "        \n",
        "        Args:\n",
        "            frequency_data: Dict of frequency bands with filtered signals\n",
        "            \n",
        "        Returns:\n",
        "            DE features array (n_windows, n_bands, n_channels)\n",
        "        \"\"\"\n",
        "        n_channels = list(frequency_data.values())[0].shape[1]\n",
        "        n_samples = list(frequency_data.values())[0].shape[0]\n",
        "        n_windows = n_samples // self.n_samples_per_window\n",
        "        \n",
        "        de_features = []\n",
        "        \n",
        "        for band_name in ['theta', 'alpha', 'beta', 'gamma']:\n",
        "            if band_name not in frequency_data:\n",
        "                continue\n",
        "                \n",
        "            band_data = frequency_data[band_name]\n",
        "            band_de = np.zeros((n_windows, n_channels))\n",
        "            \n",
        "            for win in range(n_windows):\n",
        "                start_idx = win * self.n_samples_per_window\n",
        "                end_idx = start_idx + self.n_samples_per_window\n",
        "                \n",
        "                for ch in range(n_channels):\n",
        "                    segment = band_data[start_idx:end_idx, ch]\n",
        "                    band_de[win, ch] = self.differential_entropy(segment)\n",
        "            \n",
        "            de_features.append(band_de)\n",
        "        \n",
        "        # Stack: (n_windows, n_bands, n_channels)\n",
        "        de_features = np.stack(de_features, axis=1)\n",
        "        return de_features\n",
        "    \n",
        "    def map_to_2d(self, de_features, dataset='deap'):\n",
        "        \"\"\"\n",
        "        Map 1D channel features to 2D spatial grid.\n",
        "        \n",
        "        Args:\n",
        "            de_features: (n_windows, n_bands, n_channels)\n",
        "            dataset: 'deap' or 'seed'\n",
        "            \n",
        "        Returns:\n",
        "            2D mapped features (n_windows, n_bands, height, width)\n",
        "        \"\"\"\n",
        "        mapping = self.electrode_mapping_deap if dataset == 'deap' else self.electrode_mapping_seed\n",
        "        height, width = mapping.shape\n",
        "        \n",
        "        n_windows, n_bands, n_channels = de_features.shape\n",
        "        \n",
        "        features_2d = np.zeros((n_windows, n_bands, height, width))\n",
        "        \n",
        "        for win in range(n_windows):\n",
        "            for band in range(n_bands):\n",
        "                for i in range(height):\n",
        "                    for j in range(width):\n",
        "                        ch_idx = mapping[i, j]\n",
        "                        if ch_idx >= 0 and ch_idx < n_channels:\n",
        "                            features_2d[win, band, i, j] = de_features[win, band, ch_idx]\n",
        "        \n",
        "        return features_2d\n",
        "    \n",
        "    def create_4d_features(self, eeg_data, time_steps=4, dataset='deap'):\n",
        "        \"\"\"\n",
        "        Create 4D feature structure from raw EEG data.\n",
        "        \n",
        "        Args:\n",
        "            eeg_data: (n_samples, n_channels) raw EEG data\n",
        "            time_steps: Number of consecutive time windows to combine\n",
        "            dataset: 'deap' or 'seed'\n",
        "            \n",
        "        Returns:\n",
        "            4D features (n_segments, n_bands, height, width, 2*time_steps)\n",
        "        \"\"\"\n",
        "        # Step 1: Extract frequency bands\n",
        "        frequency_data = self.extract_frequency_bands(eeg_data)\n",
        "        \n",
        "        # Step 2: Extract DE features\n",
        "        de_features = self.extract_de_features(frequency_data)\n",
        "        \n",
        "        # Step 3: Map to 2D\n",
        "        features_2d = self.map_to_2d(de_features, dataset=dataset)\n",
        "        \n",
        "        # Step 4: Create temporal structure (combine time_steps)\n",
        "        n_windows, n_bands, height, width = features_2d.shape\n",
        "        n_segments = n_windows - 2 * time_steps + 1\n",
        "        \n",
        "        if n_segments <= 0:\n",
        "            # Not enough windows, return what we have\n",
        "            features_4d = features_2d[:, :, :, :, np.newaxis]\n",
        "            return features_4d\n",
        "        \n",
        "        features_4d = []\n",
        "        for i in range(n_segments):\n",
        "            # Concatenate 2*time_steps consecutive windows\n",
        "            temporal_segment = features_2d[i:i+2*time_steps]\n",
        "            # Reshape to (n_bands, height, width, 2*time_steps)\n",
        "            temporal_segment = np.transpose(temporal_segment, (1, 2, 3, 0))\n",
        "            features_4d.append(temporal_segment)\n",
        "        \n",
        "        features_4d = np.array(features_4d)\n",
        "        return features_4d\n",
        "\n",
        "print(\"4D Feature Extractor implemented successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f23164a9",
      "metadata": {},
      "source": [
        "## Channel Attention Mechanism\n",
        "\n",
        "Implementation of the Channel Attention (CA) module to emphasize important feature channels and suppress less relevant information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "4039ad6d",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Channel Attention mechanism implemented!\n"
          ]
        }
      ],
      "source": [
        "class ChannelAttention(layers.Layer):\n",
        "    \"\"\"\n",
        "    Channel Attention mechanism for EEG feature maps.\n",
        "    \n",
        "    Uses both average and max pooling to capture channel-wise statistics,\n",
        "    then learns attention weights through a shared MLP.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, reduction_ratio=16, **kwargs):\n",
        "        super(ChannelAttention, self).__init__(**kwargs)\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        channels = input_shape[-1]\n",
        "        self.shared_dense_1 = Dense(\n",
        "            channels // self.reduction_ratio,\n",
        "            activation='relu',\n",
        "            kernel_initializer='he_normal',\n",
        "            use_bias=True,\n",
        "            bias_initializer='zeros'\n",
        "        )\n",
        "        self.shared_dense_2 = Dense(\n",
        "            channels,\n",
        "            kernel_initializer='he_normal',\n",
        "            use_bias=True,\n",
        "            bias_initializer='zeros'\n",
        "        )\n",
        "        super(ChannelAttention, self).build(input_shape)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        # Global Average Pooling\n",
        "        avg_pool = GlobalAveragePooling2D()(inputs)\n",
        "        avg_pool = Reshape((1, 1, avg_pool.shape[-1]))(avg_pool)\n",
        "        \n",
        "        # Global Max Pooling\n",
        "        max_pool = GlobalMaxPooling2D()(inputs)\n",
        "        max_pool = Reshape((1, 1, max_pool.shape[-1]))(max_pool)\n",
        "        \n",
        "        # Shared MLP\n",
        "        avg_out = self.shared_dense_2(self.shared_dense_1(avg_pool))\n",
        "        max_out = self.shared_dense_2(self.shared_dense_1(max_pool))\n",
        "        \n",
        "        # Combine and apply sigmoid\n",
        "        attention = tf.nn.sigmoid(avg_out + max_out)\n",
        "        \n",
        "        # Apply attention weights\n",
        "        return inputs * attention\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super(ChannelAttention, self).get_config()\n",
        "        config.update({'reduction_ratio': self.reduction_ratio})\n",
        "        return config\n",
        "\n",
        "print(\"Channel Attention mechanism implemented!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aaa1fff",
      "metadata": {},
      "source": [
        "## CA-CRNN Model Architecture\n",
        "\n",
        "Complete implementation of the CA-CRNN model combining:\n",
        "- CNN layers with Channel Attention for spatial-frequency feature extraction\n",
        "- BiLSTM for temporal feature learning\n",
        "- Fully connected layers for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "094dc565",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CA-CRNN model architecture implemented!\n"
          ]
        }
      ],
      "source": [
        "def build_ca_crnn_model(input_shape, n_classes=2, time_steps=4):\n",
        "    \"\"\"\n",
        "    Build CA-CRNN model for EEG emotion recognition.\n",
        "    \n",
        "    Args:\n",
        "        input_shape: (n_bands, height, width, 2*time_steps)\n",
        "        n_classes: Number of output classes\n",
        "        time_steps: Number of time steps (T)\n",
        "        \n",
        "    Returns:\n",
        "        Keras model\n",
        "    \"\"\"\n",
        "    \n",
        "    # Input layer\n",
        "    inputs = layers.Input(shape=input_shape, name='input_4d_features')\n",
        "    \n",
        "    # Process each time slice through CNN\n",
        "    # TimeDistributed wrapper applies CNN to each time slice\n",
        "    n_bands, height, width, temporal_length = input_shape\n",
        "    \n",
        "    # Reshape for processing: (batch, temporal, bands, h, w)\n",
        "    x = layers.Permute((4, 1, 2, 3))(inputs)  # Move temporal to second dimension\n",
        "    \n",
        "    # Define CNN module for each time slice\n",
        "    def cnn_module(x_slice):\n",
        "        \"\"\"CNN module with Channel Attention\"\"\"\n",
        "        # Conv Layer 1: 64 filters, 5x5\n",
        "        conv1 = Conv2D(64, (5, 5), padding='same', activation='relu', \n",
        "                       kernel_initializer='he_normal')(x_slice)\n",
        "        conv1 = BatchNormalization()(conv1)\n",
        "        conv1 = ChannelAttention(reduction_ratio=4)(conv1)\n",
        "        \n",
        "        # Conv Layer 2: 128 filters, 4x4\n",
        "        conv2 = Conv2D(128, (4, 4), padding='same', activation='relu',\n",
        "                       kernel_initializer='he_normal')(conv1)\n",
        "        conv2 = BatchNormalization()(conv2)\n",
        "        conv2 = ChannelAttention(reduction_ratio=8)(conv2)\n",
        "        \n",
        "        # Conv Layer 3: 256 filters, 4x4\n",
        "        conv3 = Conv2D(256, (4, 4), padding='same', activation='relu',\n",
        "                       kernel_initializer='he_normal')(conv2)\n",
        "        conv3 = BatchNormalization()(conv3)\n",
        "        conv3 = ChannelAttention(reduction_ratio=16)(conv3)\n",
        "        \n",
        "        # Max Pooling\n",
        "        pool = MaxPooling2D(pool_size=(2, 2), strides=2)(conv3)\n",
        "        \n",
        "        # Flatten\n",
        "        flat = Flatten()(pool)\n",
        "        \n",
        "        # Fully Connected Layer\n",
        "        fc = Dense(512, activation='relu', kernel_initializer='he_normal')(flat)\n",
        "        fc = Dropout(0.5)(fc)\n",
        "        \n",
        "        return fc\n",
        "    \n",
        "    # Apply CNN to each time slice using TimeDistributed\n",
        "    cnn_output = TimeDistributed(\n",
        "        models.Sequential([\n",
        "            Conv2D(64, (5, 5), padding='same', activation='relu', \n",
        "                   kernel_initializer='he_normal', input_shape=(n_bands, height, width)),\n",
        "            BatchNormalization(),\n",
        "            ChannelAttention(reduction_ratio=4),\n",
        "            Conv2D(128, (4, 4), padding='same', activation='relu',\n",
        "                   kernel_initializer='he_normal'),\n",
        "            BatchNormalization(),\n",
        "            ChannelAttention(reduction_ratio=8),\n",
        "            Conv2D(256, (4, 4), padding='same', activation='relu',\n",
        "                   kernel_initializer='he_normal'),\n",
        "            BatchNormalization(),\n",
        "            ChannelAttention(reduction_ratio=16),\n",
        "            MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "            Flatten(),\n",
        "            Dense(512, activation='relu', kernel_initializer='he_normal'),\n",
        "            Dropout(0.5)\n",
        "        ])\n",
        "    )(x)\n",
        "    \n",
        "    # Bidirectional LSTM layers\n",
        "    lstm1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.5))(cnn_output)\n",
        "    lstm2 = Bidirectional(LSTM(64, return_sequences=False, dropout=0.5))(lstm1)\n",
        "    \n",
        "    # Classification layers\n",
        "    dense1 = Dense(128, activation='relu', kernel_initializer='he_normal')(lstm2)\n",
        "    dense1 = Dropout(0.5)(dense1)\n",
        "    \n",
        "    # Output layer\n",
        "    if n_classes == 2:\n",
        "        outputs = Dense(1, activation='sigmoid', name='output')(dense1)\n",
        "    else:\n",
        "        outputs = Dense(n_classes, activation='softmax', name='output')(dense1)\n",
        "    \n",
        "    # Create model\n",
        "    model = models.Model(inputs=inputs, outputs=outputs, name='CA_CRNN')\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def compile_model(model, n_classes=2, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Compile the model with appropriate loss and metrics.\n",
        "    \n",
        "    Args:\n",
        "        model: Keras model\n",
        "        n_classes: Number of classes\n",
        "        learning_rate: Learning rate for optimizer\n",
        "    \"\"\"\n",
        "    \n",
        "    if n_classes == 2:\n",
        "        loss = 'binary_crossentropy'\n",
        "        metrics = ['accuracy', tf.keras.metrics.Precision(), \n",
        "                   tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
        "    else:\n",
        "        loss = 'categorical_crossentropy'\n",
        "        metrics = ['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2)]\n",
        "    \n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "print(\"CA-CRNN model architecture implemented!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b86c9706",
      "metadata": {},
      "source": [
        "## Dataset Loading Functions\n",
        "\n",
        "Functions to load and preprocess DEAP, SEED, SEED-IV, and GAMEEMO datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "37c7d8be",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loader implemented!\n"
          ]
        }
      ],
      "source": [
        "class DatasetLoader:\n",
        "    \"\"\"Load and preprocess EEG datasets\"\"\"\n",
        "    \n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.feature_extractor_deap = EEGFeatureExtractor(\n",
        "            sampling_rate=config.SAMPLING_RATE_DEAP,\n",
        "            window_size=config.WINDOW_SIZE,\n",
        "            n_channels=config.N_CHANNELS_DEAP\n",
        "        )\n",
        "        self.feature_extractor_seed = EEGFeatureExtractor(\n",
        "            sampling_rate=config.SAMPLING_RATE_SEED,\n",
        "            window_size=config.WINDOW_SIZE,\n",
        "            n_channels=config.N_CHANNELS_SEED\n",
        "        )\n",
        "        \n",
        "        # SEED-IV emotion labels for 24 trials (from SEED-IV paper)\n",
        "        # 0: neutral, 1: sad, 2: fear, 3: happy\n",
        "        # Each session has 24 trials (6 of each emotion in a specific order)\n",
        "        self.seed_iv_trial_labels = [\n",
        "            1, 2, 3, 0, 2, 0, 0, 1, 0, 1, 2, 1,  # Trials 1-12\n",
        "            1, 3, 2, 2, 3, 3, 0, 3, 0, 3, 1, 3   # Trials 13-24\n",
        "        ]\n",
        "    \n",
        "    def load_deap_subject(self, subject_id):\n",
        "        \"\"\"\n",
        "        Load DEAP dataset for a single subject.\n",
        "        \n",
        "        Args:\n",
        "            subject_id: Subject ID (1-32)\n",
        "            \n",
        "        Returns:\n",
        "            features, valence_labels, arousal_labels\n",
        "        \"\"\"\n",
        "        filename = f's{subject_id:02d}.dat'\n",
        "        filepath = os.path.join(self.config.DEAP_PATH, filename)\n",
        "        \n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"File not found: {filepath}\")\n",
        "            return None, None, None\n",
        "        \n",
        "        # Load data\n",
        "        with open(filepath, 'rb') as f:\n",
        "            subject_data = pickle.load(f, encoding='latin1')\n",
        "        \n",
        "        # Extract EEG data and labels\n",
        "        # Data shape: (40 trials, 40 channels, 8064 samples)\n",
        "        # Channels 0-31 are EEG channels\n",
        "        eeg_data = subject_data['data'][:, :32, :]  # (40, 32, 8064)\n",
        "        labels = subject_data['labels']  # (40, 4) - valence, arousal, dominance, liking\n",
        "        \n",
        "        # Extract valence and arousal labels\n",
        "        valence = labels[:, 0]  # (40,)\n",
        "        arousal = labels[:, 1]  # (40,)\n",
        "        \n",
        "        # Binary classification (threshold at 5)\n",
        "        valence_binary = (valence >= self.config.VALENCE_THRESHOLD).astype(int)\n",
        "        arousal_binary = (arousal >= self.config.AROUSAL_THRESHOLD).astype(int)\n",
        "        \n",
        "        # Process each trial\n",
        "        all_features = []\n",
        "        all_valence_labels = []\n",
        "        all_arousal_labels = []\n",
        "        \n",
        "        for trial_idx in range(eeg_data.shape[0]):\n",
        "            trial_data = eeg_data[trial_idx].T  # (8064, 32)\n",
        "            \n",
        "            # Extract 4D features\n",
        "            features_4d = self.feature_extractor_deap.create_4d_features(\n",
        "                trial_data, \n",
        "                time_steps=self.config.TIME_STEPS,\n",
        "                dataset='deap'\n",
        "            )\n",
        "            \n",
        "            if features_4d.shape[0] > 0:\n",
        "                all_features.append(features_4d)\n",
        "                # Replicate labels for all segments from this trial\n",
        "                n_segments = features_4d.shape[0]\n",
        "                all_valence_labels.extend([valence_binary[trial_idx]] * n_segments)\n",
        "                all_arousal_labels.extend([arousal_binary[trial_idx]] * n_segments)\n",
        "        \n",
        "        if len(all_features) == 0:\n",
        "            return None, None, None\n",
        "        \n",
        "        # Concatenate all features\n",
        "        features = np.concatenate(all_features, axis=0)\n",
        "        valence_labels = np.array(all_valence_labels)\n",
        "        arousal_labels = np.array(all_arousal_labels)\n",
        "        \n",
        "        return features, valence_labels, arousal_labels\n",
        "    \n",
        "    def load_deap_all_subjects(self, subject_ids=None):\n",
        "        \"\"\"\n",
        "        Load DEAP dataset for multiple subjects.\n",
        "        \n",
        "        Args:\n",
        "            subject_ids: List of subject IDs, or None for all subjects\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with features and labels for valence and arousal\n",
        "        \"\"\"\n",
        "        if subject_ids is None:\n",
        "            subject_ids = range(1, 33)  # All 32 subjects\n",
        "        \n",
        "        all_features = []\n",
        "        all_valence = []\n",
        "        all_arousal = []\n",
        "        \n",
        "        for subject_id in subject_ids:\n",
        "            print(f\"Loading DEAP subject {subject_id}...\")\n",
        "            features, valence, arousal = self.load_deap_subject(subject_id)\n",
        "            \n",
        "            if features is not None:\n",
        "                all_features.append(features)\n",
        "                all_valence.append(valence)\n",
        "                all_arousal.append(arousal)\n",
        "        \n",
        "        if len(all_features) == 0:\n",
        "            return None\n",
        "        \n",
        "        return {\n",
        "            'features': np.concatenate(all_features, axis=0),\n",
        "            'valence': np.concatenate(all_valence, axis=0),\n",
        "            'arousal': np.concatenate(all_arousal, axis=0)\n",
        "        }\n",
        "    \n",
        "    def load_seed_session(self, subject_id, session_id):\n",
        "        \"\"\"\n",
        "        Load SEED-IV dataset for a single subject and session.\n",
        "        \n",
        "        Args:\n",
        "            subject_id: Subject ID (1-15)\n",
        "            session_id: Session ID (1-3)\n",
        "            \n",
        "        Returns:\n",
        "            features, labels (4 classes: neutral=0, sad=1, fear=2, happy=3)\n",
        "        \"\"\"\n",
        "        # SEED-IV file structure: /kaggle/input/seed-iv/eeg_raw_data/{session}/{subject}_{date}.mat\n",
        "        session_path = os.path.join(self.config.SEED_IV_PATH, 'eeg_raw_data', str(session_id))\n",
        "        \n",
        "        if not os.path.exists(session_path):\n",
        "            print(f\"Session path not found: {session_path}\")\n",
        "            return None, None\n",
        "        \n",
        "        # Find the file for this subject in this session\n",
        "        # Files are named like: 1_20160518.mat, 2_20150915.mat, etc.\n",
        "        target_file = None\n",
        "        for filename in os.listdir(session_path):\n",
        "            if filename.startswith(f'{subject_id}_') and filename.endswith('.mat'):\n",
        "                target_file = filename\n",
        "                break\n",
        "        \n",
        "        if target_file is None:\n",
        "            print(f\"No file found for subject {subject_id} in session {session_id}\")\n",
        "            return None, None\n",
        "        \n",
        "        filepath = os.path.join(session_path, target_file)\n",
        "        print(f\"Loading: {filepath}\")\n",
        "        \n",
        "        # Load MATLAB file\n",
        "        mat_data = loadmat(filepath)\n",
        "        \n",
        "        # SEED-IV structure: Each .mat file contains multiple trial variables\n",
        "        # Variables are named like: 'djc_eeg1', 'djc_eeg2', etc. for each trial\n",
        "        # There are 24 trials per session, each with 62 EEG channels\n",
        "        \n",
        "        all_features = []\n",
        "        all_labels = []\n",
        "        \n",
        "        # Extract trial data - look for variables that contain EEG data\n",
        "        trial_keys = sorted([key for key in mat_data.keys() \n",
        "                           if not key.startswith('__') and isinstance(mat_data[key], np.ndarray)])\n",
        "        \n",
        "        print(f\"Found {len(trial_keys)} trial variables: {trial_keys[:5]}...\")\n",
        "        \n",
        "        for trial_idx, key in enumerate(trial_keys):\n",
        "            if trial_idx >= 24:  # SEED-IV has 24 trials per session\n",
        "                break\n",
        "                \n",
        "            trial_data = mat_data[key]\n",
        "            \n",
        "            # SEED-IV data format: (n_channels, n_samples) typically (62, n_samples)\n",
        "            if trial_data.ndim == 2:\n",
        "                if trial_data.shape[0] == 62:  # 62 channels\n",
        "                    trial_data = trial_data.T  # Convert to (n_samples, 62)\n",
        "                elif trial_data.shape[1] == 62:\n",
        "                    pass  # Already in correct format\n",
        "                else:\n",
        "                    print(f\"Unexpected shape for trial {trial_idx}: {trial_data.shape}\")\n",
        "                    continue\n",
        "                \n",
        "                # Extract 4D features\n",
        "                features_4d = self.feature_extractor_seed.create_4d_features(\n",
        "                    trial_data,\n",
        "                    time_steps=self.config.TIME_STEPS,\n",
        "                    dataset='seed'\n",
        "                )\n",
        "                \n",
        "                if features_4d.shape[0] > 0:\n",
        "                    all_features.append(features_4d)\n",
        "                    # Get label for this trial\n",
        "                    trial_label = self.seed_iv_trial_labels[trial_idx]\n",
        "                    # Replicate label for all segments from this trial\n",
        "                    n_segments = features_4d.shape[0]\n",
        "                    all_labels.extend([trial_label] * n_segments)\n",
        "        \n",
        "        if len(all_features) == 0:\n",
        "            print(f\"No valid features extracted from {filepath}\")\n",
        "            return None, None\n",
        "        \n",
        "        features = np.concatenate(all_features, axis=0)\n",
        "        labels = np.array(all_labels)\n",
        "        \n",
        "        print(f\"Extracted {features.shape[0]} segments with shape {features.shape[1:]}\")\n",
        "        print(f\"Label distribution: {np.bincount(labels)}\")\n",
        "        \n",
        "        return features, labels\n",
        "    \n",
        "    def load_seed_all_subjects(self, subject_ids=None, session_ids=None):\n",
        "        \"\"\"\n",
        "        Load SEED-IV dataset for multiple subjects and sessions.\n",
        "        \n",
        "        Args:\n",
        "            subject_ids: List of subject IDs (1-15), or None for all\n",
        "            session_ids: List of session IDs (1-3), or None for all\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with features and labels\n",
        "        \"\"\"\n",
        "        if subject_ids is None:\n",
        "            subject_ids = range(1, 16)  # 15 subjects in SEED-IV\n",
        "        if session_ids is None:\n",
        "            session_ids = range(1, 4)  # 3 sessions\n",
        "        \n",
        "        all_features = []\n",
        "        all_labels = []\n",
        "        \n",
        "        for session_id in session_ids:\n",
        "            for subject_id in subject_ids:\n",
        "                print(f\"\\nLoading SEED-IV Subject {subject_id}, Session {session_id}...\")\n",
        "                features, labels = self.load_seed_session(subject_id, session_id)\n",
        "                \n",
        "                if features is not None:\n",
        "                    all_features.append(features)\n",
        "                    all_labels.append(labels)\n",
        "        \n",
        "        if len(all_features) == 0:\n",
        "            return None\n",
        "        \n",
        "        return {\n",
        "            'features': np.concatenate(all_features, axis=0),\n",
        "            'labels': np.concatenate(all_labels, axis=0)\n",
        "        }\n",
        "    \n",
        "    def load_gameemo_subject(self, subject_id):\n",
        "        \"\"\"\n",
        "        Load GAMEEMO dataset for a single subject.\n",
        "        \n",
        "        Args:\n",
        "            subject_id: Subject ID string (e.g., 'S01')\n",
        "            \n",
        "        Returns:\n",
        "            features, labels\n",
        "        \"\"\"\n",
        "        subject_path = os.path.join(self.config.GAMEEMO_PATH, subject_id)\n",
        "        \n",
        "        if not os.path.exists(subject_path):\n",
        "            print(f\"Subject path not found: {subject_path}\")\n",
        "            return None, None\n",
        "        \n",
        "        # GAMEEMO structure varies - check for preprocessed CSV\n",
        "        csv_path = os.path.join(subject_path, 'Preprocessed EEG Data', '.csv format')\n",
        "        \n",
        "        all_features = []\n",
        "        all_labels = []\n",
        "        \n",
        "        if os.path.exists(csv_path):\n",
        "            # Load CSV files\n",
        "            for csv_file in os.listdir(csv_path):\n",
        "                if csv_file.endswith('.csv'):\n",
        "                    df = pd.read_csv(os.path.join(csv_path, csv_file))\n",
        "                    # Process based on actual CSV structure\n",
        "                    # This is a placeholder - adjust based on actual format\n",
        "        \n",
        "        return None, None  # Placeholder\n",
        "\n",
        "print(\"Dataset loader implemented!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24f086e",
      "metadata": {},
      "source": [
        "## Training and Evaluation\n",
        "\n",
        "Training loop with 5-fold cross-validation, checkpointing, and comprehensive logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "7d359481",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training manager implemented!\n"
          ]
        }
      ],
      "source": [
        "class TrainingManager:\n",
        "    \"\"\"Manage training, validation, and checkpointing\"\"\"\n",
        "    \n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.history_records = []\n",
        "        \n",
        "    def create_callbacks(self, fold, task_name):\n",
        "        \"\"\"Create callbacks for training\"\"\"\n",
        "        \n",
        "        checkpoint_path = os.path.join(\n",
        "            self.config.CHECKPOINT_DIR,\n",
        "            f'{task_name}_fold{fold}_best.h5'\n",
        "        )\n",
        "        \n",
        "        callbacks_list = [\n",
        "            callbacks.ModelCheckpoint(\n",
        "                checkpoint_path,\n",
        "                monitor='val_accuracy',\n",
        "                save_best_only=True,\n",
        "                mode='max',\n",
        "                verbose=1\n",
        "            ),\n",
        "            callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=15,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=5,\n",
        "                min_lr=1e-6,\n",
        "                verbose=1\n",
        "            ),\n",
        "            callbacks.CSVLogger(\n",
        "                os.path.join(self.config.OUTPUT_DIR, f'{task_name}_fold{fold}_log.csv')\n",
        "            )\n",
        "        ]\n",
        "        \n",
        "        return callbacks_list\n",
        "    \n",
        "    def train_with_cross_validation(self, features, labels, task_name='task', \n",
        "                                     n_classes=2, n_folds=5):\n",
        "        \"\"\"\n",
        "        Train model with k-fold cross-validation.\n",
        "        \n",
        "        Args:\n",
        "            features: 4D feature array\n",
        "            labels: Label array\n",
        "            task_name: Name of the task (e.g., 'deap_valence')\n",
        "            n_classes: Number of classes\n",
        "            n_folds: Number of folds for cross-validation\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with results\n",
        "        \"\"\"\n",
        "        \n",
        "        kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "        \n",
        "        fold_accuracies = []\n",
        "        fold_histories = []\n",
        "        \n",
        "        for fold, (train_idx, val_idx) in enumerate(kfold.split(features), 1):\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"Training Fold {fold}/{n_folds} - {task_name}\")\n",
        "            print(f\"{'='*50}\\n\")\n",
        "            \n",
        "            # Split data\n",
        "            X_train, X_val = features[train_idx], features[val_idx]\n",
        "            y_train, y_val = labels[train_idx], labels[val_idx]\n",
        "            \n",
        "            # Normalize features\n",
        "            # Reshape for normalization\n",
        "            original_shape = X_train.shape\n",
        "            X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "            X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
        "            \n",
        "            scaler = StandardScaler()\n",
        "            X_train_flat = scaler.fit_transform(X_train_flat)\n",
        "            X_val_flat = scaler.transform(X_val_flat)\n",
        "            \n",
        "            X_train = X_train_flat.reshape(original_shape)\n",
        "            X_val = X_val_flat.reshape(X_val.shape[0], *original_shape[1:])\n",
        "            \n",
        "            # Prepare labels\n",
        "            if n_classes > 2:\n",
        "                y_train_cat = to_categorical(y_train, n_classes)\n",
        "                y_val_cat = to_categorical(y_val, n_classes)\n",
        "            else:\n",
        "                y_train_cat = y_train\n",
        "                y_val_cat = y_val\n",
        "            \n",
        "            # Build and compile model\n",
        "            input_shape = X_train.shape[1:]  # (n_bands, height, width, 2*time_steps)\n",
        "            model = build_ca_crnn_model(input_shape, n_classes=n_classes, \n",
        "                                        time_steps=self.config.TIME_STEPS)\n",
        "            model = compile_model(model, n_classes=n_classes, \n",
        "                                 learning_rate=self.config.LEARNING_RATE)\n",
        "            \n",
        "            # Print model summary for first fold\n",
        "            if fold == 1:\n",
        "                print(\"\\nModel Architecture:\")\n",
        "                model.summary()\n",
        "            \n",
        "            # Create callbacks\n",
        "            callback_list = self.create_callbacks(fold, task_name)\n",
        "            \n",
        "            # Train model\n",
        "            history = model.fit(\n",
        "                X_train, y_train_cat,\n",
        "                validation_data=(X_val, y_val_cat),\n",
        "                epochs=self.config.EPOCHS,\n",
        "                batch_size=self.config.BATCH_SIZE,\n",
        "                callbacks=callback_list,\n",
        "                verbose=1\n",
        "            )\n",
        "            \n",
        "            # Evaluate\n",
        "            val_loss, val_acc, *other_metrics = model.evaluate(X_val, y_val_cat, verbose=0)\n",
        "            \n",
        "            print(f\"\\nFold {fold} Results:\")\n",
        "            print(f\"Validation Accuracy: {val_acc*100:.2f}%\")\n",
        "            print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "            \n",
        "            fold_accuracies.append(val_acc)\n",
        "            fold_histories.append(history.history)\n",
        "            \n",
        "            # Save fold results\n",
        "            self.save_fold_results(fold, task_name, history.history, val_acc)\n",
        "            \n",
        "            # Clear session to free memory\n",
        "            tf.keras.backend.clear_session()\n",
        "        \n",
        "        # Calculate statistics\n",
        "        mean_accuracy = np.mean(fold_accuracies)\n",
        "        std_accuracy = np.std(fold_accuracies)\n",
        "        \n",
        "        results = {\n",
        "            'task_name': task_name,\n",
        "            'fold_accuracies': fold_accuracies,\n",
        "            'mean_accuracy': mean_accuracy,\n",
        "            'std_accuracy': std_accuracy,\n",
        "            'histories': fold_histories\n",
        "        }\n",
        "        \n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Final Results for {task_name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"Mean Accuracy: {mean_accuracy*100:.2f}% ± {std_accuracy*100:.2f}%\")\n",
        "        print(f\"Fold Accuracies: {[f'{acc*100:.2f}%' for acc in fold_accuracies]}\")\n",
        "        \n",
        "        # Save overall results\n",
        "        self.save_overall_results(results)\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def save_fold_results(self, fold, task_name, history, accuracy):\n",
        "        \"\"\"Save results for a single fold\"\"\"\n",
        "        results_path = os.path.join(\n",
        "            self.config.OUTPUT_DIR,\n",
        "            f'{task_name}_fold{fold}_results.pkl'\n",
        "        )\n",
        "        \n",
        "        with open(results_path, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'history': history,\n",
        "                'accuracy': accuracy\n",
        "            }, f)\n",
        "    \n",
        "    def save_overall_results(self, results):\n",
        "        \"\"\"Save overall results\"\"\"\n",
        "        results_path = os.path.join(\n",
        "            self.config.OUTPUT_DIR,\n",
        "            f\"{results['task_name']}_overall_results.pkl\"\n",
        "        )\n",
        "        \n",
        "        with open(results_path, 'wb') as f:\n",
        "            pickle.dump(results, f)\n",
        "        \n",
        "        # Also save as text\n",
        "        text_path = os.path.join(\n",
        "            self.config.OUTPUT_DIR,\n",
        "            f\"{results['task_name']}_results.txt\"\n",
        "        )\n",
        "        \n",
        "        with open(text_path, 'w') as f:\n",
        "            f.write(f\"Task: {results['task_name']}\\n\")\n",
        "            f.write(f\"Mean Accuracy: {results['mean_accuracy']*100:.2f}%\\n\")\n",
        "            f.write(f\"Std Accuracy: {results['std_accuracy']*100:.2f}%\\n\")\n",
        "            f.write(f\"Fold Accuracies: {results['fold_accuracies']}\\n\")\n",
        "\n",
        "print(\"Training manager implemented!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f88797c",
      "metadata": {},
      "source": [
        "## Visualization Functions\n",
        "\n",
        "Comprehensive visualization for training metrics, feature maps, and results analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "7e619476",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Visualization functions implemented!\n"
          ]
        }
      ],
      "source": [
        "class Visualizer:\n",
        "    \"\"\"Create comprehensive visualizations for training and results\"\"\"\n",
        "    \n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        plt.style.use('seaborn-v0_8-darkgrid')\n",
        "        sns.set_palette(\"husl\")\n",
        "    \n",
        "    def plot_training_history(self, history, fold, task_name, save=True):\n",
        "        \"\"\"\n",
        "        Plot training and validation metrics for a single fold.\n",
        "        \n",
        "        Args:\n",
        "            history: Training history dictionary\n",
        "            fold: Fold number\n",
        "            task_name: Task name\n",
        "            save: Whether to save the plot\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle(f'{task_name} - Fold {fold} Training History', fontsize=16, fontweight='bold')\n",
        "        \n",
        "        # Plot Loss\n",
        "        axes[0, 0].plot(history['loss'], label='Train Loss', linewidth=2)\n",
        "        axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
        "        axes[0, 0].set_title('Model Loss', fontsize=12, fontweight='bold')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "        axes[0, 0].set_ylabel('Loss')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Plot Accuracy\n",
        "        axes[0, 1].plot(history['accuracy'], label='Train Accuracy', linewidth=2)\n",
        "        axes[0, 1].plot(history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
        "        axes[0, 1].set_title('Model Accuracy', fontsize=12, fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "        axes[0, 1].set_ylabel('Accuracy')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Plot Precision (if available)\n",
        "        if 'precision' in history:\n",
        "            axes[1, 0].plot(history['precision'], label='Train Precision', linewidth=2)\n",
        "            axes[1, 0].plot(history['val_precision'], label='Val Precision', linewidth=2)\n",
        "            axes[1, 0].set_title('Model Precision', fontsize=12, fontweight='bold')\n",
        "            axes[1, 0].set_xlabel('Epoch')\n",
        "            axes[1, 0].set_ylabel('Precision')\n",
        "            axes[1, 0].legend()\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Plot Recall (if available)\n",
        "        if 'recall' in history:\n",
        "            axes[1, 1].plot(history['recall'], label='Train Recall', linewidth=2)\n",
        "            axes[1, 1].plot(history['val_recall'], label='Val Recall', linewidth=2)\n",
        "            axes[1, 1].set_title('Model Recall', fontsize=12, fontweight='bold')\n",
        "            axes[1, 1].set_xlabel('Epoch')\n",
        "            axes[1, 1].set_ylabel('Recall')\n",
        "            axes[1, 1].legend()\n",
        "            axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        \n",
        "        if save:\n",
        "            save_path = os.path.join(\n",
        "                self.config.VISUALIZATIONS_DIR,\n",
        "                f'{task_name}_fold{fold}_history.png'\n",
        "            )\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Saved plot to {save_path}\")\n",
        "        \n",
        "        plt.show()\n",
        "        plt.close()\n",
        "    \n",
        "    def plot_all_folds_comparison(self, results, save=True):\n",
        "        \"\"\"\n",
        "        Compare results across all folds.\n",
        "        \n",
        "        Args:\n",
        "            results: Results dictionary from training\n",
        "            save: Whether to save the plot\n",
        "        \"\"\"\n",
        "        task_name = results['task_name']\n",
        "        fold_accuracies = results['fold_accuracies']\n",
        "        mean_acc = results['mean_accuracy']\n",
        "        std_acc = results['std_accuracy']\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "        fig.suptitle(f'{task_name} - Cross-Validation Results', fontsize=16, fontweight='bold')\n",
        "        \n",
        "        # Bar plot of fold accuracies\n",
        "        folds = list(range(1, len(fold_accuracies) + 1))\n",
        "        bars = axes[0].bar(folds, [acc * 100 for acc in fold_accuracies], \n",
        "                          color='steelblue', alpha=0.8, edgecolor='black')\n",
        "        axes[0].axhline(y=mean_acc * 100, color='red', linestyle='--', \n",
        "                       linewidth=2, label=f'Mean: {mean_acc*100:.2f}%')\n",
        "        axes[0].set_xlabel('Fold', fontsize=12)\n",
        "        axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
        "        axes[0].set_title('Accuracy per Fold', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xticks(folds)\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        # Add value labels on bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                        f'{height:.2f}%',\n",
        "                        ha='center', va='bottom', fontsize=9)\n",
        "        \n",
        "        # Box plot of accuracies across epochs for all folds\n",
        "        if 'histories' in results:\n",
        "            all_val_accs = []\n",
        "            for hist in results['histories']:\n",
        "                if 'val_accuracy' in hist:\n",
        "                    all_val_accs.append([acc * 100 for acc in hist['val_accuracy']])\n",
        "            \n",
        "            if all_val_accs:\n",
        "                axes[1].boxplot(all_val_accs, labels=folds)\n",
        "                axes[1].set_xlabel('Fold', fontsize=12)\n",
        "                axes[1].set_ylabel('Validation Accuracy (%)', fontsize=12)\n",
        "                axes[1].set_title('Validation Accuracy Distribution', fontsize=12, fontweight='bold')\n",
        "                axes[1].grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        \n",
        "        if save:\n",
        "            save_path = os.path.join(\n",
        "                self.config.VISUALIZATIONS_DIR,\n",
        "                f'{task_name}_folds_comparison.png'\n",
        "            )\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Saved plot to {save_path}\")\n",
        "        \n",
        "        plt.show()\n",
        "        plt.close()\n",
        "    \n",
        "    def plot_learning_curves_all_folds(self, results, save=True):\n",
        "        \"\"\"\n",
        "        Plot learning curves for all folds together.\n",
        "        \n",
        "        Args:\n",
        "            results: Results dictionary\n",
        "            save: Whether to save\n",
        "        \"\"\"\n",
        "        task_name = results['task_name']\n",
        "        histories = results['histories']\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "        fig.suptitle(f'{task_name} - Learning Curves (All Folds)', \n",
        "                    fontsize=16, fontweight='bold')\n",
        "        \n",
        "        # Plot loss for all folds\n",
        "        for fold, history in enumerate(histories, 1):\n",
        "            axes[0].plot(history['val_loss'], label=f'Fold {fold}', alpha=0.7, linewidth=2)\n",
        "        \n",
        "        axes[0].set_title('Validation Loss', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Loss')\n",
        "        axes[0].legend(loc='best', fontsize=8)\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Plot accuracy for all folds\n",
        "        for fold, history in enumerate(histories, 1):\n",
        "            axes[1].plot([acc * 100 for acc in history['val_accuracy']], \n",
        "                        label=f'Fold {fold}', alpha=0.7, linewidth=2)\n",
        "        \n",
        "        axes[1].set_title('Validation Accuracy', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Accuracy (%)')\n",
        "        axes[1].legend(loc='best', fontsize=8)\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        \n",
        "        if save:\n",
        "            save_path = os.path.join(\n",
        "                self.config.VISUALIZATIONS_DIR,\n",
        "                f'{task_name}_learning_curves.png'\n",
        "            )\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Saved plot to {save_path}\")\n",
        "        \n",
        "        plt.show()\n",
        "        plt.close()\n",
        "    \n",
        "    def plot_confusion_matrix(self, y_true, y_pred, class_names, task_name, save=True):\n",
        "        \"\"\"\n",
        "        Plot confusion matrix.\n",
        "        \n",
        "        Args:\n",
        "            y_true: True labels\n",
        "            y_pred: Predicted labels\n",
        "            class_names: List of class names\n",
        "            task_name: Task name\n",
        "            save: Whether to save\n",
        "        \"\"\"\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        \n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        \n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                   xticklabels=class_names, yticklabels=class_names,\n",
        "                   cbar_kws={'label': 'Count'})\n",
        "        plt.title(f'{task_name} - Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Predicted Label', fontsize=12)\n",
        "        plt.ylabel('True Label', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        if save:\n",
        "            save_path = os.path.join(\n",
        "                self.config.VISUALIZATIONS_DIR,\n",
        "                f'{task_name}_confusion_matrix.png'\n",
        "            )\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Saved plot to {save_path}\")\n",
        "        \n",
        "        plt.show()\n",
        "        plt.close()\n",
        "    \n",
        "    def plot_feature_maps(self, feature_sample, title='4D Feature Visualization', save=True):\n",
        "        \"\"\"\n",
        "        Visualize 4D features.\n",
        "        \n",
        "        Args:\n",
        "            feature_sample: Single feature sample (n_bands, height, width, time_steps)\n",
        "            title: Plot title\n",
        "            save: Whether to save\n",
        "        \"\"\"\n",
        "        n_bands, height, width, time_steps = feature_sample.shape\n",
        "        \n",
        "        fig, axes = plt.subplots(n_bands, min(4, time_steps), \n",
        "                                figsize=(min(4, time_steps)*3, n_bands*2.5))\n",
        "        \n",
        "        if n_bands == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "        \n",
        "        band_names = ['Theta (θ)', 'Alpha (α)', 'Beta (β)', 'Gamma (γ)']\n",
        "        \n",
        "        for band_idx in range(n_bands):\n",
        "            for t_idx in range(min(4, time_steps)):\n",
        "                ax = axes[band_idx, t_idx] if n_bands > 1 else axes[t_idx]\n",
        "                \n",
        "                im = ax.imshow(feature_sample[band_idx, :, :, t_idx], \n",
        "                              cmap='viridis', aspect='auto')\n",
        "                ax.set_title(f'{band_names[band_idx]} - T{t_idx+1}', fontsize=10)\n",
        "                ax.axis('off')\n",
        "                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "        \n",
        "        fig.suptitle(title, fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        if save:\n",
        "            save_path = os.path.join(\n",
        "                self.config.VISUALIZATIONS_DIR,\n",
        "                'feature_maps_sample.png'\n",
        "            )\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Saved plot to {save_path}\")\n",
        "        \n",
        "        plt.show()\n",
        "        plt.close()\n",
        "    \n",
        "    def create_results_summary_plot(self, all_results, save=True):\n",
        "        \"\"\"\n",
        "        Create summary plot comparing multiple tasks/datasets.\n",
        "        \n",
        "        Args:\n",
        "            all_results: List of results dictionaries\n",
        "            save: Whether to save\n",
        "        \"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        \n",
        "        task_names = [r['task_name'] for r in all_results]\n",
        "        mean_accs = [r['mean_accuracy'] * 100 for r in all_results]\n",
        "        std_accs = [r['std_accuracy'] * 100 for r in all_results]\n",
        "        \n",
        "        x_pos = np.arange(len(task_names))\n",
        "        bars = ax.bar(x_pos, mean_accs, yerr=std_accs, \n",
        "                     capsize=10, color='steelblue', alpha=0.8, \n",
        "                     edgecolor='black', linewidth=1.5)\n",
        "        \n",
        "        ax.set_xlabel('Task', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "        ax.set_title('CA-CRNN Performance Summary Across Tasks', \n",
        "                    fontsize=14, fontweight='bold')\n",
        "        ax.set_xticks(x_pos)\n",
        "        ax.set_xticklabels(task_names, rotation=45, ha='right')\n",
        "        ax.grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        # Add value labels\n",
        "        for bar, mean, std in zip(bars, mean_accs, std_accs):\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{mean:.2f}%\\n±{std:.2f}%',\n",
        "                   ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        \n",
        "        if save:\n",
        "            save_path = os.path.join(\n",
        "                self.config.VISUALIZATIONS_DIR,\n",
        "                'overall_results_summary.png'\n",
        "            )\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Saved plot to {save_path}\")\n",
        "        \n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "print(\"Visualization functions implemented!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1c36700",
      "metadata": {},
      "source": [
        "## Google Drive Backup with Rclone\n",
        "\n",
        "Setup rclone for automatic backup of checkpoints and results to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "de535ed4",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4734  100  4734    0     0  10496      0 --:--:-- --:--:-- --:--:-- 10520\n",
            "100  4734  100  4734    0     0  10496      0 --:--:-- --:--:-- --:--:-- 10520\n",
            "\n",
            "The latest version of rclone rclone v1.72.0 is already installed.\n",
            "\n",
            "\n",
            "The latest version of rclone rclone v1.72.0 is already installed.\n",
            "\n",
            "Rclone installed successfully!\n",
            "Rclone installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install rclone (if not already installed)\n",
        "!curl https://rclone.org/install.sh | bash\n",
        "\n",
        "print(\"Rclone installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "f6004c9f",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rclone backup manager implemented!\n",
            "\n",
            "# To configure rclone for Google Drive:\n",
            "# 1. Run: rclone config\n",
            "# 2. Choose 'n' for new remote\n",
            "# 3. Name it 'gdrive'\n",
            "# 4. Choose type 'drive' (Google Drive)\n",
            "# 5. Follow the authentication flow\n",
            "# \n",
            "# Or paste your existing rclone config below:\n",
            "# \n",
            "# [gdrive]\n",
            "# type = drive\n",
            "# client_id = \n",
            "# client_secret = \n",
            "# scope = drive\n",
            "# token = {\"access_token\":\"xxx\",\"token_type\":\"Bearer\",\"refresh_token\":\"xxx\",\"expiry\":\"xxx\"}\n",
            "# team_drive = \n",
            "\n"
          ]
        }
      ],
      "source": [
        "class RcloneBackup:\n",
        "    \"\"\"Manage backups to Google Drive using rclone\"\"\"\n",
        "    \n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.rclone_config_path = os.path.expanduser('~/.config/rclone/rclone.conf')\n",
        "        self.remote_name = 'gdrive'\n",
        "        self.remote_folder = 'CA-CRNN-EEG'\n",
        "    \n",
        "    def setup_rclone_config(self, config_content=None):\n",
        "        \"\"\"\n",
        "        Setup rclone configuration.\n",
        "        \n",
        "        Args:\n",
        "            config_content: Rclone configuration content as string\n",
        "        \"\"\"\n",
        "        # Create config directory\n",
        "        os.makedirs(os.path.dirname(self.rclone_config_path), exist_ok=True)\n",
        "        \n",
        "        if config_content:\n",
        "            # Write provided config\n",
        "            with open(self.rclone_config_path, 'w') as f:\n",
        "                f.write(config_content)\n",
        "            print(f\"Rclone config written to {self.rclone_config_path}\")\n",
        "        else:\n",
        "            print(\"Please provide rclone config content or configure manually\")\n",
        "            print(f\"Config should be saved to: {self.rclone_config_path}\")\n",
        "            print(\"\\nExample config format:\")\n",
        "            print(\"[gdrive]\")\n",
        "            print(\"type = drive\")\n",
        "            print(\"scope = drive\")\n",
        "            print(\"token = {YOUR_TOKEN}\")\n",
        "            print(\"team_drive = \")\n",
        "    \n",
        "    def upload_to_gdrive(self, local_path, remote_path=None):\n",
        "        \"\"\"\n",
        "        Upload files/folders to Google Drive.\n",
        "        \n",
        "        Args:\n",
        "            local_path: Local file or directory path\n",
        "            remote_path: Remote path (relative to remote_folder)\n",
        "        \"\"\"\n",
        "        if not os.path.exists(self.rclone_config_path):\n",
        "            print(\"Rclone not configured. Please run setup_rclone_config() first.\")\n",
        "            return False\n",
        "        \n",
        "        if remote_path is None:\n",
        "            remote_path = os.path.basename(local_path)\n",
        "        \n",
        "        full_remote_path = f\"{self.remote_name}:{self.remote_folder}/{remote_path}\"\n",
        "        \n",
        "        print(f\"Uploading {local_path} to {full_remote_path}...\")\n",
        "        \n",
        "        try:\n",
        "            if os.path.isdir(local_path):\n",
        "                # Upload directory\n",
        "                cmd = f\"rclone copy '{local_path}' '{full_remote_path}' -P\"\n",
        "            else:\n",
        "                # Upload single file\n",
        "                cmd = f\"rclone copy '{local_path}' '{os.path.dirname(full_remote_path)}' -P\"\n",
        "            \n",
        "            result = os.system(cmd)\n",
        "            \n",
        "            if result == 0:\n",
        "                print(f\"   Successfully uploaded to Google Drive\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"✗ Upload failed with code {result}\")\n",
        "                return False\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error during upload: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def backup_checkpoints(self):\n",
        "        \"\"\"Backup all checkpoints to Google Drive\"\"\"\n",
        "        return self.upload_to_gdrive(self.config.CHECKPOINT_DIR, 'checkpoints')\n",
        "    \n",
        "    def backup_outputs(self):\n",
        "        \"\"\"Backup all outputs to Google Drive\"\"\"\n",
        "        return self.upload_to_gdrive(self.config.OUTPUT_DIR, 'outputs')\n",
        "    \n",
        "    def backup_visualizations(self):\n",
        "        \"\"\"Backup all visualizations to Google Drive\"\"\"\n",
        "        return self.upload_to_gdrive(self.config.VISUALIZATIONS_DIR, 'visualizations')\n",
        "    \n",
        "    def backup_all(self):\n",
        "        \"\"\"Backup everything\"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"Starting backup to Google Drive...\")\n",
        "        print(\"=\"*50 + \"\\n\")\n",
        "        \n",
        "        success = True\n",
        "        success &= self.backup_checkpoints()\n",
        "        success &= self.backup_outputs()\n",
        "        success &= self.backup_visualizations()\n",
        "        \n",
        "        if success:\n",
        "            print(\"\\n   All backups completed successfully!\")\n",
        "        else:\n",
        "            print(\"\\n✗ Some backups failed. Check logs above.\")\n",
        "        \n",
        "        return success\n",
        "\n",
        "# Example rclone config template\n",
        "RCLONE_CONFIG_TEMPLATE = \"\"\"\n",
        "# To configure rclone for Google Drive:\n",
        "# 1. Run: rclone config\n",
        "# 2. Choose 'n' for new remote\n",
        "# 3. Name it 'gdrive'\n",
        "# 4. Choose type 'drive' (Google Drive)\n",
        "# 5. Follow the authentication flow\n",
        "# \n",
        "# Or paste your existing rclone config below:\n",
        "# \n",
        "# [gdrive]\n",
        "# type = drive\n",
        "# client_id = \n",
        "# client_secret = \n",
        "# scope = drive\n",
        "# token = {\"access_token\":\"xxx\",\"token_type\":\"Bearer\",\"refresh_token\":\"xxx\",\"expiry\":\"xxx\"}\n",
        "# team_drive = \n",
        "\"\"\"\n",
        "\n",
        "print(\"Rclone backup manager implemented!\")\n",
        "print(RCLONE_CONFIG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3f43118",
      "metadata": {},
      "source": [
        "## Multi-GPU Support\n",
        "\n",
        "Enable distributed training across multiple GPUs (Kaggle T4 x2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "72f0a55c",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "GPU Configuration\n",
            "==================================================\n",
            "Number of GPUs detected: 2\n",
            "Using 2 GPUs with MirroredStrategy\n",
            "  GPU 0: /physical_device:GPU:0\n",
            "  GPU 1: /physical_device:GPU:1\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of devices in strategy: 2\n",
            "==================================================\n",
            "\n",
            "   Multi-GPU training enabled with 2 GPUs\n",
            "  Effective batch size will be: 256\n",
            "\n",
            "Current strategy: MirroredStrategy\n"
          ]
        }
      ],
      "source": [
        "def setup_gpu_strategy():\n",
        "    \"\"\"\n",
        "    Setup GPU strategy for single or multi-GPU training.\n",
        "    \n",
        "    Returns:\n",
        "        strategy: TensorFlow distribution strategy\n",
        "        n_gpus: Number of GPUs available\n",
        "    \"\"\"\n",
        "    # Detect GPUs\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    n_gpus = len(gpus)\n",
        "    \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"GPU Configuration\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Number of GPUs detected: {n_gpus}\")\n",
        "    \n",
        "    if n_gpus == 0:\n",
        "        print(\"No GPU detected. Using CPU.\")\n",
        "        strategy = tf.distribute.get_strategy()  # Default strategy\n",
        "        \n",
        "    elif n_gpus == 1:\n",
        "        print(f\"Using single GPU: {gpus[0].name}\")\n",
        "        # Enable memory growth to avoid OOM errors\n",
        "        try:\n",
        "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        except:\n",
        "            pass\n",
        "        strategy = tf.distribute.get_strategy()  # Default strategy for single GPU\n",
        "        \n",
        "    else:\n",
        "        print(f\"Using {n_gpus} GPUs with MirroredStrategy\")\n",
        "        for i, gpu in enumerate(gpus):\n",
        "            print(f\"  GPU {i}: {gpu.name}\")\n",
        "            try:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        # Use MirroredStrategy for multi-GPU training\n",
        "        strategy = tf.distribute.MirroredStrategy()\n",
        "        print(f\"Number of devices in strategy: {strategy.num_replicas_in_sync}\")\n",
        "    \n",
        "    print(f\"{'='*50}\\n\")\n",
        "    \n",
        "    return strategy, n_gpus\n",
        "\n",
        "\n",
        "def build_ca_crnn_model_distributed(input_shape, n_classes=2, time_steps=4, strategy=None):\n",
        "    \"\"\"\n",
        "    Build CA-CRNN model with multi-GPU support.\n",
        "    \n",
        "    Args:\n",
        "        input_shape: Input shape\n",
        "        n_classes: Number of classes\n",
        "        time_steps: Time steps\n",
        "        strategy: TensorFlow distribution strategy\n",
        "        \n",
        "    Returns:\n",
        "        Compiled model\n",
        "    \"\"\"\n",
        "    if strategy is None:\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "    \n",
        "    with strategy.scope():\n",
        "        model = build_ca_crnn_model(input_shape, n_classes, time_steps)\n",
        "        model = compile_model(model, n_classes, config.LEARNING_RATE)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "# Test GPU setup\n",
        "strategy, n_gpus = setup_gpu_strategy()\n",
        "\n",
        "if n_gpus > 1:\n",
        "    print(f\"   Multi-GPU training enabled with {n_gpus} GPUs\")\n",
        "    print(f\"  Effective batch size will be: {config.BATCH_SIZE * n_gpus}\")\n",
        "elif n_gpus == 1:\n",
        "    print(f\"   Single GPU training enabled\")\n",
        "else:\n",
        "    print(f\"    CPU training (slower)\")\n",
        "\n",
        "print(f\"\\nCurrent strategy: {strategy.__class__.__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "616ac91f",
      "metadata": {},
      "source": [
        "## Main Execution Workflow\n",
        "\n",
        "Complete pipeline to load data, train models, visualize results, and backup to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "d280a723",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing components...\n",
            "   All components initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initialize components\n",
        "print(\"Initializing components...\")\n",
        "\n",
        "# Create instances\n",
        "dataset_loader = DatasetLoader(config)\n",
        "training_manager = TrainingManager(config)\n",
        "visualizer = Visualizer(config)\n",
        "backup_manager = RcloneBackup(config)\n",
        "\n",
        "print(\"   All components initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "b3b97ee3",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading DEAP dataset - Subject 1...\n",
            "\n",
            "   Data loaded successfully!\n",
            "  Features shape: (4760, 4, 8, 9, 8)\n",
            "  Valence labels: (4760,)\n",
            "  Arousal labels: (4760,)\n",
            "  Class distribution (Valence): [4046  714]\n",
            "  Class distribution (Arousal): [3451 1309]\n",
            "\n",
            "Visualizing sample 4D feature...\n",
            "\n",
            "   Data loaded successfully!\n",
            "  Features shape: (4760, 4, 8, 9, 8)\n",
            "  Valence labels: (4760,)\n",
            "  Arousal labels: (4760,)\n",
            "  Class distribution (Valence): [4046  714]\n",
            "  Class distribution (Arousal): [3451 1309]\n",
            "\n",
            "Visualizing sample 4D feature...\n",
            "Saved plot to ./visualizations/feature_maps_sample.png\n",
            "Saved plot to ./visualizations/feature_maps_sample.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x1000 with 32 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load DEAP data for subject 1 (example)\n",
        "print(\"Loading DEAP dataset - Subject 1...\")\n",
        "\n",
        "features, valence_labels, arousal_labels = dataset_loader.load_deap_subject(subject_id=1)\n",
        "\n",
        "if features is not None:\n",
        "    print(f\"\\n   Data loaded successfully!\")\n",
        "    print(f\"  Features shape: {features.shape}\")\n",
        "    print(f\"  Valence labels: {valence_labels.shape}\")\n",
        "    print(f\"  Arousal labels: {arousal_labels.shape}\")\n",
        "    print(f\"  Class distribution (Valence): {np.bincount(valence_labels)}\")\n",
        "    print(f\"  Class distribution (Arousal): {np.bincount(arousal_labels)}\")\n",
        "    \n",
        "    # Visualize a sample feature\n",
        "    print(\"\\nVisualizing sample 4D feature...\")\n",
        "    visualizer.plot_feature_maps(features[0], title='Sample 4D EEG Feature - DEAP Subject 1')\n",
        "else:\n",
        "    print(\"✗ Failed to load data. Check dataset path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c327b4",
      "metadata": {},
      "source": [
        "### Backup Results to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "91367e8b",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rclone config written to /root/.config/rclone/rclone.conf\n",
            "⚠ IMPORTANT: Configure rclone before backing up to Google Drive\n",
            "\n",
            "Option 1: Manual configuration\n",
            "  Run: !rclone config\n",
            "\n",
            "Option 2: Use existing config\n",
            "  Uncomment the code block above and paste your rclone config\n",
            "\n",
            "After configuration, run the backup:\n"
          ]
        }
      ],
      "source": [
        "# Setup rclone configuration (IMPORTANT: Add your config)\n",
        "# Replace with your actual rclone configuration\n",
        "\n",
        "\n",
        "\n",
        "rclone_config = '''\n",
        "Put your rclone config content here\n",
        "'''\n",
        "\n",
        "backup_manager.setup_rclone_config(rclone_config)\n",
        "\n",
        "\n",
        "print(\"    IMPORTANT: Configure rclone before backing up to Google Drive\")\n",
        "print(\"\\nOption 1: Manual configuration\")\n",
        "print(\"  Run: !rclone config\")\n",
        "print(\"\\nOption 2: Use existing config\")\n",
        "print(\"  Uncomment the code block above and paste your rclone config\")\n",
        "print(\"\\nAfter configuration, run the backup:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "15f301bc",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting backup to Google Drive...\n",
            "\n",
            "==================================================\n",
            "Starting backup to Google Drive...\n",
            "==================================================\n",
            "\n",
            "Uploading ./checkpoints to gdrive:CA-CRNN-EEG/checkpoints...\n",
            "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Elapsed time:         0.2s\n",
            "   Successfully uploaded to Google Drive\n",
            "Uploading ./output to gdrive:CA-CRNN-EEG/outputs...\n",
            "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Elapsed time:         0.2s\n",
            "   Successfully uploaded to Google Drive\n",
            "Uploading ./output to gdrive:CA-CRNN-EEG/outputs...\n",
            "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 1, 0%\n",
            "Elapsed time:         0.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:  0% /0, 0/s, -Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 1, 0%\n",
            "Elapsed time:         0.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:  0% /0, 0/s, -Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 1, 0%\n",
            "Elapsed time:         1.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:  0% /0, 0/s, -Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 1, 0%\n",
            "Elapsed time:         1.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:  0% /0, 0/s, -Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 1, 0%\n",
            "Elapsed time:         1.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:  0% /0, 0/s, -Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 1, 0%\n",
            "Elapsed time:         1.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:  0% /0, 0/s, -Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            1 / 1, 100%\n",
            "Elapsed time:         1.7s\n",
            "   Successfully uploaded to Google Drive\n",
            "Uploading ./visualizations to gdrive:CA-CRNN-EEG/visualizations...\n",
            "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            1 / 1, 100%\n",
            "Elapsed time:         1.7s\n",
            "   Successfully uploaded to Google Drive\n",
            "Uploading ./visualizations to gdrive:CA-CRNN-EEG/visualizations...\n",
            "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                 3 / 4, 75%, Listed 8\n",
            "Elapsed time:         0.4s\n",
            "Checking:\n",
            " *                       feature_maps_sample.png: checkingTransferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                 3 / 4, 75%, Listed 8\n",
            "Elapsed time:         0.4s\n",
            "Checking:\n",
            " *                       feature_maps_sample.png: checkingTransferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                 3 / 4, 75%, Listed 8\n",
            "Elapsed time:         1.0s\n",
            "Checking:\n",
            " *                       feature_maps_sample.png: checkingTransferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                 3 / 4, 75%, Listed 8\n",
            "Elapsed time:         1.0s\n",
            "Checking:\n",
            " *                       feature_maps_sample.png: checkingTransferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Elapsed time:         1.2s\n",
            "   Successfully uploaded to Google Drive\n",
            "\n",
            "   All backups completed successfully!\n",
            "Backup code ready. Configure rclone and uncomment to run.\n",
            "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Elapsed time:         1.2s\n",
            "   Successfully uploaded to Google Drive\n",
            "\n",
            "   All backups completed successfully!\n",
            "Backup code ready. Configure rclone and uncomment to run.\n"
          ]
        }
      ],
      "source": [
        "# Backup all results to Google Drive (run after training)\n",
        "# UNCOMMENT AFTER CONFIGURING RCLONE\n",
        "\n",
        "print(\"Starting backup to Google Drive...\")\n",
        "backup_manager.backup_all()\n",
        "\n",
        "print(\"Backup code ready. Configure rclone and uncomment to run.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9cfa0dd",
      "metadata": {},
      "source": [
        "## Quick Test: SEED-IV Data Loader\n",
        "\n",
        "Test the SEED-IV data loader with the fixed file structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "7c41addd",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Test SEED-IV data loader\n",
        "print(\"Testing SEED-IV Data Loader\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Try loading Subject 1, Session 1\n",
        "print(\"\\n    Loading Subject 1, Session 1...\")\n",
        "seed_features, seed_labels = dataset_loader.load_seed_session(1, 1)\n",
        "\n",
        "if seed_features is not None and seed_labels is not None:\n",
        "    print(\"\\n    Successfully loaded SEED-IV data!\")\n",
        "    print(f\"   Features shape: {seed_features.shape}\")\n",
        "    print(f\"   Labels shape: {seed_labels.shape}\")\n",
        "    print(f\"   Number of unique labels: {len(np.unique(seed_labels))}\")\n",
        "    print(f\"   Label distribution:\")\n",
        "    for label in np.unique(seed_labels):\n",
        "        count = np.sum(seed_labels == label)\n",
        "        emotion = ['neutral', 'sad', 'fear', 'happy'][label]\n",
        "        print(f\"     {emotion} ({label}): {count} segments\")\n",
        "    \n",
        "    print(f\"\\n   Expected 4D feature structure:\")\n",
        "    print(f\"     Dimension 1 (samples): {seed_features.shape[0]}\")\n",
        "    print(f\"     Dimension 2 (freq bands): {seed_features.shape[1]}\")\n",
        "    print(f\"     Dimension 3 (height): {seed_features.shape[2]}\")\n",
        "    print(f\"     Dimension 4 (width): {seed_features.shape[3]}\")\n",
        "    print(f\"     Dimension 5 (time*2): {seed_features.shape[4]}\")\n",
        "else:\n",
        "    print(\"\\n    Failed to load SEED-IV data\")\n",
        "    print(\"   Check if the dataset path is correct in Config\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1b6cde4",
      "metadata": {},
      "source": [
        "### Complete Training Pipeline (All Datasets)\n",
        "\n",
        "Uncomment and run this section to train on all datasets and reproduce paper results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b1d5f9",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "STARTING COMPLETE TRAINING PIPELINE\n",
            "======================================================================\n",
            "\n",
            "⚠ This will train on DEAP, SEED-IV, and GAMEEMO datasets\n",
            "  Expected duration: 6-12 hours depending on GPU\n",
            "  Make sure datasets are properly mounted\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "EXPERIMENT 2: SEED-IV Dataset\n",
            "======================================================================\n",
            "\n",
            "Attempting to load SEED-IV data...\n",
            "⚠ Note: SEED-IV loader may need adjustment based on actual file structure\n",
            "Loading: /kaggle/input/seed-iv/eeg_raw_data/1/1_20160518.mat\n",
            "Found 24 trial variables: ['cz_eeg1', 'cz_eeg10', 'cz_eeg11', 'cz_eeg12', 'cz_eeg13']...\n",
            "Found 24 trial variables: ['cz_eeg1', 'cz_eeg10', 'cz_eeg11', 'cz_eeg12', 'cz_eeg13']...\n",
            "Extracted 6702 segments with shape (4, 8, 9, 8)\n",
            "Label distribution: [1754 1638 1591 1719]\n",
            "   Loaded SEED-IV data: (6702, 4, 8, 9, 8)\n",
            "\n",
            "==================================================\n",
            "Training Fold 1/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "Extracted 6702 segments with shape (4, 8, 9, 8)\n",
            "Label distribution: [1754 1638 1591 1719]\n",
            "   Loaded SEED-IV data: (6702, 4, 8, 9, 8)\n",
            "\n",
            "==================================================\n",
            "Training Fold 1/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "\n",
            "Model Architecture:\n",
            "\n",
            "Model Architecture:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CA_CRNN\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"CA_CRNN\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_4d_features (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,735,920</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_4d_features (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ permute (\u001b[38;5;33mPermute\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │     \u001b[38;5;34m1,735,920\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m656,384\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,573,684</span> (9.82 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,573,684\u001b[0m (9.82 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,572,788</span> (9.81 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,572,788\u001b[0m (9.81 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2676 - loss: 1.4234 - top_k_categorical_accuracy: 0.5295\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31022, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31022, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.2677 - loss: 1.4231 - top_k_categorical_accuracy: 0.5296 - val_accuracy: 0.3102 - val_loss: 1.3744 - val_top_k_categorical_accuracy: 0.5690 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2867 - loss: 1.3860 - top_k_categorical_accuracy: 0.5361\n",
            "Epoch 2: val_accuracy improved from 0.31022 to 0.38628, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.31022 to 0.38628, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.2871 - loss: 1.3857 - top_k_categorical_accuracy: 0.5366 - val_accuracy: 0.3863 - val_loss: 1.2988 - val_top_k_categorical_accuracy: 0.6331 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3542 - loss: 1.3157 - top_k_categorical_accuracy: 0.6236\n",
            "Epoch 3: val_accuracy improved from 0.38628 to 0.45190, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.38628 to 0.45190, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.3545 - loss: 1.3153 - top_k_categorical_accuracy: 0.6239 - val_accuracy: 0.4519 - val_loss: 1.2030 - val_top_k_categorical_accuracy: 0.6957 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4069 - loss: 1.2257 - top_k_categorical_accuracy: 0.6825\n",
            "Epoch 4: val_accuracy improved from 0.45190 to 0.49963, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.45190 to 0.49963, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.4074 - loss: 1.2248 - top_k_categorical_accuracy: 0.6829 - val_accuracy: 0.4996 - val_loss: 1.0877 - val_top_k_categorical_accuracy: 0.7621 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5067 - loss: 1.0530 - top_k_categorical_accuracy: 0.7754\n",
            "Epoch 5: val_accuracy improved from 0.49963 to 0.55630, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.49963 to 0.55630, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.5074 - loss: 1.0516 - top_k_categorical_accuracy: 0.7760 - val_accuracy: 0.5563 - val_loss: 1.0002 - val_top_k_categorical_accuracy: 0.8069 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6154 - loss: 0.8481 - top_k_categorical_accuracy: 0.8712\n",
            "Epoch 6: val_accuracy improved from 0.55630 to 0.76734, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.55630 to 0.76734, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.6162 - loss: 0.8465 - top_k_categorical_accuracy: 0.8718 - val_accuracy: 0.7673 - val_loss: 0.5403 - val_top_k_categorical_accuracy: 0.9627 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7534 - loss: 0.5624 - top_k_categorical_accuracy: 0.9598\n",
            "Epoch 7: val_accuracy improved from 0.76734 to 0.84191, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.76734 to 0.84191, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.7538 - loss: 0.5620 - top_k_categorical_accuracy: 0.9599 - val_accuracy: 0.8419 - val_loss: 0.4010 - val_top_k_categorical_accuracy: 0.9881 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8546 - loss: 0.3740 - top_k_categorical_accuracy: 0.9876\n",
            "Epoch 8: val_accuracy improved from 0.84191 to 0.87547, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.84191 to 0.87547, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.8546 - loss: 0.3740 - top_k_categorical_accuracy: 0.9875 - val_accuracy: 0.8755 - val_loss: 0.2853 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8945 - loss: 0.2786 - top_k_categorical_accuracy: 0.9881\n",
            "Epoch 9: val_accuracy improved from 0.87547 to 0.92767, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.87547 to 0.92767, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.8948 - loss: 0.2777 - top_k_categorical_accuracy: 0.9882 - val_accuracy: 0.9277 - val_loss: 0.1726 - val_top_k_categorical_accuracy: 0.9963 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9433 - loss: 0.1553 - top_k_categorical_accuracy: 0.9965\n",
            "Epoch 10: val_accuracy did not improve from 0.92767\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9432 - loss: 0.1557 - top_k_categorical_accuracy: 0.9965 - val_accuracy: 0.9172 - val_loss: 0.2514 - val_top_k_categorical_accuracy: 0.9940 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.92767\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9432 - loss: 0.1557 - top_k_categorical_accuracy: 0.9965 - val_accuracy: 0.9172 - val_loss: 0.2514 - val_top_k_categorical_accuracy: 0.9940 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9500 - loss: 0.1351 - top_k_categorical_accuracy: 0.9969\n",
            "Epoch 11: val_accuracy improved from 0.92767 to 0.96868, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.92767 to 0.96868, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9501 - loss: 0.1349 - top_k_categorical_accuracy: 0.9969 - val_accuracy: 0.9687 - val_loss: 0.0818 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9636 - loss: 0.1095 - top_k_categorical_accuracy: 0.9953\n",
            "Epoch 12: val_accuracy improved from 0.96868 to 0.98285, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.96868 to 0.98285, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9636 - loss: 0.1093 - top_k_categorical_accuracy: 0.9953 - val_accuracy: 0.9828 - val_loss: 0.0453 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9780 - loss: 0.0674 - top_k_categorical_accuracy: 0.9989\n",
            "Epoch 13: val_accuracy did not improve from 0.98285\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9779 - loss: 0.0675 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9709 - val_loss: 0.0813 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.98285\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9779 - loss: 0.0675 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9709 - val_loss: 0.0813 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9733 - loss: 0.0798 - top_k_categorical_accuracy: 0.9989\n",
            "Epoch 14: val_accuracy improved from 0.98285 to 0.99180, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.98285 to 0.99180, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9734 - loss: 0.0798 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9918 - val_loss: 0.0259 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9849 - loss: 0.0449 - top_k_categorical_accuracy: 0.9990\n",
            "Epoch 15: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9849 - loss: 0.0449 - top_k_categorical_accuracy: 0.9990 - val_accuracy: 0.9881 - val_loss: 0.0468 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9849 - loss: 0.0449 - top_k_categorical_accuracy: 0.9990 - val_accuracy: 0.9881 - val_loss: 0.0468 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9894 - loss: 0.0344 - top_k_categorical_accuracy: 0.9994\n",
            "Epoch 16: val_accuracy did not improve from 0.99180\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9894 - loss: 0.0344 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9903 - val_loss: 0.0221 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9894 - loss: 0.0344 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9903 - val_loss: 0.0221 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9898 - loss: 0.0302 - top_k_categorical_accuracy: 0.9995\n",
            "Epoch 17: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9897 - loss: 0.0304 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.9873 - val_loss: 0.0449 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9897 - loss: 0.0304 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.9873 - val_loss: 0.0449 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9854 - loss: 0.0416 - top_k_categorical_accuracy: 0.9993\n",
            "Epoch 18: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9855 - loss: 0.0417 - top_k_categorical_accuracy: 0.9993 - val_accuracy: 0.9896 - val_loss: 0.0316 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9855 - loss: 0.0417 - top_k_categorical_accuracy: 0.9993 - val_accuracy: 0.9896 - val_loss: 0.0316 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9930 - loss: 0.0215 - top_k_categorical_accuracy: 0.9996\n",
            "Epoch 19: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9930 - loss: 0.0216 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9881 - val_loss: 0.0294 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9930 - loss: 0.0216 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9881 - val_loss: 0.0294 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9881 - loss: 0.0443 - top_k_categorical_accuracy: 0.9983\n",
            "Epoch 20: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9880 - loss: 0.0445 - top_k_categorical_accuracy: 0.9983 - val_accuracy: 0.9799 - val_loss: 0.0602 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.99180\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9880 - loss: 0.0445 - top_k_categorical_accuracy: 0.9983 - val_accuracy: 0.9799 - val_loss: 0.0602 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9780 - loss: 0.0695 - top_k_categorical_accuracy: 0.9962\n",
            "Epoch 21: val_accuracy improved from 0.99180 to 0.99254, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.99180 to 0.99254, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9781 - loss: 0.0693 - top_k_categorical_accuracy: 0.9962 - val_accuracy: 0.9925 - val_loss: 0.0275 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9781 - loss: 0.0693 - top_k_categorical_accuracy: 0.9962 - val_accuracy: 0.9925 - val_loss: 0.0275 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9930 - loss: 0.0201 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 22: val_accuracy improved from 0.99254 to 0.99776, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.99254 to 0.99776, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9930 - loss: 0.0201 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9978 - val_loss: 0.0070 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9987 - loss: 0.0074 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 23: val_accuracy did not improve from 0.99776\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.99776\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9987 - loss: 0.0074 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9978 - val_loss: 0.0064 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9987 - loss: 0.0074 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9978 - val_loss: 0.0064 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9978 - loss: 0.0100 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99776\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9979 - loss: 0.0100 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0065 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.99776\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9979 - loss: 0.0100 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0065 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9992 - loss: 0.0047 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 25: val_accuracy improved from 0.99776 to 0.99851, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.99776 to 0.99851, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9992 - loss: 0.0047 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0070 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9994 - loss: 0.0032 - top_k_categorical_accuracy: 0.9996\n",
            "Epoch 26: val_accuracy did not improve from 0.99851\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.99851\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9994 - loss: 0.0032 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9978 - val_loss: 0.0049 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9994 - loss: 0.0032 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9978 - val_loss: 0.0049 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0017 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99851\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0017 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0064 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.99851\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0017 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0064 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9996 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 28: val_accuracy improved from 0.99851 to 0.99925, saving model to ./checkpoints/seed_iv_fold1_best.h5\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.99851 to 0.99925, saving model to ./checkpoints/seed_iv_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9996 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0045 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9999 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9999 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0092 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9999 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0092 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9994 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9994 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0152 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9994 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0152 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9983 - loss: 0.0079 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 31: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9983 - loss: 0.0080 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9911 - val_loss: 0.0265 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9983 - loss: 0.0080 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9911 - val_loss: 0.0265 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9938 - loss: 0.0159 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 32: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9938 - loss: 0.0158 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9918 - val_loss: 0.0358 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9938 - loss: 0.0158 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9918 - val_loss: 0.0358 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9946 - loss: 0.0226 - top_k_categorical_accuracy: 0.9995\n",
            "Epoch 33: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9947 - loss: 0.0224 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.9963 - val_loss: 0.0153 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9947 - loss: 0.0224 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.9963 - val_loss: 0.0153 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9984 - loss: 0.0093 - top_k_categorical_accuracy: 0.9990\n",
            "Epoch 34: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9984 - loss: 0.0092 - top_k_categorical_accuracy: 0.9990 - val_accuracy: 0.9970 - val_loss: 0.0083 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9984 - loss: 0.0092 - top_k_categorical_accuracy: 0.9990 - val_accuracy: 0.9970 - val_loss: 0.0083 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9989 - loss: 0.0037 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9989 - loss: 0.0037 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0079 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9989 - loss: 0.0037 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0079 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9996 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9996 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0025 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9996 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0025 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9997 - loss: 0.0014 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9997 - loss: 0.0014 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0019 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9997 - loss: 0.0014 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0019 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 6.9626e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 7.0035e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0044 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 7.0035e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0044 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9995 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9995 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0036 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9995 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0036 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9998 - loss: 0.0014 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 0.0014 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0051 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 0.0014 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0051 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9990 - loss: 0.0028 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9990 - loss: 0.0027 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0071 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9990 - loss: 0.0027 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0071 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0113 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0113 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9999 - loss: 9.2455e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 9.2520e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0051 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 9.2520e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0051 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9999 - loss: 8.5847e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9999 - loss: 8.8815e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0026 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9999 - loss: 8.8815e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0026 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9994 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9994 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0080 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9994 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0080 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 5.1504e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 5.1588e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0087 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 5.1588e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0087 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9998 - loss: 8.0346e-04 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 47: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 8.1432e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9993 - val_loss: 0.0019 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 8.1432e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9993 - val_loss: 0.0019 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9999 - loss: 7.6904e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 7.6968e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 7.6968e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 6.2500e-05\n",
            "Epoch 49/100\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9997 - loss: 6.9778e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9997 - loss: 7.0270e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0051 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9997 - loss: 7.0270e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0051 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 50/100\n",
            "Epoch 50/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9997 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9997 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0061 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9997 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0061 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 6.2500e-05\n",
            "Epoch 51/100\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 5.9328e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 51: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 5.9827e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0065 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 5.9827e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0065 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 52/100\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9999 - loss: 7.5986e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 52: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 7.6362e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0071 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 52: early stopping\n",
            "Restoring model weights from the end of the best epoch: 37.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 7.6362e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0071 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 52: early stopping\n",
            "Restoring model weights from the end of the best epoch: 37.\n",
            "\n",
            "Fold 1 Results:\n",
            "Validation Accuracy: 99.85%\n",
            "Validation Loss: 0.0026\n",
            "\n",
            "Fold 1 Results:\n",
            "Validation Accuracy: 99.85%\n",
            "Validation Loss: 0.0026\n",
            "\n",
            "==================================================\n",
            "Training Fold 2/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "Training Fold 2/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.2567 - loss: 1.4258 - top_k_categorical_accuracy: 0.5117\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31394, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31394, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.2571 - loss: 1.4253 - top_k_categorical_accuracy: 0.5121 - val_accuracy: 0.3139 - val_loss: 1.3487 - val_top_k_categorical_accuracy: 0.5802 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.3058 - loss: 1.3562 - top_k_categorical_accuracy: 0.5734\n",
            "Epoch 2: val_accuracy improved from 0.31394 to 0.37584, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.31394 to 0.37584, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.3065 - loss: 1.3557 - top_k_categorical_accuracy: 0.5741 - val_accuracy: 0.3758 - val_loss: 1.2813 - val_top_k_categorical_accuracy: 0.6361 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.3769 - loss: 1.2836 - top_k_categorical_accuracy: 0.6385\n",
            "Epoch 3: val_accuracy improved from 0.37584 to 0.46309, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.37584 to 0.46309, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.3775 - loss: 1.2828 - top_k_categorical_accuracy: 0.6392 - val_accuracy: 0.4631 - val_loss: 1.1386 - val_top_k_categorical_accuracy: 0.7047 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4883 - loss: 1.1052 - top_k_categorical_accuracy: 0.7540\n",
            "Epoch 4: val_accuracy improved from 0.46309 to 0.54362, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.46309 to 0.54362, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.4887 - loss: 1.1043 - top_k_categorical_accuracy: 0.7544 - val_accuracy: 0.5436 - val_loss: 1.0031 - val_top_k_categorical_accuracy: 0.7905 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6276 - loss: 0.8473 - top_k_categorical_accuracy: 0.8678\n",
            "Epoch 5: val_accuracy improved from 0.54362 to 0.73751, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.54362 to 0.73751, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.6278 - loss: 0.8464 - top_k_categorical_accuracy: 0.8680 - val_accuracy: 0.7375 - val_loss: 0.5825 - val_top_k_categorical_accuracy: 0.9523 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7169 - loss: 0.5955 - top_k_categorical_accuracy: 0.9491\n",
            "Epoch 6: val_accuracy improved from 0.73751 to 0.77405, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.73751 to 0.77405, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.7173 - loss: 0.5945 - top_k_categorical_accuracy: 0.9492 - val_accuracy: 0.7740 - val_loss: 0.4889 - val_top_k_categorical_accuracy: 0.9635 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8010 - loss: 0.4577 - top_k_categorical_accuracy: 0.9738\n",
            "Epoch 7: val_accuracy improved from 0.77405 to 0.86726, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.77405 to 0.86726, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8013 - loss: 0.4571 - top_k_categorical_accuracy: 0.9738 - val_accuracy: 0.8673 - val_loss: 0.3660 - val_top_k_categorical_accuracy: 0.9769 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8645 - loss: 0.3533 - top_k_categorical_accuracy: 0.9849\n",
            "Epoch 8: val_accuracy improved from 0.86726 to 0.95004, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.86726 to 0.95004, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8650 - loss: 0.3522 - top_k_categorical_accuracy: 0.9849 - val_accuracy: 0.9500 - val_loss: 0.1507 - val_top_k_categorical_accuracy: 0.9933 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9476 - loss: 0.1569 - top_k_categorical_accuracy: 0.9933\n",
            "Epoch 9: val_accuracy did not improve from 0.95004\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9476 - loss: 0.1572 - top_k_categorical_accuracy: 0.9932 - val_accuracy: 0.9359 - val_loss: 0.1679 - val_top_k_categorical_accuracy: 0.9933 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.95004\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9476 - loss: 0.1572 - top_k_categorical_accuracy: 0.9932 - val_accuracy: 0.9359 - val_loss: 0.1679 - val_top_k_categorical_accuracy: 0.9933 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9464 - loss: 0.1658 - top_k_categorical_accuracy: 0.9904\n",
            "Epoch 10: val_accuracy did not improve from 0.95004\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9465 - loss: 0.1657 - top_k_categorical_accuracy: 0.9904 - val_accuracy: 0.9389 - val_loss: 0.1821 - val_top_k_categorical_accuracy: 0.9948 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.95004\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9465 - loss: 0.1657 - top_k_categorical_accuracy: 0.9904 - val_accuracy: 0.9389 - val_loss: 0.1821 - val_top_k_categorical_accuracy: 0.9948 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9676 - loss: 0.0990 - top_k_categorical_accuracy: 0.9964\n",
            "Epoch 11: val_accuracy improved from 0.95004 to 0.95749, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.95004 to 0.95749, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9674 - loss: 0.0993 - top_k_categorical_accuracy: 0.9964 - val_accuracy: 0.9575 - val_loss: 0.1097 - val_top_k_categorical_accuracy: 0.9955 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9648 - loss: 0.0997 - top_k_categorical_accuracy: 0.9950\n",
            "Epoch 12: val_accuracy improved from 0.95749 to 0.97987, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.95749 to 0.97987, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9647 - loss: 0.0998 - top_k_categorical_accuracy: 0.9950 - val_accuracy: 0.9799 - val_loss: 0.0729 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9773 - loss: 0.0736 - top_k_categorical_accuracy: 0.9981\n",
            "Epoch 13: val_accuracy improved from 0.97987 to 0.98956, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.97987 to 0.98956, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9773 - loss: 0.0736 - top_k_categorical_accuracy: 0.9981 - val_accuracy: 0.9896 - val_loss: 0.0331 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9782 - loss: 0.0778 - top_k_categorical_accuracy: 0.9976\n",
            "Epoch 14: val_accuracy did not improve from 0.98956\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9782 - loss: 0.0775 - top_k_categorical_accuracy: 0.9976 - val_accuracy: 0.9866 - val_loss: 0.0552 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.98956\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9782 - loss: 0.0775 - top_k_categorical_accuracy: 0.9976 - val_accuracy: 0.9866 - val_loss: 0.0552 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9877 - loss: 0.0429 - top_k_categorical_accuracy: 0.9989\n",
            "Epoch 15: val_accuracy did not improve from 0.98956\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9877 - loss: 0.0429 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9866 - val_loss: 0.0377 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.98956\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9877 - loss: 0.0429 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9866 - val_loss: 0.0377 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9943 - loss: 0.0228 - top_k_categorical_accuracy: 0.9988\n",
            "Epoch 16: val_accuracy did not improve from 0.98956\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9943 - loss: 0.0229 - top_k_categorical_accuracy: 0.9988 - val_accuracy: 0.9828 - val_loss: 0.0691 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.98956\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9943 - loss: 0.0229 - top_k_categorical_accuracy: 0.9988 - val_accuracy: 0.9828 - val_loss: 0.0691 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9951 - loss: 0.0194 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 17: val_accuracy improved from 0.98956 to 0.99105, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.98956 to 0.99105, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9951 - loss: 0.0195 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9911 - val_loss: 0.0274 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9889 - loss: 0.0351 - top_k_categorical_accuracy: 0.9995\n",
            "Epoch 18: val_accuracy did not improve from 0.99105\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9889 - loss: 0.0352 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.9896 - val_loss: 0.0317 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.99105\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9889 - loss: 0.0352 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.9896 - val_loss: 0.0317 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9885 - loss: 0.0372 - top_k_categorical_accuracy: 0.9989\n",
            "Epoch 19: val_accuracy did not improve from 0.99105\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9885 - loss: 0.0370 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9888 - val_loss: 0.0287 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.99105\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9885 - loss: 0.0370 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9888 - val_loss: 0.0287 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9907 - loss: 0.0310 - top_k_categorical_accuracy: 0.9992\n",
            "Epoch 20: val_accuracy improved from 0.99105 to 0.99254, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.99105 to 0.99254, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9907 - loss: 0.0310 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9925 - val_loss: 0.0238 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9921 - loss: 0.0328 - top_k_categorical_accuracy: 0.9983\n",
            "Epoch 21: val_accuracy did not improve from 0.99254\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9920 - loss: 0.0330 - top_k_categorical_accuracy: 0.9983 - val_accuracy: 0.9791 - val_loss: 0.0546 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.99254\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9920 - loss: 0.0330 - top_k_categorical_accuracy: 0.9983 - val_accuracy: 0.9791 - val_loss: 0.0546 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9873 - loss: 0.0399 - top_k_categorical_accuracy: 0.9992\n",
            "Epoch 22: val_accuracy did not improve from 0.99254\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9874 - loss: 0.0398 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9754 - val_loss: 0.0763 - val_top_k_categorical_accuracy: 0.9963 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.99254\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9874 - loss: 0.0398 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9754 - val_loss: 0.0763 - val_top_k_categorical_accuracy: 0.9963 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9929 - loss: 0.0226 - top_k_categorical_accuracy: 0.9985\n",
            "Epoch 23: val_accuracy did not improve from 0.99254\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.99254\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9930 - loss: 0.0225 - top_k_categorical_accuracy: 0.9985 - val_accuracy: 0.9903 - val_loss: 0.0284 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9930 - loss: 0.0225 - top_k_categorical_accuracy: 0.9985 - val_accuracy: 0.9903 - val_loss: 0.0284 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9956 - loss: 0.0147 - top_k_categorical_accuracy: 0.9996\n",
            "Epoch 24: val_accuracy did not improve from 0.99254\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9956 - loss: 0.0149 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9851 - val_loss: 0.0533 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.99254\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9956 - loss: 0.0149 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9851 - val_loss: 0.0533 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9886 - loss: 0.0359 - top_k_categorical_accuracy: 0.9990\n",
            "Epoch 25: val_accuracy did not improve from 0.99254\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.99254\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9885 - loss: 0.0361 - top_k_categorical_accuracy: 0.9990 - val_accuracy: 0.9754 - val_loss: 0.0683 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9885 - loss: 0.0361 - top_k_categorical_accuracy: 0.9990 - val_accuracy: 0.9754 - val_loss: 0.0683 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9900 - loss: 0.0430 - top_k_categorical_accuracy: 0.9995\n",
            "Epoch 26: val_accuracy improved from 0.99254 to 0.99702, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.99254 to 0.99702, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9901 - loss: 0.0426 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.9970 - val_loss: 0.0096 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9970 - loss: 0.0077 - top_k_categorical_accuracy: 0.9996\n",
            "Epoch 27: val_accuracy did not improve from 0.99702\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.99702\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9971 - loss: 0.0077 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9970 - val_loss: 0.0053 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9971 - loss: 0.0077 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9970 - val_loss: 0.0053 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0023 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 28: val_accuracy improved from 0.99702 to 0.99851, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.99702 to 0.99851, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0023 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0044 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9998 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 29: val_accuracy improved from 0.99851 to 1.00000, saving model to ./checkpoints/seed_iv_fold2_best.h5\n",
            "\n",
            "Epoch 29: val_accuracy improved from 0.99851 to 1.00000, saving model to ./checkpoints/seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9998 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.8511e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9998 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9998 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0043 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9998 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0043 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0011 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0011 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9996 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9996 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0058 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9996 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0058 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9998 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0012 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0012 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 6.6428e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 6.6361e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 8.4122e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 6.6361e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 8.4122e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 5.0441e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 5.0497e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0014 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 5.0497e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0014 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9998 - loss: 6.8361e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 6.8673e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0012 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 6.8673e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0012 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9995 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9995 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9955 - val_loss: 0.0179 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9995 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9955 - val_loss: 0.0179 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9978 - loss: 0.0061 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9977 - loss: 0.0064 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9955 - val_loss: 0.0088 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9977 - loss: 0.0064 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9955 - val_loss: 0.0088 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9944 - loss: 0.0234 - top_k_categorical_accuracy: 0.9985\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9943 - loss: 0.0235 - top_k_categorical_accuracy: 0.9985 - val_accuracy: 0.9858 - val_loss: 0.0375 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9943 - loss: 0.0235 - top_k_categorical_accuracy: 0.9985 - val_accuracy: 0.9858 - val_loss: 0.0375 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9943 - loss: 0.0237 - top_k_categorical_accuracy: 0.9989\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9943 - loss: 0.0234 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9985 - val_loss: 0.0050 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9943 - loss: 0.0234 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9985 - val_loss: 0.0050 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9994 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9994 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0022 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9994 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0022 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9993 - loss: 0.0024 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9993 - loss: 0.0024 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0098 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9993 - loss: 0.0024 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0098 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0032 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0032 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9995 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9995 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0032 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9995 - loss: 0.0018 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0032 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9996 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9996 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0051 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9996 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0051 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 6.1805e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 6.1948e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0053 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 6.1948e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0053 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 7.0304e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 7.0577e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0020 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 7.0577e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0020 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 9.2611e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 9.3820e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0023 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 9.3820e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0023 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 6.5227e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 6.5313e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0067 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 49: early stopping\n",
            "Restoring model weights from the end of the best epoch: 34.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 6.5313e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0067 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 49: early stopping\n",
            "Restoring model weights from the end of the best epoch: 34.\n",
            "\n",
            "Fold 2 Results:\n",
            "Validation Accuracy: 99.85%\n",
            "Validation Loss: 0.0019\n",
            "\n",
            "Fold 2 Results:\n",
            "Validation Accuracy: 99.85%\n",
            "Validation Loss: 0.0019\n",
            "\n",
            "==================================================\n",
            "Training Fold 3/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "Training Fold 3/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.2565 - loss: 1.4217 - top_k_categorical_accuracy: 0.5220\n",
            "Epoch 1: val_accuracy improved from -inf to 0.33358, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.33358, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 167ms/step - accuracy: 0.2566 - loss: 1.4214 - top_k_categorical_accuracy: 0.5221 - val_accuracy: 0.3336 - val_loss: 1.3626 - val_top_k_categorical_accuracy: 0.5910 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.3227 - loss: 1.3607 - top_k_categorical_accuracy: 0.5812\n",
            "Epoch 2: val_accuracy improved from 0.33358 to 0.36343, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.33358 to 0.36343, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.3232 - loss: 1.3602 - top_k_categorical_accuracy: 0.5817 - val_accuracy: 0.3634 - val_loss: 1.3092 - val_top_k_categorical_accuracy: 0.6343 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3583 - loss: 1.3131 - top_k_categorical_accuracy: 0.6275\n",
            "Epoch 3: val_accuracy improved from 0.36343 to 0.42537, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.36343 to 0.42537, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.3587 - loss: 1.3125 - top_k_categorical_accuracy: 0.6279 - val_accuracy: 0.4254 - val_loss: 1.2261 - val_top_k_categorical_accuracy: 0.7022 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4282 - loss: 1.1873 - top_k_categorical_accuracy: 0.6997\n",
            "Epoch 4: val_accuracy improved from 0.42537 to 0.53806, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.42537 to 0.53806, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.4290 - loss: 1.1861 - top_k_categorical_accuracy: 0.7002 - val_accuracy: 0.5381 - val_loss: 0.9546 - val_top_k_categorical_accuracy: 0.8157 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5742 - loss: 0.9180 - top_k_categorical_accuracy: 0.8209\n",
            "Epoch 5: val_accuracy improved from 0.53806 to 0.68955, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.53806 to 0.68955, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.5746 - loss: 0.9174 - top_k_categorical_accuracy: 0.8212 - val_accuracy: 0.6896 - val_loss: 0.7211 - val_top_k_categorical_accuracy: 0.9299 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7256 - loss: 0.6403 - top_k_categorical_accuracy: 0.9389\n",
            "Epoch 6: val_accuracy improved from 0.68955 to 0.78582, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.68955 to 0.78582, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.7260 - loss: 0.6391 - top_k_categorical_accuracy: 0.9392 - val_accuracy: 0.7858 - val_loss: 0.5514 - val_top_k_categorical_accuracy: 0.9657 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8035 - loss: 0.4636 - top_k_categorical_accuracy: 0.9760\n",
            "Epoch 7: val_accuracy improved from 0.78582 to 0.85970, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.78582 to 0.85970, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8037 - loss: 0.4635 - top_k_categorical_accuracy: 0.9760 - val_accuracy: 0.8597 - val_loss: 0.3544 - val_top_k_categorical_accuracy: 0.9858 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8819 - loss: 0.3120 - top_k_categorical_accuracy: 0.9914\n",
            "Epoch 8: val_accuracy improved from 0.85970 to 0.94104, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.85970 to 0.94104, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.8824 - loss: 0.3108 - top_k_categorical_accuracy: 0.9915 - val_accuracy: 0.9410 - val_loss: 0.1692 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9463 - loss: 0.1689 - top_k_categorical_accuracy: 0.9950\n",
            "Epoch 9: val_accuracy improved from 0.94104 to 0.95896, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.94104 to 0.95896, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9461 - loss: 0.1693 - top_k_categorical_accuracy: 0.9950 - val_accuracy: 0.9590 - val_loss: 0.1212 - val_top_k_categorical_accuracy: 0.9933 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9649 - loss: 0.1095 - top_k_categorical_accuracy: 0.9947\n",
            "Epoch 10: val_accuracy improved from 0.95896 to 0.97313, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.95896 to 0.97313, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9649 - loss: 0.1094 - top_k_categorical_accuracy: 0.9947 - val_accuracy: 0.9731 - val_loss: 0.0751 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9678 - loss: 0.1068 - top_k_categorical_accuracy: 0.9956\n",
            "Epoch 11: val_accuracy improved from 0.97313 to 0.98806, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.97313 to 0.98806, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9679 - loss: 0.1064 - top_k_categorical_accuracy: 0.9956 - val_accuracy: 0.9881 - val_loss: 0.0415 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9823 - loss: 0.0649 - top_k_categorical_accuracy: 0.9975\n",
            "Epoch 12: val_accuracy did not improve from 0.98806\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9824 - loss: 0.0648 - top_k_categorical_accuracy: 0.9975 - val_accuracy: 0.9761 - val_loss: 0.0960 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.98806\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9824 - loss: 0.0648 - top_k_categorical_accuracy: 0.9975 - val_accuracy: 0.9761 - val_loss: 0.0960 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9689 - loss: 0.1027 - top_k_categorical_accuracy: 0.9949\n",
            "Epoch 13: val_accuracy did not improve from 0.98806\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9691 - loss: 0.1022 - top_k_categorical_accuracy: 0.9949 - val_accuracy: 0.9866 - val_loss: 0.0422 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.98806\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9691 - loss: 0.1022 - top_k_categorical_accuracy: 0.9949 - val_accuracy: 0.9866 - val_loss: 0.0422 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9844 - loss: 0.0567 - top_k_categorical_accuracy: 0.9979\n",
            "Epoch 14: val_accuracy did not improve from 0.98806\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9844 - loss: 0.0566 - top_k_categorical_accuracy: 0.9979 - val_accuracy: 0.9851 - val_loss: 0.0520 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.98806\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9844 - loss: 0.0566 - top_k_categorical_accuracy: 0.9979 - val_accuracy: 0.9851 - val_loss: 0.0520 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9792 - loss: 0.0698 - top_k_categorical_accuracy: 0.9959\n",
            "Epoch 15: val_accuracy improved from 0.98806 to 0.99030, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.98806 to 0.99030, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9792 - loss: 0.0699 - top_k_categorical_accuracy: 0.9959 - val_accuracy: 0.9903 - val_loss: 0.0299 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9904 - loss: 0.0299 - top_k_categorical_accuracy: 0.9991\n",
            "Epoch 16: val_accuracy did not improve from 0.99030\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.99030\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9904 - loss: 0.0299 - top_k_categorical_accuracy: 0.9991 - val_accuracy: 0.9903 - val_loss: 0.0193 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9904 - loss: 0.0299 - top_k_categorical_accuracy: 0.9991 - val_accuracy: 0.9903 - val_loss: 0.0193 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9925 - loss: 0.0213 - top_k_categorical_accuracy: 0.9994\n",
            "Epoch 17: val_accuracy did not improve from 0.99030\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9924 - loss: 0.0216 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9828 - val_loss: 0.0652 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.99030\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9924 - loss: 0.0216 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9828 - val_loss: 0.0652 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9824 - loss: 0.0553 - top_k_categorical_accuracy: 0.9987\n",
            "Epoch 18: val_accuracy improved from 0.99030 to 0.99478, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.99030 to 0.99478, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9825 - loss: 0.0553 - top_k_categorical_accuracy: 0.9987 - val_accuracy: 0.9948 - val_loss: 0.0189 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9959 - loss: 0.0165 - top_k_categorical_accuracy: 0.9992\n",
            "Epoch 19: val_accuracy improved from 0.99478 to 0.99701, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.99478 to 0.99701, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9959 - loss: 0.0165 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9970 - val_loss: 0.0137 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9946 - loss: 0.0213 - top_k_categorical_accuracy: 0.9992\n",
            "Epoch 20: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9945 - loss: 0.0215 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9843 - val_loss: 0.0589 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9945 - loss: 0.0215 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9843 - val_loss: 0.0589 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9947 - loss: 0.0199 - top_k_categorical_accuracy: 0.9989\n",
            "Epoch 21: val_accuracy did not improve from 0.99701\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9947 - loss: 0.0199 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9963 - val_loss: 0.0119 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9947 - loss: 0.0199 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9963 - val_loss: 0.0119 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9966 - loss: 0.0141 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 22: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9965 - loss: 0.0141 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.9955 - val_loss: 0.0133 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9965 - loss: 0.0141 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.9955 - val_loss: 0.0133 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9949 - loss: 0.0172 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 23: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9949 - loss: 0.0172 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9955 - val_loss: 0.0143 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9949 - loss: 0.0172 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9955 - val_loss: 0.0143 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9958 - loss: 0.0144 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 24: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9957 - loss: 0.0149 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.9813 - val_loss: 0.0531 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9957 - loss: 0.0149 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.9813 - val_loss: 0.0531 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9865 - loss: 0.0471 - top_k_categorical_accuracy: 0.9992\n",
            "Epoch 25: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9865 - loss: 0.0469 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9724 - val_loss: 0.0784 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9865 - loss: 0.0469 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9724 - val_loss: 0.0784 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9957 - loss: 0.0188 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99701\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.99701\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9957 - loss: 0.0187 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9963 - val_loss: 0.0189 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9957 - loss: 0.0187 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9963 - val_loss: 0.0189 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9976 - loss: 0.0110 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 27: val_accuracy improved from 0.99701 to 0.99851, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 27: val_accuracy improved from 0.99701 to 0.99851, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9976 - loss: 0.0109 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9985 - val_loss: 0.0046 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9988 - loss: 0.0046 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 28: val_accuracy improved from 0.99851 to 0.99925, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.99851 to 0.99925, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9988 - loss: 0.0046 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0023 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9987 - loss: 0.0052 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 29: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9987 - loss: 0.0052 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9970 - val_loss: 0.0109 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9987 - loss: 0.0052 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9970 - val_loss: 0.0109 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9989 - loss: 0.0048 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9989 - loss: 0.0048 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0035 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9989 - loss: 0.0048 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0035 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9988 - loss: 0.0042 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9988 - loss: 0.0041 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0016 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9988 - loss: 0.0041 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0016 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9990 - loss: 0.0019 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 32: val_accuracy improved from 0.99925 to 1.00000, saving model to ./checkpoints/seed_iv_fold3_best.h5\n",
            "\n",
            "Epoch 32: val_accuracy improved from 0.99925 to 1.00000, saving model to ./checkpoints/seed_iv_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9991 - loss: 0.0019 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.7835e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9997 - loss: 0.0012 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9997 - loss: 0.0012 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.9868e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9997 - loss: 0.0012 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.9868e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9991 - loss: 0.0025 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9991 - loss: 0.0025 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.7340e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9991 - loss: 0.0025 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.7340e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9987 - loss: 0.0042 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9987 - loss: 0.0042 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.5059e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9987 - loss: 0.0042 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.5059e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9992 - loss: 0.0028 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.0029 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 1.0000 - val_loss: 6.1318e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.0029 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 1.0000 - val_loss: 6.1318e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9998 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0039 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0039 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9991 - loss: 0.0030 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9991 - loss: 0.0030 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1448e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9991 - loss: 0.0030 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1448e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9993 - loss: 0.0023 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9993 - loss: 0.0023 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0021 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9993 - loss: 0.0023 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0021 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 4.3793e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 4.3879e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0512e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 4.3879e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0512e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 4.3762e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 4.3731e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.8547e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 4.3731e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.8547e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9998 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9997 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.0773e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9997 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.0773e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 4.0456e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 4.0300e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0006e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 4.0300e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0006e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9997 - loss: 9.0260e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9997 - loss: 9.0555e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.4637e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9997 - loss: 9.0555e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.4637e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 1.9439e-04 - top_k_categorical_accuracy: 1.0000Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9998 - loss: 0.0010 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9998 - loss: 0.0010 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.3157e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9998 - loss: 0.0010 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.3157e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 8.0954e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 8.0357e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.8622e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 8.0357e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.8622e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 4.8782e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 4.8620e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.1807e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 4.8620e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.1807e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.3242e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.3290e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.1842e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.3290e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.1842e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 7.3852e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 7.2941e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.5370e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 7.2941e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.5370e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "Epoch 50/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 3.8993e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.8873e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.8422e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.8873e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.8422e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 1.7228e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 1.7246e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0578e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 1.7246e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0578e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 4.3366e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.3294e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.4939e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.3294e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.4939e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 53/100\n",
            "Epoch 53/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 2.5419e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 2.5408e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.2047e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 2.5408e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.2047e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 54/100\n",
            "Epoch 54/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 2.1291e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 2.1384e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1869e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 2.1384e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1869e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 55/100\n",
            "Epoch 55/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 2.0024e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 2.0047e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.9101e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 2.0047e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.9101e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "Epoch 56/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 3.0490e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 3.0374e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2303e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 3.0374e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2303e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 1.9033e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 1.9179e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.5955e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 1.9179e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.5955e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 58/100\n",
            "Epoch 58/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.7959e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.7975e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.6531e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.7975e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.6531e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 59/100\n",
            "Epoch 59/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9999 - loss: 3.5674e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 3.5822e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.4941e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 3.5822e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.4941e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 60/100\n",
            "Epoch 60/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 2.2603e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.2720e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.1445e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.2720e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.1445e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 61/100\n",
            "Epoch 61/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 2.5417e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.5366e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.0449e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.5366e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.0449e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.7694e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.7724e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.1218e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.7724e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.1218e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 63/100\n",
            "Epoch 63/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 2.2285e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 2.2275e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.7646e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 2.2275e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.7646e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 64/100\n",
            "Epoch 64/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 2.1785e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.1757e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.5211e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.1757e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.5211e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 65/100\n",
            "Epoch 65/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 4.0155e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 3.9850e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.5803e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 3.9850e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.5803e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 66/100\n",
            "Epoch 66/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.9788e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.9794e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.2712e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.9794e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.2712e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9998 - loss: 4.8628e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 4.8919e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.4287e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9998 - loss: 4.8919e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.4287e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 68/100\n",
            "Epoch 68/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.6889e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.6933e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.8299e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.6933e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.8299e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 69/100\n",
            "Epoch 69/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 3.2773e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 3.3954e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.0888e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 3.3954e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.0888e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 70/100\n",
            "Epoch 70/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 2.2195e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.2209e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.1733e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.2209e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.1733e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 1.5318e-04 - top_k_categorical_accuracy: 1.0000Epoch 71/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9999 - loss: 3.9740e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 3.9711e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.4837e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 3.9711e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.4837e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 4.2592e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 4.2269e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.6182e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 4.2269e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.6182e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 73/100\n",
            "Epoch 73/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9997 - loss: 0.0012 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9997 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.0713e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9997 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.0713e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 74/100\n",
            "Epoch 74/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9999 - loss: 3.5418e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 3.5482e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.6334e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 3.5482e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.6334e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 75/100\n",
            "Epoch 75/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9995 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9995 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.9575e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9995 - loss: 0.0011 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.9575e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 76/100\n",
            "Epoch 76/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.6520e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 1.6549e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.4175e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 1.6549e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.4175e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.8574e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.8571e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.3036e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.8571e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.3036e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "Epoch 78/100\n",
            "Epoch 78/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.8801e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.8769e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.0013e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 1.8769e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.0013e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "Epoch 78: early stopping\n",
            "Restoring model weights from the end of the best epoch: 63.\n",
            "Epoch 78: early stopping\n",
            "Restoring model weights from the end of the best epoch: 63.\n",
            "\n",
            "Fold 3 Results:\n",
            "Validation Accuracy: 100.00%\n",
            "Validation Loss: 0.0004\n",
            "\n",
            "Fold 3 Results:\n",
            "Validation Accuracy: 100.00%\n",
            "Validation Loss: 0.0004\n",
            "\n",
            "==================================================\n",
            "Training Fold 4/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "Training Fold 4/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.2584 - loss: 1.4230 - top_k_categorical_accuracy: 0.5061\n",
            "Epoch 1: val_accuracy improved from -inf to 0.30821, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.30821, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 166ms/step - accuracy: 0.2585 - loss: 1.4227 - top_k_categorical_accuracy: 0.5061 - val_accuracy: 0.3082 - val_loss: 1.3709 - val_top_k_categorical_accuracy: 0.5746 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.2920 - loss: 1.3763 - top_k_categorical_accuracy: 0.5474\n",
            "Epoch 2: val_accuracy improved from 0.30821 to 0.35373, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.30821 to 0.35373, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.2923 - loss: 1.3760 - top_k_categorical_accuracy: 0.5480 - val_accuracy: 0.3537 - val_loss: 1.3195 - val_top_k_categorical_accuracy: 0.6351 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.3437 - loss: 1.3259 - top_k_categorical_accuracy: 0.6149\n",
            "Epoch 3: val_accuracy improved from 0.35373 to 0.42687, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.35373 to 0.42687, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.3442 - loss: 1.3253 - top_k_categorical_accuracy: 0.6154 - val_accuracy: 0.4269 - val_loss: 1.2074 - val_top_k_categorical_accuracy: 0.6993 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4292 - loss: 1.2072 - top_k_categorical_accuracy: 0.6975\n",
            "Epoch 4: val_accuracy improved from 0.42687 to 0.55149, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.42687 to 0.55149, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.4300 - loss: 1.2060 - top_k_categorical_accuracy: 0.6983 - val_accuracy: 0.5515 - val_loss: 1.0023 - val_top_k_categorical_accuracy: 0.8090 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5535 - loss: 0.9767 - top_k_categorical_accuracy: 0.8294\n",
            "Epoch 5: val_accuracy improved from 0.55149 to 0.76567, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.55149 to 0.76567, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.5550 - loss: 0.9743 - top_k_categorical_accuracy: 0.8304 - val_accuracy: 0.7657 - val_loss: 0.5742 - val_top_k_categorical_accuracy: 0.9582 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7646 - loss: 0.5758 - top_k_categorical_accuracy: 0.9574\n",
            "Epoch 6: val_accuracy improved from 0.76567 to 0.85597, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.76567 to 0.85597, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.7649 - loss: 0.5754 - top_k_categorical_accuracy: 0.9573 - val_accuracy: 0.8560 - val_loss: 0.3786 - val_top_k_categorical_accuracy: 0.9724 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8973 - loss: 0.2911 - top_k_categorical_accuracy: 0.9838\n",
            "Epoch 7: val_accuracy improved from 0.85597 to 0.95896, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.85597 to 0.95896, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.8977 - loss: 0.2902 - top_k_categorical_accuracy: 0.9838 - val_accuracy: 0.9590 - val_loss: 0.1185 - val_top_k_categorical_accuracy: 0.9948 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9540 - loss: 0.1351 - top_k_categorical_accuracy: 0.9934\n",
            "Epoch 8: val_accuracy improved from 0.95896 to 0.97612, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.95896 to 0.97612, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9541 - loss: 0.1348 - top_k_categorical_accuracy: 0.9934 - val_accuracy: 0.9761 - val_loss: 0.0689 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9652 - loss: 0.1031 - top_k_categorical_accuracy: 0.9967\n",
            "Epoch 9: val_accuracy improved from 0.97612 to 0.98134, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.97612 to 0.98134, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.9652 - loss: 0.1032 - top_k_categorical_accuracy: 0.9966 - val_accuracy: 0.9813 - val_loss: 0.0635 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.9922 - loss: 0.0512 - top_k_categorical_accuracy: 1.0000Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9740 - loss: 0.0831 - top_k_categorical_accuracy: 0.9967\n",
            "Epoch 10: val_accuracy did not improve from 0.98134\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9740 - loss: 0.0832 - top_k_categorical_accuracy: 0.9967 - val_accuracy: 0.9731 - val_loss: 0.0868 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.98134\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9740 - loss: 0.0832 - top_k_categorical_accuracy: 0.9967 - val_accuracy: 0.9731 - val_loss: 0.0868 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9839 - loss: 0.0526 - top_k_categorical_accuracy: 0.9971\n",
            "Epoch 11: val_accuracy did not improve from 0.98134\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.98134\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9837 - loss: 0.0530 - top_k_categorical_accuracy: 0.9971 - val_accuracy: 0.9672 - val_loss: 0.1201 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9837 - loss: 0.0530 - top_k_categorical_accuracy: 0.9971 - val_accuracy: 0.9672 - val_loss: 0.1201 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9745 - loss: 0.0775 - top_k_categorical_accuracy: 0.9956\n",
            "Epoch 12: val_accuracy improved from 0.98134 to 0.99478, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.98134 to 0.99478, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9747 - loss: 0.0772 - top_k_categorical_accuracy: 0.9956 - val_accuracy: 0.9948 - val_loss: 0.0200 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9918 - loss: 0.0329 - top_k_categorical_accuracy: 0.9983\n",
            "Epoch 13: val_accuracy did not improve from 0.99478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9918 - loss: 0.0331 - top_k_categorical_accuracy: 0.9983 - val_accuracy: 0.9925 - val_loss: 0.0218 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.99478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9918 - loss: 0.0331 - top_k_categorical_accuracy: 0.9983 - val_accuracy: 0.9925 - val_loss: 0.0218 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9922 - loss: 0.0276 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 14: val_accuracy did not improve from 0.99478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9922 - loss: 0.0276 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9903 - val_loss: 0.0236 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.99478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9922 - loss: 0.0276 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9903 - val_loss: 0.0236 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9925 - loss: 0.0235 - top_k_categorical_accuracy: 0.9994\n",
            "Epoch 15: val_accuracy did not improve from 0.99478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9925 - loss: 0.0235 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9918 - val_loss: 0.0238 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.99478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9925 - loss: 0.0235 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9918 - val_loss: 0.0238 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9888 - loss: 0.0383 - top_k_categorical_accuracy: 0.9973\n",
            "Epoch 16: val_accuracy did not improve from 0.99478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9888 - loss: 0.0384 - top_k_categorical_accuracy: 0.9973 - val_accuracy: 0.9530 - val_loss: 0.1976 - val_top_k_categorical_accuracy: 0.9933 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.99478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9888 - loss: 0.0384 - top_k_categorical_accuracy: 0.9973 - val_accuracy: 0.9530 - val_loss: 0.1976 - val_top_k_categorical_accuracy: 0.9933 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9823 - loss: 0.0660 - top_k_categorical_accuracy: 0.9977\n",
            "Epoch 17: val_accuracy improved from 0.99478 to 0.99552, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.99478 to 0.99552, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9824 - loss: 0.0656 - top_k_categorical_accuracy: 0.9978 - val_accuracy: 0.9955 - val_loss: 0.0129 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9950 - loss: 0.0149 - top_k_categorical_accuracy: 0.9987\n",
            "Epoch 18: val_accuracy improved from 0.99552 to 0.99627, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.99552 to 0.99627, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9950 - loss: 0.0149 - top_k_categorical_accuracy: 0.9988 - val_accuracy: 0.9963 - val_loss: 0.0079 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9979 - loss: 0.0099 - top_k_categorical_accuracy: 0.9997\n",
            "Epoch 19: val_accuracy did not improve from 0.99627\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9979 - loss: 0.0100 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9948 - val_loss: 0.0131 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.99627\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9979 - loss: 0.0100 - top_k_categorical_accuracy: 0.9997 - val_accuracy: 0.9948 - val_loss: 0.0131 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9945 - loss: 0.0176 - top_k_categorical_accuracy: 0.9994\n",
            "Epoch 20: val_accuracy did not improve from 0.99627\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9945 - loss: 0.0177 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9873 - val_loss: 0.0480 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.99627\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9945 - loss: 0.0177 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9873 - val_loss: 0.0480 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9923 - loss: 0.0213 - top_k_categorical_accuracy: 0.9993\n",
            "Epoch 21: val_accuracy did not improve from 0.99627\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9923 - loss: 0.0215 - top_k_categorical_accuracy: 0.9993 - val_accuracy: 0.9866 - val_loss: 0.0379 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.99627\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9923 - loss: 0.0215 - top_k_categorical_accuracy: 0.9993 - val_accuracy: 0.9866 - val_loss: 0.0379 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9890 - loss: 0.0366 - top_k_categorical_accuracy: 0.9994\n",
            "Epoch 22: val_accuracy did not improve from 0.99627\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9890 - loss: 0.0366 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9866 - val_loss: 0.0501 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.99627\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9890 - loss: 0.0366 - top_k_categorical_accuracy: 0.9994 - val_accuracy: 0.9866 - val_loss: 0.0501 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9934 - loss: 0.0211 - top_k_categorical_accuracy: 0.9993\n",
            "Epoch 23: val_accuracy did not improve from 0.99627\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.99627\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9934 - loss: 0.0211 - top_k_categorical_accuracy: 0.9993 - val_accuracy: 0.9896 - val_loss: 0.0311 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9934 - loss: 0.0211 - top_k_categorical_accuracy: 0.9993 - val_accuracy: 0.9896 - val_loss: 0.0311 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9974 - loss: 0.0121 - top_k_categorical_accuracy: 0.9996\n",
            "Epoch 24: val_accuracy improved from 0.99627 to 0.99701, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.99627 to 0.99701, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9974 - loss: 0.0121 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9970 - val_loss: 0.0082 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9972 - loss: 0.0080 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 25: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9972 - loss: 0.0080 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9955 - val_loss: 0.0133 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9972 - loss: 0.0080 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9955 - val_loss: 0.0133 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9991 - loss: 0.0032 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9991 - loss: 0.0032 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9948 - val_loss: 0.0135 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9991 - loss: 0.0032 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9948 - val_loss: 0.0135 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9989 - loss: 0.0028 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 27: val_accuracy improved from 0.99701 to 0.99925, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 27: val_accuracy improved from 0.99701 to 0.99925, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9989 - loss: 0.0028 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0068 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m 2/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 6.9888e-04 - top_k_categorical_accuracy: 1.0000 Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0010 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0010 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0060 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0010 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0060 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 9.0897e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 9.0932e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0057 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 9.0932e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0057 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 7.5243e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 7.5448e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0050 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 7.5448e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0050 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 6.1997e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 6.1847e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0079 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 6.1847e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0079 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 4.2627e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.2682e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.2682e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 5.6378e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9999 - loss: 5.7402e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0053 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9999 - loss: 5.7402e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0053 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9992 - loss: 0.0025 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9992 - loss: 0.0025 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0018 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9992 - loss: 0.0025 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0018 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9948 - loss: 0.0139 - top_k_categorical_accuracy: 0.9998\n",
            "Epoch 35: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9948 - loss: 0.0139 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.9963 - val_loss: 0.0108 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9948 - loss: 0.0139 - top_k_categorical_accuracy: 0.9998 - val_accuracy: 0.9963 - val_loss: 0.0108 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9976 - loss: 0.0098 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9976 - loss: 0.0098 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9940 - val_loss: 0.0131 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9976 - loss: 0.0098 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9940 - val_loss: 0.0131 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9981 - loss: 0.0068 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 37: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9981 - loss: 0.0068 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9963 - val_loss: 0.0096 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9981 - loss: 0.0068 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9963 - val_loss: 0.0096 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9985 - loss: 0.0048 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9985 - loss: 0.0048 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0073 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9985 - loss: 0.0048 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0073 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9988 - loss: 0.0048 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9988 - loss: 0.0047 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0039 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9988 - loss: 0.0047 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0039 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9983 - loss: 0.0055 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 40: val_accuracy improved from 0.99925 to 1.00000, saving model to ./checkpoints/seed_iv_fold4_best.h5\n",
            "\n",
            "Epoch 40: val_accuracy improved from 0.99925 to 1.00000, saving model to ./checkpoints/seed_iv_fold4_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9983 - loss: 0.0055 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.1999e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 5.9147e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 5.9325e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.7667e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 5.9325e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.7667e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9997 - loss: 0.0015 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9997 - loss: 0.0015 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.8616e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9997 - loss: 0.0015 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.8616e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 6.3338e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 6.2776e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.3152e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 6.2776e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.3152e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9994 - loss: 8.6947e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9994 - loss: 8.6088e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0016 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9994 - loss: 8.6088e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0016 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 4.3645e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.3433e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.3063e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.3433e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.3063e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9998 - loss: 7.5431e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9998 - loss: 7.5107e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0013 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9998 - loss: 7.5107e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0013 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.5747e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.5999e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2156e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.5999e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2156e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 3.0951e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.1000e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.8839e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.1000e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.8839e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9998 - loss: 5.3519e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9998 - loss: 5.3477e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 8.9492e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9998 - loss: 5.3477e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 8.9492e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "Epoch 50/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9999 - loss: 4.3876e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9999 - loss: 4.4848e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9999 - loss: 4.4848e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0042 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9994 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9994 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.3237e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9994 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.3237e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 52/100\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 4.1387e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.1422e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.7798e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.1422e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.7798e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 53/100\n",
            "Epoch 53/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 6.9011e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 6.8786e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 8.2095e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 6.8786e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 8.2095e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 54/100\n",
            "Epoch 54/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9998 - loss: 4.9023e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9998 - loss: 4.9063e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0018 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9998 - loss: 4.9063e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0018 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 55/100\n",
            "Epoch 55/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 6.8523e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 6.7895e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0068 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 6.7895e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0068 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9998 - loss: 4.6351e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 4.6218e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.6756e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 4.6218e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.6756e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 57/100\n",
            "Epoch 57/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9997 - loss: 9.7500e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9997 - loss: 9.6718e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.4555e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9997 - loss: 9.6718e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.4555e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 58/100\n",
            "Epoch 58/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.9915e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.9951e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0019 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.9951e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0019 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 59/100\n",
            "Epoch 59/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9999 - loss: 5.4010e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9999 - loss: 5.4144e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.6673e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9999 - loss: 5.4144e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.6673e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 60/100\n",
            "Epoch 60/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 4.1492e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 4.1301e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.6800e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 4.1301e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.6800e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.9303e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.9379e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0639e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.9379e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0639e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 62/100\n",
            "Epoch 62/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9999 - loss: 3.9382e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9999 - loss: 3.9589e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.5231e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9999 - loss: 3.9589e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.5231e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.4708e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.4718e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.1320e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.4718e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.1320e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 64/100\n",
            "Epoch 64/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 4.6477e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.6180e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 7.6416e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 4.6180e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 7.6416e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 65/100\n",
            "Epoch 65/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.6755e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.6717e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 8.3041e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.6717e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 8.3041e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.3128e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.3189e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.2561e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.3189e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.2561e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 67/100\n",
            "Epoch 67/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.7797e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.8010e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0040 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.8010e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0040 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 68/100\n",
            "Epoch 68/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 1.7488e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 1.7540e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.6991e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 1.7540e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.6991e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 69/100\n",
            "Epoch 69/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.0959e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.0877e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.0877e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 70/100\n",
            "Epoch 70/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.2110e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.2120e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.2858e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.2120e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.2858e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 3.1800e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 3.1717e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 7.5996e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 3.1717e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 7.5996e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 72/100\n",
            "Epoch 72/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.4284e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.4376e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.3422e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.4376e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.3422e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 73/100\n",
            "Epoch 73/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9998 - loss: 4.1859e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 4.2108e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.3634e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 4.2108e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.3634e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 74/100\n",
            "Epoch 74/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 1.6218e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 1.6355e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.5471e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 1.6355e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.5471e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 75/100\n",
            "Epoch 75/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.0723e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.0823e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.1639e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.0823e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.1639e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.9063e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.3603e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.3747e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.5474e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.3747e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.5474e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "Epoch 77/100\n",
            "Epoch 77/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9997 - loss: 4.6052e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9997 - loss: 4.5825e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 6.3174e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9997 - loss: 4.5825e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 6.3174e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "Epoch 78/100\n",
            "Epoch 78/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 1.9912e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.0001e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 6.7436e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.0001e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 6.7436e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "Epoch 79/100\n",
            "Epoch 79/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9998 - loss: 5.9744e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 5.9598e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.1618e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 5.9598e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.1618e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "Epoch 80/100\n",
            "Epoch 80/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.2981e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 80: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 80: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.3027e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0011 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.3027e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0011 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.9531e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 3.3536e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.3598e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.5392e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.3598e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.5392e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "Epoch 82/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.7404e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.7277e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 7.4203e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.7277e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 7.4203e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "Epoch 83/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 3.9792e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 3.9564e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.6015e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 3.9564e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.6015e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "Epoch 84/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.8945e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.8817e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0015 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.8817e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0015 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "Epoch 85/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.3366e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.3547e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.4920e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.3547e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.4920e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "Epoch 86/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 1.8659e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 1.8798e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 8.0505e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 1.8798e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 8.0505e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "Epoch 87/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.2863e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.2907e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0014 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.2907e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0014 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "Epoch 88/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.9088e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.8962e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.3438e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.8962e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.3438e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "Epoch 89/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9996 - loss: 7.2071e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9996 - loss: 7.2158e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0777e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 89: early stopping\n",
            "Restoring model weights from the end of the best epoch: 74.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9996 - loss: 7.2158e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.0777e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.0000e-06\n",
            "Epoch 89: early stopping\n",
            "Restoring model weights from the end of the best epoch: 74.\n",
            "\n",
            "Fold 4 Results:\n",
            "Validation Accuracy: 100.00%\n",
            "Validation Loss: 0.0000\n",
            "\n",
            "Fold 4 Results:\n",
            "Validation Accuracy: 100.00%\n",
            "Validation Loss: 0.0000\n",
            "\n",
            "==================================================\n",
            "Training Fold 5/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "Training Fold 5/5 - seed_iv\n",
            "==================================================\n",
            "\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.2695 - loss: 1.4212 - top_k_categorical_accuracy: 0.5159\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31642, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31642, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 178ms/step - accuracy: 0.2696 - loss: 1.4210 - top_k_categorical_accuracy: 0.5159 - val_accuracy: 0.3164 - val_loss: 1.3733 - val_top_k_categorical_accuracy: 0.5522 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2695 - loss: 1.3896 - top_k_categorical_accuracy: 0.5272\n",
            "Epoch 2: val_accuracy improved from 0.31642 to 0.37910, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.31642 to 0.37910, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.2702 - loss: 1.3892 - top_k_categorical_accuracy: 0.5278 - val_accuracy: 0.3791 - val_loss: 1.3105 - val_top_k_categorical_accuracy: 0.6500 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - accuracy: 0.3125 - loss: 1.4004 - top_k_categorical_accuracy: 0.5859Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3613 - loss: 1.3225 - top_k_categorical_accuracy: 0.6171\n",
            "Epoch 3: val_accuracy improved from 0.37910 to 0.41642, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.37910 to 0.41642, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.3618 - loss: 1.3218 - top_k_categorical_accuracy: 0.6178 - val_accuracy: 0.4164 - val_loss: 1.2143 - val_top_k_categorical_accuracy: 0.6985 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.4297 - loss: 1.2141 - top_k_categorical_accuracy: 0.7109Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4719 - loss: 1.1535 - top_k_categorical_accuracy: 0.7433\n",
            "Epoch 4: val_accuracy improved from 0.41642 to 0.63209, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.41642 to 0.63209, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.4727 - loss: 1.1519 - top_k_categorical_accuracy: 0.7443 - val_accuracy: 0.6321 - val_loss: 0.8305 - val_top_k_categorical_accuracy: 0.9075 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.5156 - loss: 0.9659 - top_k_categorical_accuracy: 0.8359Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6273 - loss: 0.8282 - top_k_categorical_accuracy: 0.8962\n",
            "Epoch 5: val_accuracy improved from 0.63209 to 0.80299, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.63209 to 0.80299, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.6283 - loss: 0.8264 - top_k_categorical_accuracy: 0.8968 - val_accuracy: 0.8030 - val_loss: 0.4774 - val_top_k_categorical_accuracy: 0.9791 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7732 - loss: 0.5421 - top_k_categorical_accuracy: 0.9601\n",
            "Epoch 6: val_accuracy improved from 0.80299 to 0.86194, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.80299 to 0.86194, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.7739 - loss: 0.5405 - top_k_categorical_accuracy: 0.9604 - val_accuracy: 0.8619 - val_loss: 0.3410 - val_top_k_categorical_accuracy: 0.9873 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - accuracy: 0.8984 - loss: 0.2930 - top_k_categorical_accuracy: 0.9766Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8831 - loss: 0.3179 - top_k_categorical_accuracy: 0.9924\n",
            "Epoch 7: val_accuracy improved from 0.86194 to 0.94030, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.86194 to 0.94030, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.8834 - loss: 0.3171 - top_k_categorical_accuracy: 0.9924 - val_accuracy: 0.9403 - val_loss: 0.1679 - val_top_k_categorical_accuracy: 0.9978 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.9297 - loss: 0.2032 - top_k_categorical_accuracy: 1.0000Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9384 - loss: 0.1786 - top_k_categorical_accuracy: 0.9973\n",
            "Epoch 8: val_accuracy improved from 0.94030 to 0.94478, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.94030 to 0.94478, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9385 - loss: 0.1783 - top_k_categorical_accuracy: 0.9973 - val_accuracy: 0.9448 - val_loss: 0.1530 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9481 - loss: 0.1597 - top_k_categorical_accuracy: 0.9970\n",
            "Epoch 9: val_accuracy did not improve from 0.94478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9481 - loss: 0.1599 - top_k_categorical_accuracy: 0.9970 - val_accuracy: 0.9187 - val_loss: 0.2345 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.94478\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9481 - loss: 0.1599 - top_k_categorical_accuracy: 0.9970 - val_accuracy: 0.9187 - val_loss: 0.2345 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9528 - loss: 0.1502 - top_k_categorical_accuracy: 0.9941\n",
            "Epoch 10: val_accuracy improved from 0.94478 to 0.96866, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.94478 to 0.96866, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9531 - loss: 0.1491 - top_k_categorical_accuracy: 0.9941 - val_accuracy: 0.9687 - val_loss: 0.0998 - val_top_k_categorical_accuracy: 0.9955 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9759 - loss: 0.0762 - top_k_categorical_accuracy: 0.9989\n",
            "Epoch 11: val_accuracy improved from 0.96866 to 0.97015, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.96866 to 0.97015, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9759 - loss: 0.0763 - top_k_categorical_accuracy: 0.9989 - val_accuracy: 0.9701 - val_loss: 0.0807 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9715 - loss: 0.0920 - top_k_categorical_accuracy: 0.9968\n",
            "Epoch 12: val_accuracy improved from 0.97015 to 0.98134, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.97015 to 0.98134, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9714 - loss: 0.0922 - top_k_categorical_accuracy: 0.9968 - val_accuracy: 0.9813 - val_loss: 0.0560 - val_top_k_categorical_accuracy: 0.9985 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0284 - top_k_categorical_accuracy: 1.0000Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9864 - loss: 0.0471 - top_k_categorical_accuracy: 0.9991\n",
            "Epoch 13: val_accuracy improved from 0.98134 to 0.99030, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.98134 to 0.99030, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9863 - loss: 0.0472 - top_k_categorical_accuracy: 0.9991 - val_accuracy: 0.9903 - val_loss: 0.0268 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9868 - loss: 0.0394 - top_k_categorical_accuracy: 0.9992\n",
            "Epoch 14: val_accuracy did not improve from 0.99030\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.99030\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9868 - loss: 0.0395 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9903 - val_loss: 0.0266 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9868 - loss: 0.0395 - top_k_categorical_accuracy: 0.9992 - val_accuracy: 0.9903 - val_loss: 0.0266 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9894 - loss: 0.0316 - top_k_categorical_accuracy: 0.9995\n",
            "Epoch 15: val_accuracy improved from 0.99030 to 0.99328, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.99030 to 0.99328, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9894 - loss: 0.0316 - top_k_categorical_accuracy: 0.9995 - val_accuracy: 0.9933 - val_loss: 0.0194 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9938 - loss: 0.0229 - top_k_categorical_accuracy: 0.9988\n",
            "Epoch 16: val_accuracy did not improve from 0.99328\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9938 - loss: 0.0229 - top_k_categorical_accuracy: 0.9988 - val_accuracy: 0.9933 - val_loss: 0.0257 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.99328\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9938 - loss: 0.0229 - top_k_categorical_accuracy: 0.9988 - val_accuracy: 0.9933 - val_loss: 0.0257 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9814 - loss: 0.0623 - top_k_categorical_accuracy: 0.9969\n",
            "Epoch 17: val_accuracy did not improve from 0.99328\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9813 - loss: 0.0626 - top_k_categorical_accuracy: 0.9969 - val_accuracy: 0.9724 - val_loss: 0.0884 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.99328\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9813 - loss: 0.0626 - top_k_categorical_accuracy: 0.9969 - val_accuracy: 0.9724 - val_loss: 0.0884 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9796 - loss: 0.0581 - top_k_categorical_accuracy: 0.9979\n",
            "Epoch 18: val_accuracy did not improve from 0.99328\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9797 - loss: 0.0579 - top_k_categorical_accuracy: 0.9979 - val_accuracy: 0.9836 - val_loss: 0.0478 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.99328\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9797 - loss: 0.0579 - top_k_categorical_accuracy: 0.9979 - val_accuracy: 0.9836 - val_loss: 0.0478 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9925 - loss: 0.0264 - top_k_categorical_accuracy: 0.9996\n",
            "Epoch 19: val_accuracy did not improve from 0.99328\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9925 - loss: 0.0265 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9776 - val_loss: 0.0792 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.99328\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9925 - loss: 0.0265 - top_k_categorical_accuracy: 0.9996 - val_accuracy: 0.9776 - val_loss: 0.0792 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9877 - loss: 0.0387 - top_k_categorical_accuracy: 0.9985\n",
            "Epoch 20: val_accuracy did not improve from 0.99328\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.99328\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.9877 - loss: 0.0387 - top_k_categorical_accuracy: 0.9985 - val_accuracy: 0.9813 - val_loss: 0.0645 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.9877 - loss: 0.0387 - top_k_categorical_accuracy: 0.9985 - val_accuracy: 0.9813 - val_loss: 0.0645 - val_top_k_categorical_accuracy: 0.9970 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9921 - loss: 0.0269 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 21: val_accuracy improved from 0.99328 to 0.99478, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.99328 to 0.99478, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.9921 - loss: 0.0269 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9948 - val_loss: 0.0188 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.0053 - top_k_categorical_accuracy: 1.0000Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9979 - loss: 0.0089 - top_k_categorical_accuracy: 0.9999\n",
            "Epoch 22: val_accuracy improved from 0.99478 to 0.99701, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.99478 to 0.99701, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9979 - loss: 0.0089 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 0.9970 - val_loss: 0.0093 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 8.5628e-04 - top_k_categorical_accuracy: 1.0000Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9990 - loss: 0.0045 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9990 - loss: 0.0045 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0104 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9990 - loss: 0.0045 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0104 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9984 - loss: 0.0070 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9984 - loss: 0.0069 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0103 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.99701\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9984 - loss: 0.0069 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0103 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9987 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 25: val_accuracy improved from 0.99701 to 0.99776, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.99701 to 0.99776, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9988 - loss: 0.0029 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0074 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9999 - loss: 0.0020 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.99776\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 0.0020 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0110 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.99776\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9999 - loss: 0.0020 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0110 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9995 - loss: 0.0033 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.99776\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9995 - loss: 0.0033 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0115 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.99776\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9995 - loss: 0.0033 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0115 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9994 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.99776\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.99776\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9994 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0052 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9994 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0052 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9998 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 29: val_accuracy improved from 0.99776 to 0.99925, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 29: val_accuracy improved from 0.99776 to 0.99925, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9998 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0019 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m 2/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.8518e-04 - top_k_categorical_accuracy: 1.0000 Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 6.2428e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 6.2522e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0025 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 6.2522e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0025 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9997 - loss: 0.0017 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9997 - loss: 0.0017 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0055 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9997 - loss: 0.0017 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0055 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9994 - loss: 0.0049 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9994 - loss: 0.0050 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9948 - val_loss: 0.0143 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9994 - loss: 0.0050 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9948 - val_loss: 0.0143 - val_top_k_categorical_accuracy: 0.9993 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0019 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0019 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9963 - val_loss: 0.0129 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0019 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9963 - val_loss: 0.0129 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9978 - loss: 0.0090 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9978 - loss: 0.0090 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9940 - val_loss: 0.0261 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9978 - loss: 0.0090 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9940 - val_loss: 0.0261 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9996 - loss: 0.0016 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9996 - loss: 0.0016 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0060 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9996 - loss: 0.0016 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9970 - val_loss: 0.0060 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9992 - loss: 0.0028 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.0028 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0054 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.0028 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0054 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 7.7818e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 7.7907e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0093 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 7.7907e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0093 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 5.1543e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9999 - loss: 5.1838e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0073 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9999 - loss: 5.1838e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0073 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9996 - loss: 8.8556e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.99925\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9996 - loss: 8.8069e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0131 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9996 - loss: 8.8069e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9978 - val_loss: 0.0131 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9994 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9994 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0022 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9994 - loss: 0.0021 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0022 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 4.8128e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 4.9131e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0046 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.99925\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 4.9131e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0046 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 7.3530e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 42: val_accuracy improved from 0.99925 to 1.00000, saving model to ./checkpoints/seed_iv_fold5_best.h5\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.99925 to 1.00000, saving model to ./checkpoints/seed_iv_fold5_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9999 - loss: 7.3685e-04 - top_k_categorical_accuracy: 0.9999 - val_accuracy: 1.0000 - val_loss: 2.9444e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m 2/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 6.5053e-04 - top_k_categorical_accuracy: 1.0000 Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9998 - loss: 6.9382e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 6.9212e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0030 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 6.9212e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0030 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9992 - loss: 0.0025 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.0025 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0013 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.0025 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0013 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9997 - loss: 6.5579e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9997 - loss: 6.5579e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.4062e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9997 - loss: 6.5579e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.4062e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 6.9753e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 6.9789e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.2010e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 6.9789e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.2010e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 3.0058e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.0093e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0028 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.0093e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0028 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9996 - loss: 0.0012 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9996 - loss: 0.0012 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 6.8904e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9996 - loss: 0.0012 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 6.8904e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9998 - loss: 6.9624e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 6.9947e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9998 - loss: 6.9947e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "Epoch 50/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9988 - loss: 0.0020 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9988 - loss: 0.0020 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.5294e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9988 - loss: 0.0020 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.5294e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9995 - loss: 8.2972e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9995 - loss: 8.2251e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.7564e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9995 - loss: 8.2251e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.7564e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9992 - loss: 0.0037 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.0037 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.0518e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.0037 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.0518e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 53/100\n",
            "Epoch 53/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 3.3808e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.3896e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.3896e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0031 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 54/100\n",
            "Epoch 54/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 3.1996e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.2002e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.2002e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9985 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 55/100\n",
            "Epoch 55/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 5.6316e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 5.6018e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.4542e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 5.6018e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.4542e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 2.4962e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 2.4935e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 2.4935e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0033 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 57/100\n",
            "Epoch 57/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.6441e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.6457e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.5790e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.6457e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.5790e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 58/100\n",
            "Epoch 58/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9998 - loss: 6.7090e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9998 - loss: 6.6868e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.2998e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9998 - loss: 6.6868e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.2998e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 59/100\n",
            "Epoch 59/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.8292e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.8260e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0024 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.8260e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0024 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.6336e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.6279e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.5695e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.6279e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.5695e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 3.1184e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.1371e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0012 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 3.1371e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0012 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 62/100\n",
            "Epoch 62/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.2273e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.2259e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0022 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 2.2259e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0022 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 63/100\n",
            "Epoch 63/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9995 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9995 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.5759e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9995 - loss: 0.0013 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.5759e-05 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 64/100\n",
            "Epoch 64/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9996 - loss: 0.0017 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9996 - loss: 0.0017 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.7497e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9996 - loss: 0.0017 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.7497e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 65/100\n",
            "Epoch 65/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9999 - loss: 5.2063e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9999 - loss: 5.2734e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0036 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9999 - loss: 5.2734e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0036 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.0437e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.0443e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0012 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.0443e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 0.9993 - val_loss: 0.0012 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 67/100\n",
            "Epoch 67/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 2.4739e-04 - top_k_categorical_accuracy: 1.0000\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.4752e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.6278e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 1.00000\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 2.4752e-04 - top_k_categorical_accuracy: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.6278e-04 - val_top_k_categorical_accuracy: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 67: early stopping\n",
            "Restoring model weights from the end of the best epoch: 52.\n",
            "Epoch 67: early stopping\n",
            "Restoring model weights from the end of the best epoch: 52.\n",
            "\n",
            "Fold 5 Results:\n",
            "Validation Accuracy: 99.93%\n",
            "Validation Loss: 0.0035\n",
            "\n",
            "Fold 5 Results:\n",
            "Validation Accuracy: 99.93%\n",
            "Validation Loss: 0.0035\n",
            "\n",
            "==================================================\n",
            "Final Results for seed_iv\n",
            "==================================================\n",
            "Mean Accuracy: 99.93% ± 0.07%\n",
            "Fold Accuracies: ['99.85%', '99.85%', '100.00%', '100.00%', '99.93%']\n",
            "\n",
            "==================================================\n",
            "Final Results for seed_iv\n",
            "==================================================\n",
            "Mean Accuracy: 99.93% ± 0.07%\n",
            "Fold Accuracies: ['99.85%', '99.85%', '100.00%', '100.00%', '99.93%']\n",
            "Saved plot to ./visualizations/seed_iv_learning_curves.png\n",
            "Saved plot to ./visualizations/seed_iv_learning_curves.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved plot to ./visualizations/seed_iv_folds_comparison.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "EXPERIMENT COMPLETE - RESULTS SUMMARY\n",
            "======================================================================\n",
            "Saved plot to ./visualizations/overall_results_summary.png\n",
            "Saved plot to ./visualizations/overall_results_summary.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    RESULTS COMPARISON:\n",
            "----------------------------------------------------------------------\n",
            "Task                           Our Result           Paper Result        \n",
            "----------------------------------------------------------------------\n",
            "seed_iv                        99.93±0.07%\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "📤 Final backup to Google Drive...\n",
            "\n",
            "==================================================\n",
            "Starting backup to Google Drive...\n",
            "==================================================\n",
            "\n",
            "Uploading ./checkpoints to gdrive:CA-CRNN-EEG/checkpoints...\n",
            "Transferred:   \t          0 B / 147.852 MiB, 0%, 0 B/s, ETA -\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            0 / 5, 0%\n",
            "Elapsed time:         0.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5:  0% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold1_best.h5:  0% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold3_best.h5:  0% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold2_best.h5:  0% /29.570Mi, 0/s, -Transferred:   \t          0 B / 147.852 MiB, 0%, 0 B/s, ETA -\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            0 / 5, 0%\n",
            "Elapsed time:         0.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5:  0% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold1_best.h5:  0% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold3_best.h5:  0% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold2_best.h5:  0% /29.570Mi, 0/s, -Transferred:   \t       72 MiB / 147.852 MiB, 49%, 71.992 MiB/s, ETA 1s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            0 / 5, 0%\n",
            "Elapsed time:         1.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5: 54% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold1_best.h5: 54% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold3_best.h5: 81% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold2_best.h5: 54% /29.570Mi, 0/s, -Transferred:   \t       72 MiB / 147.852 MiB, 49%, 71.992 MiB/s, ETA 1s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            0 / 5, 0%\n",
            "Elapsed time:         1.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5: 54% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold1_best.h5: 54% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold3_best.h5: 81% /29.570Mi, 0/s, -\n",
            " *                         seed_iv_fold2_best.h5: 54% /29.570Mi, 0/s, -Transferred:   \t  118.282 MiB / 147.852 MiB, 80%, 71.992 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            0 / 5, 0%\n",
            "Elapsed time:         1.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5:100% /29.570Mi, 29.548Mi/s, 0s\n",
            " *                         seed_iv_fold1_best.h5:100% /29.570Mi, 29.569Mi/s, 0s\n",
            " *                         seed_iv_fold3_best.h5:100% /29.570Mi, 29.562Mi/s, 0s\n",
            " *                         seed_iv_fold2_best.h5:100% /29.570Mi, 29.563Mi/s, 0sTransferred:   \t  118.282 MiB / 147.852 MiB, 80%, 71.992 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            0 / 5, 0%\n",
            "Elapsed time:         1.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5:100% /29.570Mi, 29.548Mi/s, 0s\n",
            " *                         seed_iv_fold1_best.h5:100% /29.570Mi, 29.569Mi/s, 0s\n",
            " *                         seed_iv_fold3_best.h5:100% /29.570Mi, 29.562Mi/s, 0s\n",
            " *                         seed_iv_fold2_best.h5:100% /29.570Mi, 29.563Mi/s, 0sTransferred:   \t  118.282 MiB / 147.852 MiB, 80%, 59.137 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            0 / 5, 0%\n",
            "Elapsed time:         2.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5:100% /29.570Mi, 29.548Mi/s, 0s\n",
            " *                         seed_iv_fold1_best.h5:100% /29.570Mi, 29.569Mi/s, 0s\n",
            " *                         seed_iv_fold3_best.h5:100% /29.570Mi, 29.562Mi/s, 0s\n",
            " *                         seed_iv_fold2_best.h5:100% /29.570Mi, 29.563Mi/s, 0sTransferred:   \t  118.282 MiB / 147.852 MiB, 80%, 59.137 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            0 / 5, 0%\n",
            "Elapsed time:         2.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5:100% /29.570Mi, 29.548Mi/s, 0s\n",
            " *                         seed_iv_fold1_best.h5:100% /29.570Mi, 29.569Mi/s, 0s\n",
            " *                         seed_iv_fold3_best.h5:100% /29.570Mi, 29.562Mi/s, 0s\n",
            " *                         seed_iv_fold2_best.h5:100% /29.570Mi, 29.563Mi/s, 0sTransferred:   \t  118.282 MiB / 147.852 MiB, 80%, 59.137 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            1 / 5, 20%\n",
            "Elapsed time:         2.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5:100% /29.570Mi, 14.774Mi/s, 0s\n",
            " *                         seed_iv_fold1_best.h5:100% /29.570Mi, 14.784Mi/s, 0s\n",
            " *                         seed_iv_fold2_best.h5:100% /29.570Mi, 14.782Mi/s, 0s\n",
            " *                         seed_iv_fold4_best.h5:  0% /29.570Mi, 0/s, -Transferred:   \t  118.282 MiB / 147.852 MiB, 80%, 59.137 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            1 / 5, 20%\n",
            "Elapsed time:         2.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold5_best.h5:100% /29.570Mi, 14.774Mi/s, 0s\n",
            " *                         seed_iv_fold1_best.h5:100% /29.570Mi, 14.784Mi/s, 0s\n",
            " *                         seed_iv_fold2_best.h5:100% /29.570Mi, 14.782Mi/s, 0s\n",
            " *                         seed_iv_fold4_best.h5:  0% /29.570Mi, 0/s, -Transferred:   \t  133.434 MiB / 147.852 MiB, 90%, 59.137 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            4 / 5, 80%\n",
            "Elapsed time:         2.9s\n",
            "Transferring:\n",
            " *                         seed_iv_fold4_best.h5: 51% /29.570Mi, 0/s, -Transferred:   \t  133.434 MiB / 147.852 MiB, 90%, 59.137 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            4 / 5, 80%\n",
            "Elapsed time:         2.9s\n",
            "Transferring:\n",
            " *                         seed_iv_fold4_best.h5: 51% /29.570Mi, 0/s, -Transferred:   \t  147.852 MiB / 147.852 MiB, 100%, 44.538 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            4 / 5, 80%\n",
            "Elapsed time:         3.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold4_best.h5:100% /29.570Mi, 29.570Mi/s, 0sTransferred:   \t  147.852 MiB / 147.852 MiB, 100%, 44.538 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            4 / 5, 80%\n",
            "Elapsed time:         3.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold4_best.h5:100% /29.570Mi, 29.570Mi/s, 0sTransferred:   \t  147.852 MiB / 147.852 MiB, 100%, 44.538 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            4 / 5, 80%\n",
            "Elapsed time:         4.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold4_best.h5:100% /29.570Mi, 29.570Mi/s, 0sTransferred:   \t  147.852 MiB / 147.852 MiB, 100%, 44.538 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            4 / 5, 80%\n",
            "Elapsed time:         4.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold4_best.h5:100% /29.570Mi, 29.570Mi/s, 0sTransferred:   \t  147.852 MiB / 147.852 MiB, 100%, 36.961 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            5 / 5, 100%\n",
            "Elapsed time:         4.4s\n",
            "   Successfully uploaded to Google Drive\n",
            "Uploading ./output to gdrive:CA-CRNN-EEG/outputs...\n",
            "Transferred:   \t  147.852 MiB / 147.852 MiB, 100%, 36.961 MiB/s, ETA 0s\n",
            "Checks:                14 / 14, 100%, Listed 28\n",
            "Transferred:            5 / 5, 100%\n",
            "Elapsed time:         4.4s\n",
            "   Successfully uploaded to Google Drive\n",
            "Uploading ./output to gdrive:CA-CRNN-EEG/outputs...\n",
            "Transferred:   \t   27.698 KiB / 82.008 KiB, 34%, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 12, 0%\n",
            "Elapsed time:         0.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:100% /6.834Ki, 0/s, -\n",
            " *                         seed_iv_fold2_log.csv:100% /6.133Ki, 0/s, -\n",
            " *                     seed_iv_fold3_results.pkl:100% /4.985Ki, 0/s, -\n",
            " *                         seed_iv_fold4_log.csv:100% /9.746Ki, 0/s, -Transferred:   \t   27.698 KiB / 82.008 KiB, 34%, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 12, 0%\n",
            "Elapsed time:         0.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:100% /6.834Ki, 0/s, -\n",
            " *                         seed_iv_fold2_log.csv:100% /6.133Ki, 0/s, -\n",
            " *                     seed_iv_fold3_results.pkl:100% /4.985Ki, 0/s, -\n",
            " *                         seed_iv_fold4_log.csv:100% /9.746Ki, 0/s, -Transferred:   \t   27.698 KiB / 82.008 KiB, 34%, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 12, 0%\n",
            "Elapsed time:         1.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:100% /6.834Ki, 0/s, -\n",
            " *                         seed_iv_fold2_log.csv:100% /6.133Ki, 0/s, -\n",
            " *                     seed_iv_fold3_results.pkl:100% /4.985Ki, 0/s, -\n",
            " *                         seed_iv_fold4_log.csv:100% /9.746Ki, 0/s, -Transferred:   \t   27.698 KiB / 82.008 KiB, 34%, 0 B/s, ETA -\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 12, 0%\n",
            "Elapsed time:         1.0s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:100% /6.834Ki, 0/s, -\n",
            " *                         seed_iv_fold2_log.csv:100% /6.133Ki, 0/s, -\n",
            " *                     seed_iv_fold3_results.pkl:100% /4.985Ki, 0/s, -\n",
            " *                         seed_iv_fold4_log.csv:100% /9.746Ki, 0/s, -Transferred:   \t   27.698 KiB / 82.008 KiB, 34%, 27.696 KiB/s, ETA 1s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 12, 0%\n",
            "Elapsed time:         1.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:100% /6.834Ki, 6.833Ki/s, 0s\n",
            " *                         seed_iv_fold2_log.csv:100% /6.133Ki, 6.132Ki/s, 0s\n",
            " *                     seed_iv_fold3_results.pkl:100% /4.985Ki, 4.984Ki/s, 0s\n",
            " *                         seed_iv_fold4_log.csv:100% /9.746Ki, 9.745Ki/s, 0sTransferred:   \t   27.698 KiB / 82.008 KiB, 34%, 27.696 KiB/s, ETA 1s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            0 / 12, 0%\n",
            "Elapsed time:         1.5s\n",
            "Transferring:\n",
            " *                         seed_iv_fold1_log.csv:100% /6.834Ki, 6.833Ki/s, 0s\n",
            " *                         seed_iv_fold2_log.csv:100% /6.133Ki, 6.132Ki/s, 0s\n",
            " *                     seed_iv_fold3_results.pkl:100% /4.985Ki, 4.984Ki/s, 0s\n",
            " *                         seed_iv_fold4_log.csv:100% /9.746Ki, 9.745Ki/s, 0sTransferred:   \t   66.813 KiB / 82.008 KiB, 81%, 27.696 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            4 / 12, 33%\n",
            "Elapsed time:         1.9s\n",
            "Transferring:\n",
            " *                     seed_iv_fold4_results.pkl:100% /5.662Ki, 0/s, -\n",
            " *                     seed_iv_fold5_results.pkl:100% /4.309Ki, 0/s, -\n",
            " *                         seed_iv_fold5_log.csv:100% /7.729Ki, 0/s, -\n",
            " *                   seed_iv_overall_results.pkl:100% /21.416Ki, 0/s, -Transferred:   \t   66.813 KiB / 82.008 KiB, 81%, 27.696 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            4 / 12, 33%\n",
            "Elapsed time:         1.9s\n",
            "Transferring:\n",
            " *                     seed_iv_fold4_results.pkl:100% /5.662Ki, 0/s, -\n",
            " *                     seed_iv_fold5_results.pkl:100% /4.309Ki, 0/s, -\n",
            " *                         seed_iv_fold5_log.csv:100% /7.729Ki, 0/s, -\n",
            " *                   seed_iv_overall_results.pkl:100% /21.416Ki, 0/s, -Transferred:   \t   66.813 KiB / 82.008 KiB, 81%, 33.405 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            4 / 12, 33%\n",
            "Elapsed time:         2.5s\n",
            "Transferring:\n",
            " *                     seed_iv_fold4_results.pkl:100% /5.662Ki, 0/s, -\n",
            " *                     seed_iv_fold5_results.pkl:100% /4.309Ki, 0/s, -\n",
            " *                         seed_iv_fold5_log.csv:100% /7.729Ki, 0/s, -\n",
            " *                   seed_iv_overall_results.pkl:100% /21.416Ki, 0/s, -Transferred:   \t   66.813 KiB / 82.008 KiB, 81%, 33.405 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            4 / 12, 33%\n",
            "Elapsed time:         2.5s\n",
            "Transferring:\n",
            " *                     seed_iv_fold4_results.pkl:100% /5.662Ki, 0/s, -\n",
            " *                     seed_iv_fold5_results.pkl:100% /4.309Ki, 0/s, -\n",
            " *                         seed_iv_fold5_log.csv:100% /7.729Ki, 0/s, -\n",
            " *                   seed_iv_overall_results.pkl:100% /21.416Ki, 0/s, -Transferred:   \t   66.954 KiB / 82.008 KiB, 82%, 22.317 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            5 / 12, 42%\n",
            "Elapsed time:         3.0s\n",
            "Transferring:\n",
            " *                     seed_iv_fold5_results.pkl:100% /4.309Ki, 4.308Ki/s, 0s\n",
            " *                         seed_iv_fold5_log.csv:100% /7.729Ki, 7.728Ki/s, 0s\n",
            " *                   seed_iv_overall_results.pkl:100% /21.416Ki, 21.414Ki/s, 0s\n",
            " *                           seed_iv_results.txt:100% /144, 0/s, -Transferred:   \t   66.954 KiB / 82.008 KiB, 82%, 22.317 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            5 / 12, 42%\n",
            "Elapsed time:         3.0s\n",
            "Transferring:\n",
            " *                     seed_iv_fold5_results.pkl:100% /4.309Ki, 4.308Ki/s, 0s\n",
            " *                         seed_iv_fold5_log.csv:100% /7.729Ki, 7.728Ki/s, 0s\n",
            " *                   seed_iv_overall_results.pkl:100% /21.416Ki, 21.414Ki/s, 0s\n",
            " *                           seed_iv_results.txt:100% /144, 0/s, -Transferred:   \t   82.008 KiB / 82.008 KiB, 100%, 22.317 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            8 / 12, 67%\n",
            "Elapsed time:         3.5s\n",
            "Transferring:\n",
            " *                           seed_iv_results.txt:100% /144, 0/s, -\n",
            " *                     seed_iv_fold1_results.pkl:100% /3.386Ki, 0/s, -\n",
            " *                     seed_iv_fold2_results.pkl:100% /3.201Ki, 0/s, -\n",
            " *                         seed_iv_fold3_log.csv:100% /8.467Ki, 0/s, -Transferred:   \t   82.008 KiB / 82.008 KiB, 100%, 22.317 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            8 / 12, 67%\n",
            "Elapsed time:         3.5s\n",
            "Transferring:\n",
            " *                           seed_iv_results.txt:100% /144, 0/s, -\n",
            " *                     seed_iv_fold1_results.pkl:100% /3.386Ki, 0/s, -\n",
            " *                     seed_iv_fold2_results.pkl:100% /3.201Ki, 0/s, -\n",
            " *                         seed_iv_fold3_log.csv:100% /8.467Ki, 0/s, -Transferred:   \t   82.008 KiB / 82.008 KiB, 100%, 20.501 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            8 / 12, 67%\n",
            "Elapsed time:         4.0s\n",
            "Transferring:\n",
            " *                           seed_iv_results.txt:100% /144, 143/s, 0s\n",
            " *                     seed_iv_fold1_results.pkl:100% /3.386Ki, 0/s, -\n",
            " *                     seed_iv_fold2_results.pkl:100% /3.201Ki, 0/s, -\n",
            " *                         seed_iv_fold3_log.csv:100% /8.467Ki, 0/s, -Transferred:   \t   82.008 KiB / 82.008 KiB, 100%, 20.501 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:            8 / 12, 67%\n",
            "Elapsed time:         4.0s\n",
            "Transferring:\n",
            " *                           seed_iv_results.txt:100% /144, 143/s, 0s\n",
            " *                     seed_iv_fold1_results.pkl:100% /3.386Ki, 0/s, -\n",
            " *                     seed_iv_fold2_results.pkl:100% /3.201Ki, 0/s, -\n",
            " *                         seed_iv_fold3_log.csv:100% /8.467Ki, 0/s, -Transferred:   \t   82.008 KiB / 82.008 KiB, 100%, 20.501 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:           10 / 12, 83%\n",
            "Elapsed time:         4.5s\n",
            "Transferring:\n",
            " *                     seed_iv_fold1_results.pkl:100% /3.386Ki, 3.385Ki/s, 0s\n",
            " *                         seed_iv_fold3_log.csv:100% /8.467Ki, 8.466Ki/s, 0sTransferred:   \t   82.008 KiB / 82.008 KiB, 100%, 20.501 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:           10 / 12, 83%\n",
            "Elapsed time:         4.5s\n",
            "Transferring:\n",
            " *                     seed_iv_fold1_results.pkl:100% /3.386Ki, 3.385Ki/s, 0s\n",
            " *                         seed_iv_fold3_log.csv:100% /8.467Ki, 8.466Ki/s, 0sTransferred:   \t   82.008 KiB / 82.008 KiB, 100%, 20.501 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:           12 / 12, 100%\n",
            "Elapsed time:         4.7s\n",
            "   Successfully uploaded to Google Drive\n",
            "Uploading ./visualizations to gdrive:CA-CRNN-EEG/visualizations...\n",
            "Transferred:   \t   82.008 KiB / 82.008 KiB, 100%, 20.501 KiB/s, ETA 0s\n",
            "Checks:                28 / 28, 100%, Listed 56\n",
            "Transferred:           12 / 12, 100%\n",
            "Elapsed time:         4.7s\n",
            "   Successfully uploaded to Google Drive\n",
            "Uploading ./visualizations to gdrive:CA-CRNN-EEG/visualizations...\n",
            "Transferred:   \t  622.946 KiB / 622.946 KiB, 100%, 0 B/s, ETA -\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            0 / 3, 0%\n",
            "Elapsed time:         0.5s\n",
            "Transferring:\n",
            " *                  seed_iv_folds_comparison.png:100% /221.788Ki, 0/s, -\n",
            " *                   overall_results_summary.png:100% /98.807Ki, 0/s, -\n",
            " *                   seed_iv_learning_curves.png:100% /302.352Ki, 0/s, -Transferred:   \t  622.946 KiB / 622.946 KiB, 100%, 0 B/s, ETA -\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            0 / 3, 0%\n",
            "Elapsed time:         0.5s\n",
            "Transferring:\n",
            " *                  seed_iv_folds_comparison.png:100% /221.788Ki, 0/s, -\n",
            " *                   overall_results_summary.png:100% /98.807Ki, 0/s, -\n",
            " *                   seed_iv_learning_curves.png:100% /302.352Ki, 0/s, -Transferred:   \t  622.946 KiB / 622.946 KiB, 100%, 622.888 KiB/s, ETA 0s\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            0 / 3, 0%\n",
            "Elapsed time:         1.0s\n",
            "Transferring:\n",
            " *                  seed_iv_folds_comparison.png:100% /221.788Ki, 0/s, -\n",
            " *                   overall_results_summary.png:100% /98.807Ki, 0/s, -\n",
            " *                   seed_iv_learning_curves.png:100% /302.352Ki, 0/s, -Transferred:   \t  622.946 KiB / 622.946 KiB, 100%, 622.888 KiB/s, ETA 0s\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            0 / 3, 0%\n",
            "Elapsed time:         1.0s\n",
            "Transferring:\n",
            " *                  seed_iv_folds_comparison.png:100% /221.788Ki, 0/s, -\n",
            " *                   overall_results_summary.png:100% /98.807Ki, 0/s, -\n",
            " *                   seed_iv_learning_curves.png:100% /302.352Ki, 0/s, -Transferred:   \t  622.946 KiB / 622.946 KiB, 100%, 622.888 KiB/s, ETA 0s\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            0 / 3, 0%\n",
            "Elapsed time:         1.4s\n",
            "Transferring:\n",
            " *                  seed_iv_folds_comparison.png:100% /221.788Ki, 221.775Ki/s, 0\n",
            " *                   overall_results_summary.png:100% /98.807Ki, 98.802Ki/s, 0s\n",
            " *                   seed_iv_learning_curves.png:100% /302.352Ki, 302.315Ki/s, 0Transferred:   \t  622.946 KiB / 622.946 KiB, 100%, 622.888 KiB/s, ETA 0s\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            0 / 3, 0%\n",
            "Elapsed time:         1.4s\n",
            "Transferring:\n",
            " *                  seed_iv_folds_comparison.png:100% /221.788Ki, 221.775Ki/s, 0\n",
            " *                   overall_results_summary.png:100% /98.807Ki, 98.802Ki/s, 0s\n",
            " *                   seed_iv_learning_curves.png:100% /302.352Ki, 302.315Ki/s, 0Transferred:   \t  622.946 KiB / 622.946 KiB, 100%, 622.888 KiB/s, ETA 0s\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            1 / 3, 33%\n",
            "Elapsed time:         2.0s\n",
            "Transferring:\n",
            " *                  seed_iv_folds_comparison.png:100% /221.788Ki, 221.775Ki/s, 0\n",
            " *                   overall_results_summary.png:100% /98.807Ki, 98.802Ki/s, 0sTransferred:   \t  622.946 KiB / 622.946 KiB, 100%, 311.443 KiB/s, ETA 0s\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            3 / 3, 100%\n",
            "Elapsed time:         2.1s\n",
            "   Successfully uploaded to Google Drive\n",
            "\n",
            "   All backups completed successfully!\n",
            "\n",
            "    ALL EXPERIMENTS COMPLETED!\n",
            "Total tasks trained: 1\n",
            "Transferred:   \t  622.946 KiB / 622.946 KiB, 100%, 622.888 KiB/s, ETA 0s\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            1 / 3, 33%\n",
            "Elapsed time:         2.0s\n",
            "Transferring:\n",
            " *                  seed_iv_folds_comparison.png:100% /221.788Ki, 221.775Ki/s, 0\n",
            " *                   overall_results_summary.png:100% /98.807Ki, 98.802Ki/s, 0sTransferred:   \t  622.946 KiB / 622.946 KiB, 100%, 311.443 KiB/s, ETA 0s\n",
            "Checks:                 4 / 4, 100%, Listed 8\n",
            "Transferred:            3 / 3, 100%\n",
            "Elapsed time:         2.1s\n",
            "   Successfully uploaded to Google Drive\n",
            "\n",
            "   All backups completed successfully!\n",
            "\n",
            "    ALL EXPERIMENTS COMPLETED!\n",
            "Total tasks trained: 1\n"
          ]
        }
      ],
      "source": [
        "# COMPLETE TRAINING PIPELINE\n",
        "# ===========================\n",
        "# This pipeline trains on DEAP, SEED-IV, and GAMEEMO datasets\n",
        "# \n",
        "# EXPECTED RESULTS (from paper):\n",
        "# - DEAP Arousal: 94.83% ± 1.30%\n",
        "# - DEAP Valence: 94.58% ± 1.31%\n",
        "# - SEED: 94.76% ± 0.18%\n",
        "\n",
        "def run_complete_experiment():\n",
        "    all_results = []\n",
        "    \n",
        "    # =====================================================================\n",
        "    # 1. DEAP DATASET - ALL SUBJECTS\n",
        "    # =====================================================================\n",
        "    # print(\"\\n\" + \"=\"*70)\n",
        "    # print(\"EXPERIMENT 1: DEAP Dataset (All 32 Subjects)\")\n",
        "    # print(\"=\"*70)\n",
        "    \n",
        "    # print(\"\\nLoading DEAP data for all subjects...\")\n",
        "    # deap_data = dataset_loader.load_deap_all_subjects()\n",
        "    \n",
        "    # if deap_data is not None:\n",
        "    #     print(f\"   Loaded {len(deap_data['valence'])} samples\")\n",
        "        \n",
        "    #     # Train on Arousal\n",
        "    #     print(\"\\n--- Training: DEAP Arousal ---\")\n",
        "    #     arousal_results = training_manager.train_with_cross_validation(\n",
        "    #         features=deap_data['features'],\n",
        "    #         labels=deap_data['arousal'],\n",
        "    #         task_name='deap_arousal',\n",
        "    #         n_classes=2,\n",
        "    #         n_folds=config.N_FOLDS\n",
        "    #     )\n",
        "    #     all_results.append(arousal_results)\n",
        "        \n",
        "    #     # Visualizations\n",
        "    #     visualizer.plot_learning_curves_all_folds(arousal_results)\n",
        "    #     visualizer.plot_all_folds_comparison(arousal_results)\n",
        "        \n",
        "    #     # Train on Valence\n",
        "    #     print(\"\\n--- Training: DEAP Valence ---\")\n",
        "    #     valence_results = training_manager.train_with_cross_validation(\n",
        "    #         features=deap_data['features'],\n",
        "    #         labels=deap_data['valence'],\n",
        "    #         task_name='deap_valence',\n",
        "    #         n_classes=2,\n",
        "    #         n_folds=config.N_FOLDS\n",
        "    #     )\n",
        "    #     all_results.append(valence_results)\n",
        "        \n",
        "    #     # Visualizations\n",
        "    #     visualizer.plot_learning_curves_all_folds(valence_results)\n",
        "    #     visualizer.plot_all_folds_comparison(valence_results)\n",
        "        \n",
        "    #     # Backup after DEAP\n",
        "    #     print(\"\\n    Backing up DEAP results...\")\n",
        "    #     backup_manager.backup_all()\n",
        "    # else:\n",
        "    #     print(\"✗ Failed to load DEAP dataset\")\n",
        "    \n",
        "    # =====================================================================\n",
        "    # 2. SEED-IV DATASET\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EXPERIMENT 2: SEED-IV Dataset\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    try:\n",
        "        # Try to load SEED-IV data\n",
        "        # Note: This is a simplified loader - adjust based on actual file structure\n",
        "        print(\"\\nAttempting to load SEED-IV data...\")\n",
        "        print(\"    Note: SEED-IV loader may need adjustment based on actual file structure\")\n",
        "        \n",
        "        # Example: Load first session for first subject\n",
        "        seed_features, seed_labels = dataset_loader.load_seed_session(1, 1)\n",
        "        \n",
        "        if seed_features is not None and seed_labels is not None:\n",
        "            print(f\"   Loaded SEED-IV data: {seed_features.shape}\")\n",
        "            \n",
        "            seed_results = training_manager.train_with_cross_validation(\n",
        "                features=seed_features,\n",
        "                labels=seed_labels,\n",
        "                task_name='seed_iv',\n",
        "                n_classes=config.N_CLASSES_SEED_IV,\n",
        "                n_folds=config.N_FOLDS\n",
        "            )\n",
        "            all_results.append(seed_results)\n",
        "            \n",
        "            visualizer.plot_learning_curves_all_folds(seed_results)\n",
        "            visualizer.plot_all_folds_comparison(seed_results)\n",
        "        else:\n",
        "            print(\"    SEED-IV data not loaded - skipping\")\n",
        "    except Exception as e:\n",
        "        print(f\"    Error loading SEED-IV: {e}\")\n",
        "        print(\"  Skipping SEED-IV training\")\n",
        "    \n",
        "    # =====================================================================\n",
        "    # 3. GAMEEMO DATASET\n",
        "    # # =====================================================================\n",
        "    # print(\"\\n\" + \"=\"*70)\n",
        "    # print(\"EXPERIMENT 3: GAMEEMO Dataset\")\n",
        "    # print(\"=\"*70)\n",
        "    \n",
        "    # try:\n",
        "    #     # GAMEEMO has 28 subjects (S01-S28)\n",
        "    #     gameemo_subjects = [f'S{i:02d}' for i in range(1, 29)]\n",
        "        \n",
        "    #     print(f\"\\nAttempting to load GAMEEMO data for {len(gameemo_subjects)} subjects...\")\n",
        "        \n",
        "    #     # Try to load a few subjects as example\n",
        "    #     gameemo_all_features = []\n",
        "    #     gameemo_all_labels = []\n",
        "        \n",
        "    #     for subject_id in gameemo_subjects[:5]:  # Start with first 5 subjects\n",
        "    #         print(f\"  Loading {subject_id}...\")\n",
        "    #         features, labels = dataset_loader.load_gameemo_subject(subject_id)\n",
        "            \n",
        "    #         if features is not None and labels is not None:\n",
        "    #             gameemo_all_features.append(features)\n",
        "    #             gameemo_all_labels.append(labels)\n",
        "        \n",
        "    #     if len(gameemo_all_features) > 0:\n",
        "    #         # Concatenate all features\n",
        "    #         gameemo_features = np.concatenate(gameemo_all_features, axis=0)\n",
        "    #         gameemo_labels = np.concatenate(gameemo_all_labels, axis=0)\n",
        "            \n",
        "    #         print(f\"   Loaded GAMEEMO data: {gameemo_features.shape}\")\n",
        "            \n",
        "    #         # Train on GAMEEMO\n",
        "    #         print(\"\\n--- Training: GAMEEMO Emotion Recognition ---\")\n",
        "    #         gameemo_results = training_manager.train_with_cross_validation(\n",
        "    #             features=gameemo_features,\n",
        "    #             labels=gameemo_labels,\n",
        "    #             task_name='gameemo_emotion',\n",
        "    #             n_classes=len(np.unique(gameemo_labels)),\n",
        "    #             n_folds=config.N_FOLDS\n",
        "    #         )\n",
        "    #         all_results.append(gameemo_results)\n",
        "            \n",
        "    #         # Visualizations\n",
        "    #         visualizer.plot_learning_curves_all_folds(gameemo_results)\n",
        "    #         visualizer.plot_all_folds_comparison(gameemo_results)\n",
        "            \n",
        "    #         print(\"\\n    Backing up GAMEEMO results...\")\n",
        "    #         backup_manager.backup_all()\n",
        "    #     else:\n",
        "    #         print(\"    No GAMEEMO data loaded - skipping\")\n",
        "    #         print(\"  Note: GAMEEMO loader may need adjustment based on actual file structure\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"    Error loading GAMEEMO: {e}\")\n",
        "    #     print(\"  Skipping GAMEEMO training\")\n",
        "    \n",
        "    # =====================================================================\n",
        "    # 4. FINAL SUMMARY\n",
        "    # =====================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EXPERIMENT COMPLETE - RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Create summary visualization\n",
        "    if len(all_results) > 0:\n",
        "        visualizer.create_results_summary_plot(all_results)\n",
        "    \n",
        "    # Print comparison with paper results\n",
        "    print(\"\\n    RESULTS COMPARISON:\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'Task':<30} {'Our Result':<20} {'Paper Result':<20}\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    paper_results = {\n",
        "        'deap_arousal': (94.83, 1.30),\n",
        "        'deap_valence': (94.58, 1.31),\n",
        "        'seed': (94.76, 0.18)\n",
        "    }\n",
        "    \n",
        "    for result in all_results:\n",
        "        task = result['task_name']\n",
        "        our_mean = result['mean_accuracy'] * 100\n",
        "        our_std = result['std_accuracy'] * 100\n",
        "        \n",
        "        if task in paper_results:\n",
        "            paper_mean, paper_std = paper_results[task]\n",
        "            print(f\"{task:<30} {our_mean:.2f}±{our_std:.2f}%{'':<10} {paper_mean:.2f}±{paper_std:.2f}%\")\n",
        "        else:\n",
        "            print(f\"{task:<30} {our_mean:.2f}±{our_std:.2f}%\")\n",
        "    \n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    # Final backup\n",
        "    print(\"\\n    Final backup to Google Drive...\")\n",
        "    backup_manager.backup_all()\n",
        "    \n",
        "    print(\"\\n    ALL EXPERIMENTS COMPLETED!\")\n",
        "    print(f\"Total tasks trained: {len(all_results)}\")\n",
        "    return all_results\n",
        "\n",
        "# Run the complete experiment\n",
        "print(\"=\"*70)\n",
        "print(\"STARTING COMPLETE TRAINING PIPELINE\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n    This will train on DEAP, SEED-IV, and GAMEEMO datasets\")\n",
        "print(\"  Expected duration: 6-12 hours depending on GPU\")\n",
        "print(\"  Make sure datasets are properly mounted\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Start training\n",
        "results = run_complete_experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0969aaa5",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🚀 Starting GAMEEMO testing pipeline...\n",
            "\n",
            "======================================================================\n",
            "TESTING TRAINED MODELS ON GAMEEMO DATASET\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "STEP 1: Loading GAMEEMO Dataset\n",
            "======================================================================\n",
            "\n",
            "📋 Inspecting first file to understand structure...\n",
            "\n",
            "Inspecting: S01G1AllChannels.mat\n",
            "Keys in file:\n",
            "  AF3: shape=(38252, 1), dtype=float64\n",
            "  AF4: shape=(38252, 1), dtype=float64\n",
            "  F3: shape=(38252, 1), dtype=float64\n",
            "  F4: shape=(38252, 1), dtype=float64\n",
            "  F7: shape=(38252, 1), dtype=float64\n",
            "  F8: shape=(38252, 1), dtype=float64\n",
            "  FC5: shape=(38252, 1), dtype=float64\n",
            "  FC6: shape=(38252, 1), dtype=float64\n",
            "  O1: shape=(38252, 1), dtype=float64\n",
            "  O2: shape=(38252, 1), dtype=float64\n",
            "  P7: shape=(38252, 1), dtype=float64\n",
            "  P8: shape=(38252, 1), dtype=float64\n",
            "  T7: shape=(38252, 1), dtype=float64\n",
            "  T8: shape=(38252, 1), dtype=float64\n",
            "\n",
            "\n",
            "📥 Loading data from all subjects and games...\n",
            "----------------------------------------------------------------------\n",
            "S01 G1:    590 segments\n",
            "S01 G2:    590 segments\n",
            "S01 G2:    590 segments\n",
            "S01 G3:    590 segments\n",
            "S01 G3:    590 segments\n",
            "S01 G4:    590 segments\n",
            "S01 G4:    590 segments\n",
            "S02 G1:    590 segments\n",
            "S02 G1:    590 segments\n",
            "S02 G2:    590 segments\n",
            "S02 G2:    590 segments\n",
            "S02 G3:    590 segments\n",
            "S02 G3:    590 segments\n",
            "S02 G4:    590 segments\n",
            "S02 G4:    590 segments\n",
            "S03 G1:    590 segments\n",
            "S03 G1:    590 segments\n",
            "S03 G2:    590 segments\n",
            "S03 G2:    590 segments\n",
            "S03 G3:    590 segments\n",
            "S03 G3:    590 segments\n",
            "S03 G4:    590 segments\n",
            "S03 G4:    590 segments\n",
            "S04 G1:    590 segments\n",
            "S04 G1:    590 segments\n",
            "S04 G2:    590 segments\n",
            "S04 G2:    590 segments\n",
            "S04 G3:    590 segments\n",
            "S04 G3:    590 segments\n",
            "S04 G4:    590 segments\n",
            "S04 G4:    590 segments\n",
            "S05 G1:    590 segments\n",
            "S05 G1:    590 segments\n",
            "S05 G2:    590 segments\n",
            "S05 G2:    590 segments\n",
            "S05 G3:    590 segments\n",
            "S05 G3:    590 segments\n",
            "S05 G4:    590 segments\n",
            "S05 G4:    590 segments\n",
            "S06 G1:    590 segments\n",
            "S06 G1:    590 segments\n",
            "S06 G2:    590 segments\n",
            "S06 G2:    590 segments\n",
            "S06 G3:    590 segments\n",
            "S06 G3:    590 segments\n",
            "S06 G4:    590 segments\n",
            "S06 G4:    590 segments\n",
            "S07 G1:    590 segments\n",
            "S07 G1:    590 segments\n",
            "S07 G2:    590 segments\n",
            "S07 G2:    590 segments\n",
            "S07 G3:    590 segments\n",
            "S07 G3:    590 segments\n",
            "S07 G4:    590 segments\n",
            "S07 G4:    590 segments\n",
            "S08 G1:    590 segments\n",
            "S08 G1:    590 segments\n",
            "S08 G2:    590 segments\n",
            "S08 G2:    590 segments\n",
            "S08 G3:    590 segments\n",
            "S08 G3:    590 segments\n",
            "S08 G4:    590 segments\n",
            "S08 G4:    590 segments\n",
            "S09 G1:    590 segments\n",
            "S09 G1:    590 segments\n",
            "S09 G2:    590 segments\n",
            "S09 G2:    590 segments\n",
            "S09 G3:    590 segments\n",
            "S09 G3:    590 segments\n",
            "S09 G4:    590 segments\n",
            "S09 G4:    590 segments\n",
            "S10 G1:    590 segments\n",
            "S10 G1:    590 segments\n",
            "S10 G2:    590 segments\n",
            "S10 G2:    590 segments\n",
            "S10 G3:    590 segments\n",
            "S10 G3:    590 segments\n",
            "S10 G4:    590 segments\n",
            "S10 G4:    590 segments\n",
            "S11 G1:    590 segments\n",
            "S11 G1:    590 segments\n",
            "S11 G2:    590 segments\n",
            "S11 G2:    590 segments\n",
            "S11 G3:    590 segments\n",
            "S11 G3:    590 segments\n",
            "S11 G4:    590 segments\n",
            "S11 G4:    590 segments\n",
            "S12 G1:    590 segments\n",
            "S12 G1:    590 segments\n",
            "S12 G2:    590 segments\n",
            "S12 G2:    590 segments\n",
            "S12 G3:    590 segments\n",
            "S12 G3:    590 segments\n",
            "S12 G4:    590 segments\n",
            "S12 G4:    590 segments\n",
            "S13 G1:    590 segments\n",
            "S13 G1:    590 segments\n",
            "S13 G2:    590 segments\n",
            "S13 G2:    590 segments\n",
            "S13 G3:    590 segments\n",
            "S13 G3:    590 segments\n",
            "S13 G4:    590 segments\n",
            "S13 G4:    590 segments\n",
            "S14 G1:    590 segments\n",
            "S14 G1:    590 segments\n",
            "S14 G2:    590 segments\n",
            "S14 G2:    590 segments\n",
            "S14 G3:    590 segments\n",
            "S14 G3:    590 segments\n",
            "S14 G4:    590 segments\n",
            "S14 G4:    590 segments\n",
            "S15 G1:    590 segments\n",
            "S15 G1:    590 segments\n",
            "S15 G2:    590 segments\n",
            "S15 G2:    590 segments\n",
            "S15 G3:    590 segments\n",
            "S15 G3:    590 segments\n",
            "S15 G4:    590 segments\n",
            "S15 G4:    590 segments\n",
            "S16 G1:    590 segments\n",
            "S16 G1:    590 segments\n",
            "S16 G2:    590 segments\n",
            "S16 G2:    590 segments\n",
            "S16 G3:    590 segments\n",
            "S16 G3:    590 segments\n",
            "S16 G4:    590 segments\n",
            "S16 G4:    590 segments\n",
            "S17 G1:    590 segments\n",
            "S17 G1:    590 segments\n",
            "S17 G2:    590 segments\n",
            "S17 G2:    590 segments\n",
            "S17 G3:    590 segments\n",
            "S17 G3:    590 segments\n",
            "S17 G4:    590 segments\n",
            "S17 G4:    590 segments\n",
            "S18 G1:    590 segments\n",
            "S18 G1:    590 segments\n",
            "S18 G2:    590 segments\n",
            "S18 G2:    590 segments\n",
            "S18 G3:    590 segments\n",
            "S18 G3:    590 segments\n",
            "S18 G4:    590 segments\n",
            "S18 G4:    590 segments\n",
            "S19 G1:    590 segments\n",
            "S19 G1:    590 segments\n",
            "S19 G2:    590 segments\n",
            "S19 G2:    590 segments\n",
            "S19 G3:    590 segments\n",
            "S19 G3:    590 segments\n",
            "S19 G4:    590 segments\n",
            "S19 G4:    590 segments\n",
            "S20 G1:    590 segments\n",
            "S20 G1:    590 segments\n",
            "S20 G2:    590 segments\n",
            "S20 G2:    590 segments\n",
            "S20 G3:    590 segments\n",
            "S20 G3:    590 segments\n",
            "S20 G4:    590 segments\n",
            "S20 G4:    590 segments\n",
            "S21 G1:    590 segments\n",
            "S21 G1:    590 segments\n",
            "S21 G2:    590 segments\n",
            "S21 G2:    590 segments\n",
            "S21 G3:    590 segments\n",
            "S21 G3:    590 segments\n",
            "S21 G4:    590 segments\n",
            "S21 G4:    590 segments\n",
            "S22 G1:    590 segments\n",
            "S22 G1:    590 segments\n",
            "S22 G2:    590 segments\n",
            "S22 G2:    590 segments\n",
            "S22 G3:    590 segments\n",
            "S22 G3:    590 segments\n",
            "S22 G4:    590 segments\n",
            "S22 G4:    590 segments\n",
            "S23 G1:    590 segments\n",
            "S23 G1:    590 segments\n",
            "S23 G2:    590 segments\n",
            "S23 G2:    590 segments\n",
            "S23 G3:    590 segments\n",
            "S23 G3:    590 segments\n",
            "S23 G4:    590 segments\n",
            "S23 G4:    590 segments\n",
            "S24 G1:    590 segments\n",
            "S24 G1:    590 segments\n",
            "S24 G2:    590 segments\n",
            "S24 G2:    590 segments\n",
            "S24 G3:    590 segments\n",
            "S24 G3:    590 segments\n",
            "S24 G4:    590 segments\n",
            "S24 G4:    590 segments\n",
            "S25 G1:    590 segments\n",
            "S25 G1:    590 segments\n",
            "S25 G2:    590 segments\n",
            "S25 G2:    590 segments\n",
            "S25 G3:    590 segments\n",
            "S25 G3:    590 segments\n",
            "S25 G4:    590 segments\n",
            "S25 G4:    590 segments\n",
            "S26 G1:    590 segments\n",
            "S26 G1:    590 segments\n",
            "S26 G2:    590 segments\n",
            "S26 G2:    590 segments\n",
            "S26 G3:    590 segments\n",
            "S26 G3:    590 segments\n",
            "S26 G4:    590 segments\n",
            "S26 G4:    590 segments\n",
            "S27 G1:    590 segments\n",
            "S27 G1:    590 segments\n",
            "S27 G2:    590 segments\n",
            "S27 G2:    590 segments\n",
            "S27 G3:    590 segments\n",
            "S27 G3:    590 segments\n",
            "S27 G4:    590 segments\n",
            "S27 G4:    590 segments\n",
            "S28 G1:    590 segments\n",
            "S28 G1:    590 segments\n",
            "S28 G2:    590 segments\n",
            "S28 G2:    590 segments\n",
            "S28 G3:    590 segments\n",
            "S28 G3:    590 segments\n",
            "S28 G4:    590 segments\n",
            "S28 G4:    590 segments\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "   Loaded 112 sessions successfully (0 skipped)\n",
            "   590 segments\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "   Loaded 112 sessions successfully (0 skipped)\n",
            "\n",
            "   GAMEEMO Data Loaded!\n",
            "  Total samples: 66080\n",
            "  Feature shape: (66080, 4, 8, 9, 8)\n",
            "  Arousal - Low: 33040, High: 33040\n",
            "  Valence - Low: 33040, High: 33040\n",
            "\n",
            "📂 Found models in ./output/models:\n",
            "  DEAP Arousal: 5 models\n",
            "  DEAP Valence: 4 models\n",
            "  SEED: 5 models\n",
            "\n",
            "======================================================================\n",
            "STEP 2: Testing DEAP Arousal Model on GAMEEMO\n",
            "======================================================================\n",
            "\n",
            "Loading model: deap_arousal_fold3_best.h5\n",
            "\n",
            "   GAMEEMO Data Loaded!\n",
            "  Total samples: 66080\n",
            "  Feature shape: (66080, 4, 8, 9, 8)\n",
            "  Arousal - Low: 33040, High: 33040\n",
            "  Valence - Low: 33040, High: 33040\n",
            "\n",
            "📂 Found models in ./output/models:\n",
            "  DEAP Arousal: 5 models\n",
            "  DEAP Valence: 4 models\n",
            "  SEED: 5 models\n",
            "\n",
            "======================================================================\n",
            "STEP 2: Testing DEAP Arousal Model on GAMEEMO\n",
            "======================================================================\n",
            "\n",
            "Loading model: deap_arousal_fold3_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Making predictions...\n",
            "\n",
            "   DEAP Arousal on GAMEEMO Results:\n",
            "  Accuracy:  50.73%\n",
            "  Precision: 0.5068\n",
            "  Recall:    0.5454\n",
            "  F1-Score:  0.5254\n",
            "\n",
            "  Confusion Matrix:\n",
            "  [[15505 17535]\n",
            " [15021 18019]]\n",
            "\n",
            "======================================================================\n",
            "STEP 3: Testing DEAP Valence Model on GAMEEMO\n",
            "======================================================================\n",
            "\n",
            "Loading model: deap_subject1_valence_fold1_best.h5\n",
            "\n",
            "   DEAP Arousal on GAMEEMO Results:\n",
            "  Accuracy:  50.73%\n",
            "  Precision: 0.5068\n",
            "  Recall:    0.5454\n",
            "  F1-Score:  0.5254\n",
            "\n",
            "  Confusion Matrix:\n",
            "  [[15505 17535]\n",
            " [15021 18019]]\n",
            "\n",
            "======================================================================\n",
            "STEP 3: Testing DEAP Valence Model on GAMEEMO\n",
            "======================================================================\n",
            "\n",
            "Loading model: deap_subject1_valence_fold1_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Making predictions...\n",
            "\n",
            "   DEAP Valence on GAMEEMO Results:\n",
            "  Accuracy:  50.22%\n",
            "  Precision: 0.5014\n",
            "  Recall:    0.7678\n",
            "  F1-Score:  0.6067\n",
            "\n",
            "  Confusion Matrix:\n",
            "  [[ 7818 25222]\n",
            " [ 7672 25368]]\n",
            "\n",
            "======================================================================\n",
            "STEP 4: Testing SEED-IV Model on GAMEEMO\n",
            "======================================================================\n",
            "Note: SEED-IV predicts 4 emotions (neutral, sad, fear, happy)\n",
            "      Mapping to arousal/valence dimensions:\n",
            "        - Arousal: neutral/sad → Low, fear/happy → High\n",
            "        - Valence: sad/fear → Low, neutral/happy → High\n",
            "\n",
            "Loading model: seed_iv_fold2_best.h5\n",
            "\n",
            "   DEAP Valence on GAMEEMO Results:\n",
            "  Accuracy:  50.22%\n",
            "  Precision: 0.5014\n",
            "  Recall:    0.7678\n",
            "  F1-Score:  0.6067\n",
            "\n",
            "  Confusion Matrix:\n",
            "  [[ 7818 25222]\n",
            " [ 7672 25368]]\n",
            "\n",
            "======================================================================\n",
            "STEP 4: Testing SEED-IV Model on GAMEEMO\n",
            "======================================================================\n",
            "Note: SEED-IV predicts 4 emotions (neutral, sad, fear, happy)\n",
            "      Mapping to arousal/valence dimensions:\n",
            "        - Arousal: neutral/sad → Low, fear/happy → High\n",
            "        - Valence: sad/fear → Low, neutral/happy → High\n",
            "\n",
            "Loading model: seed_iv_fold2_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Making predictions...\n",
            "\n",
            "  Testing Arousal dimension...\n",
            "\n",
            "   SEED-IV Arousal on GAMEEMO Results:\n",
            "  Accuracy:  50.53%\n",
            "  Precision: 0.5027\n",
            "  Recall:    0.9737\n",
            "  F1-Score:  0.6631\n",
            "\n",
            "  Confusion Matrix:\n",
            "  [[ 1217 31823]\n",
            " [  869 32171]]\n",
            "\n",
            "  Testing Valence dimension...\n",
            "\n",
            "   SEED-IV Valence on GAMEEMO Results:\n",
            "  Accuracy:  49.86%\n",
            "  Precision: 0.4731\n",
            "  Recall:    0.0242\n",
            "  F1-Score:  0.0461\n",
            "\n",
            "  Confusion Matrix:\n",
            "  [[32149   891]\n",
            " [32240   800]]\n",
            "\n",
            "======================================================================\n",
            "FINAL TESTING RESULTS SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Task                                Accuracy     Precision    Recall       F1-Score    \n",
            "-------------------------------------------------------------------------------------\n",
            "DEAP Arousal → GAMEEMO               50.73%     0.5068      0.5454      0.5254\n",
            "DEAP Valence → GAMEEMO               50.22%     0.5014      0.7678      0.6067\n",
            "SEED-IV Arousal → GAMEEMO            50.53%     0.5027      0.9737      0.6631\n",
            "SEED-IV Valence → GAMEEMO            49.86%     0.4731      0.0242      0.0461\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "TESTING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "  Testing Arousal dimension...\n",
            "\n",
            "   SEED-IV Arousal on GAMEEMO Results:\n",
            "  Accuracy:  50.53%\n",
            "  Precision: 0.5027\n",
            "  Recall:    0.9737\n",
            "  F1-Score:  0.6631\n",
            "\n",
            "  Confusion Matrix:\n",
            "  [[ 1217 31823]\n",
            " [  869 32171]]\n",
            "\n",
            "  Testing Valence dimension...\n",
            "\n",
            "   SEED-IV Valence on GAMEEMO Results:\n",
            "  Accuracy:  49.86%\n",
            "  Precision: 0.4731\n",
            "  Recall:    0.0242\n",
            "  F1-Score:  0.0461\n",
            "\n",
            "  Confusion Matrix:\n",
            "  [[32149   891]\n",
            " [32240   800]]\n",
            "\n",
            "======================================================================\n",
            "FINAL TESTING RESULTS SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Task                                Accuracy     Precision    Recall       F1-Score    \n",
            "-------------------------------------------------------------------------------------\n",
            "DEAP Arousal → GAMEEMO               50.73%     0.5068      0.5454      0.5254\n",
            "DEAP Valence → GAMEEMO               50.22%     0.5014      0.7678      0.6067\n",
            "SEED-IV Arousal → GAMEEMO            50.53%     0.5027      0.9737      0.6631\n",
            "SEED-IV Valence → GAMEEMO            49.86%     0.4731      0.0242      0.0461\n",
            "-------------------------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "TESTING COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# GAMEEMO DATA LOADER AND TESTING\n",
        "# ============================================================================\n",
        "\n",
        "class GameemoDataLoader:\n",
        "    \"\"\"Load GAMEEMO dataset and extract 4D features\"\"\"\n",
        "    \n",
        "    def __init__(self, config, feature_extractor):\n",
        "        self.config = config\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.n_channels = 14  # GAMEEMO uses 14 EEG channels\n",
        "        \n",
        "        # GAMEEMO channel names (Emotiv EPOC headset)\n",
        "        self.channel_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1',\n",
        "                             'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
        "        \n",
        "    def inspect_mat_file(self, mat_path):\n",
        "        \"\"\"Inspect the structure of a GAMEEMO .mat file\"\"\"\n",
        "        try:\n",
        "            mat_data = loadmat(mat_path)\n",
        "            print(f\"\\nInspecting: {os.path.basename(mat_path)}\")\n",
        "            print(\"Keys in file:\")\n",
        "            for key in mat_data.keys():\n",
        "                if not key.startswith('__'):\n",
        "                    data = mat_data[key]\n",
        "                    if isinstance(data, np.ndarray):\n",
        "                        print(f\"  {key}: shape={data.shape}, dtype={data.dtype}\")\n",
        "                    else:\n",
        "                        print(f\"  {key}: type={type(data)}\")\n",
        "            return mat_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error inspecting file: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def load_subject_game(self, subject_id, game_id):\n",
        "        \"\"\"Load data for one subject's game session\"\"\"\n",
        "        subject_folder = f'(S{subject_id:02d})'\n",
        "        mat_file = f'S{subject_id:02d}G{game_id}AllChannels.mat'\n",
        "        \n",
        "        mat_path = os.path.join(\n",
        "            self.config.GAMEEMO_PATH,\n",
        "            subject_folder,\n",
        "            'Preprocessed EEG Data',\n",
        "            '.mat format',\n",
        "            mat_file\n",
        "        )\n",
        "        \n",
        "        if not os.path.exists(mat_path):\n",
        "            return None, None\n",
        "        \n",
        "        try:\n",
        "            mat_data = loadmat(mat_path)\n",
        "            \n",
        "            # GAMEEMO stores each channel as a separate variable\n",
        "            # Try to load channels by their names\n",
        "            channel_data = []\n",
        "            found_channels = []\n",
        "            \n",
        "            for ch_name in self.channel_names:\n",
        "                if ch_name in mat_data:\n",
        "                    ch_signal = mat_data[ch_name]\n",
        "                    # Flatten if needed (remove singleton dimensions)\n",
        "                    if ch_signal.ndim > 1:\n",
        "                        ch_signal = ch_signal.flatten()\n",
        "                    channel_data.append(ch_signal)\n",
        "                    found_channels.append(ch_name)\n",
        "            \n",
        "            if len(channel_data) == 0:\n",
        "                return None, None\n",
        "            \n",
        "            # Stack channels: (n_samples, n_channels)\n",
        "            eeg_data = np.column_stack(channel_data)\n",
        "            \n",
        "            # Check if data is too short (minimum 30 samples needed for filtering)\n",
        "            if eeg_data.shape[0] < 30:\n",
        "                return None, None\n",
        "            \n",
        "            # Extract 4D features\n",
        "            try:\n",
        "                features_4d = self.feature_extractor.create_4d_features(\n",
        "                    eeg_data,\n",
        "                    time_steps=self.config.TIME_STEPS,\n",
        "                    dataset='deap'\n",
        "                )\n",
        "            except ValueError:\n",
        "                return None, None\n",
        "            \n",
        "            n_segments = features_4d.shape[0]\n",
        "            \n",
        "            # Skip if no segments were created\n",
        "            if n_segments == 0:\n",
        "                return None, None\n",
        "            \n",
        "            # Create arousal/valence labels\n",
        "            # Based on GAMEEMO paper:\n",
        "            # G1: Boring (Low Arousal, Low Valence)\n",
        "            # G2: Calm (Low Arousal, High Valence) \n",
        "            # G3: Horror (High Arousal, Low Valence)\n",
        "            # G4: Exciting (High Arousal, High Valence)\n",
        "            arousal_label = 1 if game_id >= 3 else 0  # G3, G4 = High Arousal\n",
        "            valence_label = 1 if game_id in [2, 4] else 0  # G2, G4 = High Valence\n",
        "            \n",
        "            arousal_labels = np.full(n_segments, arousal_label)\n",
        "            valence_labels = np.full(n_segments, valence_label)\n",
        "            \n",
        "            return features_4d, {'arousal': arousal_labels, 'valence': valence_labels}\n",
        "            \n",
        "        except Exception:\n",
        "            return None, None\n",
        "    \n",
        "    def load_all_subjects(self, subject_ids=None, game_ids=None, inspect_first=True):\n",
        "        \"\"\"Load GAMEEMO data for multiple subjects and games\"\"\"\n",
        "        if subject_ids is None:\n",
        "            subject_ids = range(1, 29)  # All 28 subjects\n",
        "        if game_ids is None:\n",
        "            game_ids = range(1, 5)  # All 4 games\n",
        "        \n",
        "        # Inspect first file to understand structure\n",
        "        if inspect_first:\n",
        "            print(\"\\n📋 Inspecting first file to understand structure...\")\n",
        "            first_subject = subject_ids[0] if isinstance(subject_ids, list) else list(subject_ids)[0]\n",
        "            first_game = game_ids[0] if isinstance(game_ids, list) else list(game_ids)[0]\n",
        "            \n",
        "            subject_folder = f'(S{first_subject:02d})'\n",
        "            mat_file = f'S{first_subject:02d}G{first_game}AllChannels.mat'\n",
        "            mat_path = os.path.join(\n",
        "                self.config.GAMEEMO_PATH,\n",
        "                subject_folder,\n",
        "                'Preprocessed EEG Data',\n",
        "                '.mat format',\n",
        "                mat_file\n",
        "            )\n",
        "            \n",
        "            if os.path.exists(mat_path):\n",
        "                self.inspect_mat_file(mat_path)\n",
        "            print()\n",
        "        \n",
        "        all_features = []\n",
        "        all_arousal = []\n",
        "        all_valence = []\n",
        "        \n",
        "        skipped_count = 0\n",
        "        loaded_count = 0\n",
        "        \n",
        "        print(\"\\n📥 Loading data from all subjects and games...\")\n",
        "        print(\"-\" * 70)\n",
        "        \n",
        "        for subject_id in subject_ids:\n",
        "            for game_id in game_ids:\n",
        "                print(f\"S{subject_id:02d} G{game_id}: \", end='', flush=True)\n",
        "                features, labels = self.load_subject_game(subject_id, game_id)\n",
        "                \n",
        "                if features is not None:\n",
        "                    all_features.append(features)\n",
        "                    all_arousal.append(labels['arousal'])\n",
        "                    all_valence.append(labels['valence'])\n",
        "                    print(f\"   {features.shape[0]} segments\")\n",
        "                    loaded_count += 1\n",
        "                else:\n",
        "                    print(\"✗ skipped\")\n",
        "                    skipped_count += 1\n",
        "        \n",
        "        print(\"-\" * 70)\n",
        "        \n",
        "        if len(all_features) == 0:\n",
        "            print(f\"\\n✗ No data loaded. All {skipped_count} files were skipped.\")\n",
        "            return None\n",
        "        \n",
        "        print(f\"\\n   Loaded {loaded_count} sessions successfully ({skipped_count} skipped)\")\n",
        "        \n",
        "        return {\n",
        "            'features': np.concatenate(all_features, axis=0),\n",
        "            'arousal': np.concatenate(all_arousal, axis=0),\n",
        "            'valence': np.concatenate(all_valence, axis=0)\n",
        "        }\n",
        "\n",
        "\n",
        "def test_models_on_gameemo():\n",
        "    \"\"\"Test trained DEAP and SEED models on GAMEEMO dataset\"\"\"\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    print(\"TESTING TRAINED MODELS ON GAMEEMO DATASET\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Load GAMEEMO data\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 1: Loading GAMEEMO Dataset\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    gameemo_loader = GameemoDataLoader(config, dataset_loader.feature_extractor_deap)\n",
        "    gameemo_data = gameemo_loader.load_all_subjects(inspect_first=True)\n",
        "    \n",
        "    if gameemo_data is None:\n",
        "        print(\"\\n✗ Failed to load GAMEEMO data\")\n",
        "        return\n",
        "    \n",
        "    print(f\"\\n   GAMEEMO Data Loaded!\")\n",
        "    print(f\"  Total samples: {gameemo_data['features'].shape[0]}\")\n",
        "    print(f\"  Feature shape: {gameemo_data['features'].shape}\")\n",
        "    print(f\"  Arousal - Low: {np.sum(gameemo_data['arousal']==0)}, High: {np.sum(gameemo_data['arousal']==1)}\")\n",
        "    print(f\"  Valence - Low: {np.sum(gameemo_data['valence']==0)}, High: {np.sum(gameemo_data['valence']==1)}\")\n",
        "    \n",
        "    # Check if models directory exists\n",
        "    models_dir = os.path.join(config.OUTPUT_DIR, 'models')\n",
        "    \n",
        "    # Try to download models from checkpoints if not found locally\n",
        "    if not os.path.exists(models_dir) or len(os.listdir(models_dir)) == 0:\n",
        "        print(f\"\\n📦 Models directory not found or empty: {models_dir}\")\n",
        "        print(\"  Attempting to download models from Google Drive (checkpoints folder)...\")\n",
        "        \n",
        "        # Create models directory if it doesn't exist\n",
        "        os.makedirs(models_dir, exist_ok=True)\n",
        "        \n",
        "        # Check if rclone is configured\n",
        "        if not os.path.exists(backup_manager.rclone_config_path):\n",
        "            print(f\"\\n      Rclone not configured at {backup_manager.rclone_config_path}\")\n",
        "            print(\"  Please configure rclone or train models first.\")\n",
        "            print(\"\\n  To configure rclone:\")\n",
        "            print(\"    1. Uncomment and run the rclone setup cell above\")\n",
        "            print(\"    2. Or manually run: !rclone config\")\n",
        "            return\n",
        "        \n",
        "        # Try to download from Google Drive using rclone (from checkpoints folder)\n",
        "        remote_path = f\"{backup_manager.remote_name}:{backup_manager.remote_folder}/checkpoints\"\n",
        "        \n",
        "        try:\n",
        "            print(f\"\\n  📥 Running: rclone copy '{remote_path}' '{models_dir}' -P\")\n",
        "            result = os.system(f\"rclone copy '{remote_path}' '{models_dir}' -P\")\n",
        "            \n",
        "            if result == 0 and os.path.exists(models_dir) and len(os.listdir(models_dir)) > 0:\n",
        "                print(\"     Models downloaded successfully from Google Drive\")\n",
        "            else:\n",
        "                print(f\"  ✗ Download failed or no models found in Google Drive\")\n",
        "                print(\"  ℹ You need to:\")\n",
        "                print(\"    1. Train models on DEAP/SEED datasets first\")\n",
        "                print(\"    2. Backup models to Google Drive using backup_manager.backup_all()\")\n",
        "                print(\"    3. Or uncomment and run the DEAP training code\")\n",
        "                return\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error downloading models: {e}\")\n",
        "            print(\"  ℹ You may need to train models first\")\n",
        "            return\n",
        "    \n",
        "    # Look for trained models (support both .keras and .h5 formats)\n",
        "    model_files = os.listdir(models_dir) if os.path.exists(models_dir) else []\n",
        "    deap_arousal_models = [f for f in model_files if 'deap' in f.lower() and 'arousal' in f.lower() \n",
        "                           and (f.endswith('.keras') or f.endswith('.h5'))]\n",
        "    deap_valence_models = [f for f in model_files if 'deap' in f.lower() and 'valence' in f.lower() \n",
        "                           and (f.endswith('.keras') or f.endswith('.h5'))]\n",
        "    seed_models = [f for f in model_files if 'seed' in f.lower() \n",
        "                   and (f.endswith('.keras') or f.endswith('.h5'))]\n",
        "    \n",
        "    print(f\"\\n    Found models in {models_dir}:\")\n",
        "    print(f\"  DEAP Arousal: {len(deap_arousal_models)} models\")\n",
        "    print(f\"  DEAP Valence: {len(deap_valence_models)} models\")\n",
        "    print(f\"  SEED: {len(seed_models)} models\")\n",
        "    \n",
        "    if len(deap_arousal_models) == 0 and len(deap_valence_models) == 0 and len(seed_models) == 0:\n",
        "        print(\"\\n    No trained models found!\")\n",
        "        print(\"  Please train models first or ensure they are uploaded to Google Drive.\")\n",
        "        return\n",
        "    \n",
        "    all_results = []\n",
        "    \n",
        "    # Test DEAP Arousal Model\n",
        "    if len(deap_arousal_models) > 0:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"STEP 2: Testing DEAP Arousal Model on GAMEEMO\")\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "        model_path = os.path.join(models_dir, deap_arousal_models[0])\n",
        "        print(f\"\\nLoading model: {deap_arousal_models[0]}\")\n",
        "        \n",
        "        try:\n",
        "            # Load model with custom objects (ChannelAttention layer)\n",
        "            with tf.keras.utils.custom_object_scope({'ChannelAttention': ChannelAttention}):\n",
        "                model = tf.keras.models.load_model(model_path)\n",
        "            \n",
        "            # Make predictions\n",
        "            print(\"Making predictions...\")\n",
        "            y_pred_prob = model.predict(gameemo_data['features'], batch_size=32, verbose=0)\n",
        "            y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "            y_true = gameemo_data['arousal']\n",
        "            \n",
        "            # Calculate metrics\n",
        "            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "            \n",
        "            accuracy = accuracy_score(y_true, y_pred)\n",
        "            precision = precision_score(y_true, y_pred, average='binary')\n",
        "            recall = recall_score(y_true, y_pred, average='binary')\n",
        "            f1 = f1_score(y_true, y_pred, average='binary')\n",
        "            cm = confusion_matrix(y_true, y_pred)\n",
        "            \n",
        "            print(f\"\\n   DEAP Arousal on GAMEEMO Results:\")\n",
        "            print(f\"  Accuracy:  {accuracy*100:.2f}%\")\n",
        "            print(f\"  Precision: {precision:.4f}\")\n",
        "            print(f\"  Recall:    {recall:.4f}\")\n",
        "            print(f\"  F1-Score:  {f1:.4f}\")\n",
        "            print(f\"\\n  Confusion Matrix:\")\n",
        "            print(f\"  {cm}\")\n",
        "            \n",
        "            all_results.append({\n",
        "                'task': 'DEAP Arousal → GAMEEMO',\n",
        "                'accuracy': accuracy,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1_score': f1\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error loading/testing model: {e}\")\n",
        "    \n",
        "    # Test DEAP Valence Model\n",
        "    if len(deap_valence_models) > 0:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"STEP 3: Testing DEAP Valence Model on GAMEEMO\")\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "        model_path = os.path.join(models_dir, deap_valence_models[0])\n",
        "        print(f\"\\nLoading model: {deap_valence_models[0]}\")\n",
        "        \n",
        "        try:\n",
        "            # Load model with custom objects (ChannelAttention layer)\n",
        "            with tf.keras.utils.custom_object_scope({'ChannelAttention': ChannelAttention}):\n",
        "                model = tf.keras.models.load_model(model_path)\n",
        "            \n",
        "            # Make predictions\n",
        "            print(\"Making predictions...\")\n",
        "            y_pred_prob = model.predict(gameemo_data['features'], batch_size=32, verbose=0)\n",
        "            y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "            y_true = gameemo_data['valence']\n",
        "            \n",
        "            # Calculate metrics\n",
        "            accuracy = accuracy_score(y_true, y_pred)\n",
        "            precision = precision_score(y_true, y_pred, average='binary')\n",
        "            recall = recall_score(y_true, y_pred, average='binary')\n",
        "            f1 = f1_score(y_true, y_pred, average='binary')\n",
        "            cm = confusion_matrix(y_true, y_pred)\n",
        "            \n",
        "            print(f\"\\n   DEAP Valence on GAMEEMO Results:\")\n",
        "            print(f\"  Accuracy:  {accuracy*100:.2f}%\")\n",
        "            print(f\"  Precision: {precision:.4f}\")\n",
        "            print(f\"  Recall:    {recall:.4f}\")\n",
        "            print(f\"  F1-Score:  {f1:.4f}\")\n",
        "            print(f\"\\n  Confusion Matrix:\")\n",
        "            print(f\"  {cm}\")\n",
        "            \n",
        "            all_results.append({\n",
        "                'task': 'DEAP Valence → GAMEEMO',\n",
        "                'accuracy': accuracy,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1_score': f1\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error loading/testing model: {e}\")\n",
        "    \n",
        "    # Test SEED-IV Model (4-class emotion → Arousal/Valence mapping)\n",
        "    if len(seed_models) > 0:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"STEP 4: Testing SEED-IV Model on GAMEEMO\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"Note: SEED-IV predicts 4 emotions (neutral, sad, fear, happy)\")\n",
        "        print(\"      Mapping to arousal/valence dimensions:\")\n",
        "        print(\"        - Arousal: neutral/sad → Low, fear/happy → High\")\n",
        "        print(\"        - Valence: sad/fear → Low, neutral/happy → High\")\n",
        "        \n",
        "        model_path = os.path.join(models_dir, seed_models[0])\n",
        "        print(f\"\\nLoading model: {seed_models[0]}\")\n",
        "        \n",
        "        try:\n",
        "            # Load model with custom objects (ChannelAttention layer)\n",
        "            with tf.keras.utils.custom_object_scope({'ChannelAttention': ChannelAttention}):\n",
        "                model = tf.keras.models.load_model(model_path)\n",
        "            \n",
        "            # Make predictions\n",
        "            print(\"Making predictions...\")\n",
        "            y_pred_prob = model.predict(gameemo_data['features'], batch_size=32, verbose=0)\n",
        "            y_pred_emotion = np.argmax(y_pred_prob, axis=1)  # 0=neutral, 1=sad, 2=fear, 3=happy\n",
        "            \n",
        "            # Map SEED emotions to arousal/valence\n",
        "            # Arousal mapping: neutral(0)/sad(1) → 0 (Low), fear(2)/happy(3) → 1 (High)\n",
        "            y_pred_arousal = np.where((y_pred_emotion == 2) | (y_pred_emotion == 3), 1, 0)\n",
        "            \n",
        "            # Valence mapping: sad(1)/fear(2) → 0 (Low), neutral(0)/happy(3) → 1 (High)\n",
        "            y_pred_valence = np.where((y_pred_emotion == 1) | (y_pred_emotion == 2), 0, 1)\n",
        "            \n",
        "            # Test Arousal\n",
        "            print(\"\\n  Testing Arousal dimension...\")\n",
        "            y_true_arousal = gameemo_data['arousal']\n",
        "            accuracy_arousal = accuracy_score(y_true_arousal, y_pred_arousal)\n",
        "            precision_arousal = precision_score(y_true_arousal, y_pred_arousal, average='binary')\n",
        "            recall_arousal = recall_score(y_true_arousal, y_pred_arousal, average='binary')\n",
        "            f1_arousal = f1_score(y_true_arousal, y_pred_arousal, average='binary')\n",
        "            cm_arousal = confusion_matrix(y_true_arousal, y_pred_arousal)\n",
        "            \n",
        "            print(f\"\\n   SEED-IV Arousal on GAMEEMO Results:\")\n",
        "            print(f\"  Accuracy:  {accuracy_arousal*100:.2f}%\")\n",
        "            print(f\"  Precision: {precision_arousal:.4f}\")\n",
        "            print(f\"  Recall:    {recall_arousal:.4f}\")\n",
        "            print(f\"  F1-Score:  {f1_arousal:.4f}\")\n",
        "            print(f\"\\n  Confusion Matrix:\")\n",
        "            print(f\"  {cm_arousal}\")\n",
        "            \n",
        "            all_results.append({\n",
        "                'task': 'SEED-IV Arousal → GAMEEMO',\n",
        "                'accuracy': accuracy_arousal,\n",
        "                'precision': precision_arousal,\n",
        "                'recall': recall_arousal,\n",
        "                'f1_score': f1_arousal\n",
        "            })\n",
        "            \n",
        "            # Test Valence\n",
        "            print(\"\\n  Testing Valence dimension...\")\n",
        "            y_true_valence = gameemo_data['valence']\n",
        "            accuracy_valence = accuracy_score(y_true_valence, y_pred_valence)\n",
        "            precision_valence = precision_score(y_true_valence, y_pred_valence, average='binary')\n",
        "            recall_valence = recall_score(y_true_valence, y_pred_valence, average='binary')\n",
        "            f1_valence = f1_score(y_true_valence, y_pred_valence, average='binary')\n",
        "            cm_valence = confusion_matrix(y_true_valence, y_pred_valence)\n",
        "            \n",
        "            print(f\"\\n   SEED-IV Valence on GAMEEMO Results:\")\n",
        "            print(f\"  Accuracy:  {accuracy_valence*100:.2f}%\")\n",
        "            print(f\"  Precision: {precision_valence:.4f}\")\n",
        "            print(f\"  Recall:    {recall_valence:.4f}\")\n",
        "            print(f\"  F1-Score:  {f1_valence:.4f}\")\n",
        "            print(f\"\\n  Confusion Matrix:\")\n",
        "            print(f\"  {cm_valence}\")\n",
        "            \n",
        "            all_results.append({\n",
        "                'task': 'SEED-IV Valence → GAMEEMO',\n",
        "                'accuracy': accuracy_valence,\n",
        "                'precision': precision_valence,\n",
        "                'recall': recall_valence,\n",
        "                'f1_score': f1_valence\n",
        "            })\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error loading/testing SEED model: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "    \n",
        "    # Final Summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"FINAL TESTING RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    if len(all_results) > 0:\n",
        "        print(f\"\\n{'Task':<35} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
        "        print(\"-\" * 85)\n",
        "        \n",
        "        for result in all_results:\n",
        "            print(f\"{result['task']:<35} {result['accuracy']*100:>6.2f}%     \"\n",
        "                  f\"{result['precision']:>6.4f}      {result['recall']:>6.4f}      \"\n",
        "                  f\"{result['f1_score']:>6.4f}\")\n",
        "        \n",
        "        print(\"-\" * 85)\n",
        "    else:\n",
        "        print(\"\\n    No models were tested.\")\n",
        "        print(\"  Train models on DEAP/SEED first, then run this test.\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TESTING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Execute the testing\n",
        "print(\"\\n🚀 Starting GAMEEMO testing pipeline...\\n\")\n",
        "test_models_on_gameemo()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a42fb0cb",
      "metadata": {},
      "source": [
        "### Combined Results Visualization and Summary\n",
        "\n",
        "Visualize and compare results from all trained datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97709a3",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "COMBINED RESULTS - ALL EXPERIMENTS\n",
            "======================================================================\n",
            "\n",
            "⚠ No experiments completed yet.\n",
            "  Run the individual dataset training cells above first.\n",
            "  Results will be automatically collected in 'all_experiment_results'\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMBINED RESULTS - ALL EXPERIMENTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if len(all_experiment_results) > 0:\n",
        "    # Create summary visualization comparing all tasks\n",
        "    print(f\"\\n   Total experiments completed: {len(all_experiment_results)}\")\n",
        "    \n",
        "    print(\"\\n    Creating combined visualizations...\")\n",
        "    visualizer.create_results_summary_plot(all_experiment_results)\n",
        "    \n",
        "    # Print detailed comparison table\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RESULTS COMPARISON WITH PAPER\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"{'Task':<30} {'Our Result':<25} {'Paper Result':<20}\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    # Paper results for comparison\n",
        "    paper_results = {\n",
        "        'deap_arousal': (94.83, 1.30),\n",
        "        'deap_valence': (94.58, 1.31),\n",
        "        'seed_iv': (94.76, 0.18),\n",
        "        'seed': (94.76, 0.18)\n",
        "    }\n",
        "    \n",
        "    for result in all_experiment_results:\n",
        "        task = result['task_name']\n",
        "        our_mean = result['mean_accuracy'] * 100\n",
        "        our_std = result['std_accuracy'] * 100\n",
        "        \n",
        "        if task in paper_results:\n",
        "            paper_mean, paper_std = paper_results[task]\n",
        "            diff = our_mean - paper_mean\n",
        "            symbol = \"  \" if abs(diff) < 2.0 else \"   \"\n",
        "            print(f\"{symbol} {task:<28} {our_mean:5.2f}% ± {our_std:4.2f}%{'':<10} {paper_mean:5.2f}% ± {paper_std:4.2f}%\")\n",
        "        else:\n",
        "            print(f\"  {task:<28} {our_mean:5.2f}% ± {our_std:4.2f}%\")\n",
        "    \n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    # Calculate average accuracy across all tasks\n",
        "    avg_accuracy = np.mean([r['mean_accuracy'] for r in all_experiment_results]) * 100\n",
        "    print(f\"\\nAverage Accuracy Across All Tasks: {avg_accuracy:.2f}%\")\n",
        "    \n",
        "    # Print individual fold results for each task\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DETAILED FOLD RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for result in all_experiment_results:\n",
        "        print(f\"\\n{result['task_name'].upper()}:\")\n",
        "        fold_accs = [f\"{acc*100:.2f}%\" for acc in result['fold_accuracies']]\n",
        "        for i, acc in enumerate(fold_accs, 1):\n",
        "            print(f\"  Fold {i}: {acc}\")\n",
        "        print(f\"  Mean: {result['mean_accuracy']*100:.2f}% ± {result['std_accuracy']*100:.2f}%\")\n",
        "    \n",
        "    # Final backup\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"    Final backup to Google Drive...\")\n",
        "    backup_manager.backup_all()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"    ALL EXPERIMENTS COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Total tasks trained: {len(all_experiment_results)}\")\n",
        "    print(f\"All results saved to: {config.OUTPUT_DIR}\")\n",
        "    print(f\"All checkpoints saved to: {config.CHECKPOINT_DIR}\")\n",
        "    print(f\"All visualizations saved to: {config.VISUALIZATIONS_DIR}\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\n    No experiments completed yet.\")\n",
        "    print(\"  Run the individual dataset training cells above first.\")\n",
        "    print(\"  Results will be automatically collected in 'all_experiment_results'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
